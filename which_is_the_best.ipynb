{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "finalSVD123RedditPolarityMethod1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gruntrexpewrus/StatLearnTeam/blob/master/which_is_the_best.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyD2FiBmVd15",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "41105aeb-08f7-40d4-f4d8-7d2120c4ee30"
      },
      "source": [
        "from nltk.stem.snowball import ItalianStemmer\n",
        "from nltk import RegexpTokenizer\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRWufpvpNf8h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "181dc20f-bb31-4706-d6a6-09d6c33fbcf9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymwVRjARXBao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stopwords = nltk.corpus.stopwords.words(\"italian\")\n",
        "def process_text(text):\n",
        "  to_return = [ItalianStemmer().stem(x) for x in RegexpTokenizer(r\"\\w+\").tokenize(text) if not x in stopwords]\n",
        "  #return (\" \".join(to_return))\n",
        "  return to_return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw6VcKIMXE49",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f620b1ff-00e5-4abc-c56b-6700c2170a50"
      },
      "source": [
        "process_text('La Connessione di Nina fa schifo.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['la', 'connession', 'nin', 'fa', 'schif']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tMNL1eKX3Op",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cB58IlhgXMDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wikineutral = pd.read_csv('/content/drive/My Drive/Topic detection/wiki_topics.csv', index_col = 0 , sep = \"\\t\", encoding = \"utf-8\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HffG3dcY-bn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e75c2fc6-0149-4e42-9957-17f6b7a3b82f"
      },
      "source": [
        "wikineutral.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(354, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBvYaTSbX5ME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wikineutral.drop(wikineutral.tail(200).index, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSi-tC0cZOzu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a661922a-408c-44bf-c7a8-62576aaaf799"
      },
      "source": [
        "wikineutral.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(154, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdlVQiN4ZSrw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bd9fb0cc-9d96-48e0-b40c-f17bf65bd9a4"
      },
      "source": [
        "wikineutral.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(154, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njiW0kkGZVQJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "3b849684-81b0-4976-ba95-16ad1f6033f1"
      },
      "source": [
        "wikineutral.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Arte e cultura</td>\n",
              "      <td>Coordinate: 45°22′02.71″N 10°13′15.84″E﻿ / ﻿45...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Arte e cultura</td>\n",
              "      <td>Coordinate: 43°34′38.28″N 11°14′51″E﻿ / ﻿43.57...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Arte e cultura</td>\n",
              "      <td>Voci principali: Architettura del Settecento, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Arte e cultura</td>\n",
              "      <td>Coordinate: 45°26′24.29″N 10°59′19.71″E﻿ / ﻿45...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Arte e cultura</td>\n",
              "      <td>Coordinate: 45°26′20″N 10°59′40″E﻿ / ﻿45.43888...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Topic                                               Text\n",
              "0  Arte e cultura  Coordinate: 45°22′02.71″N 10°13′15.84″E﻿ / ﻿45...\n",
              "1  Arte e cultura  Coordinate: 43°34′38.28″N 11°14′51″E﻿ / ﻿43.57...\n",
              "2  Arte e cultura  Voci principali: Architettura del Settecento, ...\n",
              "3  Arte e cultura  Coordinate: 45°26′24.29″N 10°59′19.71″E﻿ / ﻿45...\n",
              "4  Arte e cultura  Coordinate: 45°26′20″N 10°59′40″E﻿ / ﻿45.43888..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK7x8LLoZW6i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wikineutral.drop(['Topic'], axis = 1,  inplace = True)\n",
        "wikineutral['Sentiment'] = 'neutral'\n",
        "\n",
        "wikineutral.to_csv('/content/drive/My Drive/Topic detection/Wikineutral.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3R5MVUT3Z32E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "97deef49-be2b-4dde-f522-56a9a32819be"
      },
      "source": [
        "wikineutral.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Coordinate: 45°22′02.71″N 10°13′15.84″E﻿ / ﻿45...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Coordinate: 43°34′38.28″N 11°14′51″E﻿ / ﻿43.57...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Voci principali: Architettura del Settecento, ...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Coordinate: 45°26′24.29″N 10°59′19.71″E﻿ / ﻿45...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Coordinate: 45°26′20″N 10°59′40″E﻿ / ﻿45.43888...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text Sentiment\n",
              "0  Coordinate: 45°22′02.71″N 10°13′15.84″E﻿ / ﻿45...   neutral\n",
              "1  Coordinate: 43°34′38.28″N 11°14′51″E﻿ / ﻿43.57...   neutral\n",
              "2  Voci principali: Architettura del Settecento, ...   neutral\n",
              "3  Coordinate: 45°26′24.29″N 10°59′19.71″E﻿ / ﻿45...   neutral\n",
              "4  Coordinate: 45°26′20″N 10°59′40″E﻿ / ﻿45.43888...   neutral"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ze8raciaC84",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "a01d4dd8-e52e-4b11-d5a3-a54ec052cdf5"
      },
      "source": [
        "Amazonrewiews = pd.read_csv('/content/drive/My Drive/Topic detection/TrainDataSentiment.csv', index_col = 0 )\n",
        "Amazonrewiews.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ho acquistato questa confezione di mascherine ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Attenzione, ha un ferretto nasale in plastica ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>La confezione di cartone era già aperta, appen...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mascherine vendute come \"Maschera Chirurgica 3...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ARRIVATO APERTO PESSIMO PRODOTTO</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content  rating\n",
              "0  Ho acquistato questa confezione di mascherine ...       4\n",
              "1  Attenzione, ha un ferretto nasale in plastica ...       1\n",
              "2  La confezione di cartone era già aperta, appen...       1\n",
              "3  Mascherine vendute come \"Maschera Chirurgica 3...       1\n",
              "4                   ARRIVATO APERTO PESSIMO PRODOTTO       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XD3f6vaFbQI1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "4b5cd519-d9f2-48ae-bef8-f5fb9e9dd9ad"
      },
      "source": [
        "Amazonrewiews['rating'] = Amazonrewiews['rating'].map({5: 'positive', 4: 'positive', 1:'negative', 2:'negative',3:'negative' })\n",
        "Ama = Amazonrewiews.rename(columns={'content': 'Text', 'rating': 'Sentiment' })\n",
        "Ama.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ho acquistato questa confezione di mascherine ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Attenzione, ha un ferretto nasale in plastica ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>La confezione di cartone era già aperta, appen...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mascherine vendute come \"Maschera Chirurgica 3...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ARRIVATO APERTO PESSIMO PRODOTTO</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text Sentiment\n",
              "0  Ho acquistato questa confezione di mascherine ...  positive\n",
              "1  Attenzione, ha un ferretto nasale in plastica ...  negative\n",
              "2  La confezione di cartone era già aperta, appen...  negative\n",
              "3  Mascherine vendute come \"Maschera Chirurgica 3...  negative\n",
              "4                   ARRIVATO APERTO PESSIMO PRODOTTO  negative"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcPmtvy4iDcQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "bd58cc40-f6da-4810-e799-455ec08f7e54"
      },
      "source": [
        "Ama.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ho acquistato questa confezione di mascherine ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Attenzione, ha un ferretto nasale in plastica ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>La confezione di cartone era già aperta, appen...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mascherine vendute come \"Maschera Chirurgica 3...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ARRIVATO APERTO PESSIMO PRODOTTO</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text Sentiment\n",
              "0  Ho acquistato questa confezione di mascherine ...  positive\n",
              "1  Attenzione, ha un ferretto nasale in plastica ...  negative\n",
              "2  La confezione di cartone era già aperta, appen...  negative\n",
              "3  Mascherine vendute come \"Maschera Chirurgica 3...  negative\n",
              "4                   ARRIVATO APERTO PESSIMO PRODOTTO  negative"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vt6uIND8iQlY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d68298b6-c5cb-45e0-90ae-0f440758cca8"
      },
      "source": [
        "Ama['Sentiment'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'positive'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd-owvtgiVFP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "89824aa8-01da-40d9-d0e0-90f94313c447"
      },
      "source": [
        "wikineutral['Sentiment'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'neutral'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZUBFN0siENu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "f167de06-a538-458e-8c8c-94ce569e7de3"
      },
      "source": [
        "wikineutral.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Coordinate: 45°22′02.71″N 10°13′15.84″E﻿ / ﻿45...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Coordinate: 43°34′38.28″N 11°14′51″E﻿ / ﻿43.57...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Voci principali: Architettura del Settecento, ...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Coordinate: 45°26′24.29″N 10°59′19.71″E﻿ / ﻿45...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Coordinate: 45°26′20″N 10°59′40″E﻿ / ﻿45.43888...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text Sentiment\n",
              "0  Coordinate: 45°22′02.71″N 10°13′15.84″E﻿ / ﻿45...   neutral\n",
              "1  Coordinate: 43°34′38.28″N 11°14′51″E﻿ / ﻿43.57...   neutral\n",
              "2  Voci principali: Architettura del Settecento, ...   neutral\n",
              "3  Coordinate: 45°26′24.29″N 10°59′19.71″E﻿ / ﻿45...   neutral\n",
              "4  Coordinate: 45°26′20″N 10°59′40″E﻿ / ﻿45.43888...   neutral"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po42rWt5iEQQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "38757bac-d41a-4178-b0bd-f55ec450b509"
      },
      "source": [
        "Ama.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(460, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xMojTW_iESr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "18b1f48d-fb53-4720-b428-ddec3c9f6b09"
      },
      "source": [
        "wikineutral.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(154, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRbOAyF-iEU2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmW7NNCLaQTP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TrainData = pd.concat([Ama, wikineutral], ignore_index = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mYwXStWcZZw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "415ccafe-a7ea-4fa8-b1ab-cfd013a666fb"
      },
      "source": [
        "TrainData.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ho acquistato questa confezione di mascherine ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Attenzione, ha un ferretto nasale in plastica ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>La confezione di cartone era già aperta, appen...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mascherine vendute come \"Maschera Chirurgica 3...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ARRIVATO APERTO PESSIMO PRODOTTO</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text Sentiment\n",
              "0  Ho acquistato questa confezione di mascherine ...  positive\n",
              "1  Attenzione, ha un ferretto nasale in plastica ...  negative\n",
              "2  La confezione di cartone era già aperta, appen...  negative\n",
              "3  Mascherine vendute come \"Maschera Chirurgica 3...  negative\n",
              "4                   ARRIVATO APERTO PESSIMO PRODOTTO  negative"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCDvNHkecpdK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c62ff833-1c86-475a-b764-b17eeacdf2be"
      },
      "source": [
        "TrainData.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(614, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y97xw_SpcrsW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TrainData.to_csv('/content/drive/My Drive/Topic detection/TrainData4SentimentLeoandNigna.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "megW-DfFc1zY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "2ab93822-d4f4-44fa-85d1-beffd86dd966"
      },
      "source": [
        "TrainData = pd.read_csv('/content/drive/My Drive/Topic detection/TrainData4SentimentLeoandNigna.csv', index_col = 0 )\n",
        "TrainData.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ho acquistato questa confezione di mascherine ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Attenzione, ha un ferretto nasale in plastica ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>La confezione di cartone era già aperta, appen...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mascherine vendute come \"Maschera Chirurgica 3...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ARRIVATO APERTO PESSIMO PRODOTTO</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text Sentiment\n",
              "0  Ho acquistato questa confezione di mascherine ...  positive\n",
              "1  Attenzione, ha un ferretto nasale in plastica ...  negative\n",
              "2  La confezione di cartone era già aperta, appen...  negative\n",
              "3  Mascherine vendute come \"Maschera Chirurgica 3...  negative\n",
              "4                   ARRIVATO APERTO PESSIMO PRODOTTO  negative"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVhqLLP7mNI8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a97ef5aa-1ee4-4a0b-a2d5-ba5a9860da25"
      },
      "source": [
        "TrainData = TrainData.dropna()\n",
        "tokenized_data = []\n",
        "from tqdm import tqdm \n",
        "for index in tqdm(range(len(TrainData))):\n",
        "  tokenized_data.append(\" \".join(process_text(TrainData.iloc[index][\"Text\"])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 613/613 [00:21<00:00, 29.09it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwjoRO_7po63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TrainData[\"Processed Text\"] = tokenized_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsv2ar2kp9LC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "e0bbca94-5acd-4eb8-df90-dc6dafd22ec0"
      },
      "source": [
        "TrainData.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Processed Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ho acquistato questa confezione di mascherine ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>ho acquist confezion mascherin 19 99 quind 40 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Attenzione, ha un ferretto nasale in plastica ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>attenzion ferrett nasal plastic permett far ad...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>La confezione di cartone era già aperta, appen...</td>\n",
              "      <td>negative</td>\n",
              "      <td>la confezion carton già apert appen pres lat t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mascherine vendute come \"Maschera Chirurgica 3...</td>\n",
              "      <td>negative</td>\n",
              "      <td>mascherin vend mascher chirurg 3p tip iir conf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ARRIVATO APERTO PESSIMO PRODOTTO</td>\n",
              "      <td>negative</td>\n",
              "      <td>arriv apert pessim prodott</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  ...                                     Processed Text\n",
              "0  Ho acquistato questa confezione di mascherine ...  ...  ho acquist confezion mascherin 19 99 quind 40 ...\n",
              "1  Attenzione, ha un ferretto nasale in plastica ...  ...  attenzion ferrett nasal plastic permett far ad...\n",
              "2  La confezione di cartone era già aperta, appen...  ...  la confezion carton già apert appen pres lat t...\n",
              "3  Mascherine vendute come \"Maschera Chirurgica 3...  ...  mascherin vend mascher chirurg 3p tip iir conf...\n",
              "4                   ARRIVATO APERTO PESSIMO PRODOTTO  ...                         arriv apert pessim prodott\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRwPGmCLq21Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TrainData.to_csv('/content/drive/My Drive/Topic detection/ProcessedTrainData4SentimentLeoandNigna.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9tRxudbrlMg",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7H098QYrn0F",
        "colab_type": "text"
      },
      "source": [
        "## Let's create the tftidf model\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L79g86mS5XWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TrainData = pd.read_csv('/content/drive/My Drive/Topic detection/ProcessedTrainData4SentimentLeoandNigna.csv', index_col = 0 )"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o90sCSU8wawh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "bc2f3716-c334-4263-a796-0ccda74fd508"
      },
      "source": [
        "TrainData.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Processed Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ho acquistato questa confezione di mascherine ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>ho acquist confezion mascherin 19 99 quind 40 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Attenzione, ha un ferretto nasale in plastica ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>attenzion ferrett nasal plastic permett far ad...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>La confezione di cartone era già aperta, appen...</td>\n",
              "      <td>negative</td>\n",
              "      <td>la confezion carton già apert appen pres lat t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mascherine vendute come \"Maschera Chirurgica 3...</td>\n",
              "      <td>negative</td>\n",
              "      <td>mascherin vend mascher chirurg 3p tip iir conf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ARRIVATO APERTO PESSIMO PRODOTTO</td>\n",
              "      <td>negative</td>\n",
              "      <td>arriv apert pessim prodott</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  ...                                     Processed Text\n",
              "0  Ho acquistato questa confezione di mascherine ...  ...  ho acquist confezion mascherin 19 99 quind 40 ...\n",
              "1  Attenzione, ha un ferretto nasale in plastica ...  ...  attenzion ferrett nasal plastic permett far ad...\n",
              "2  La confezione di cartone era già aperta, appen...  ...  la confezion carton già apert appen pres lat t...\n",
              "3  Mascherine vendute come \"Maschera Chirurgica 3...  ...  mascherin vend mascher chirurg 3p tip iir conf...\n",
              "4                   ARRIVATO APERTO PESSIMO PRODOTTO  ...                         arriv apert pessim prodott\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTN3VDCawv6b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4b71d439-c064-4461-e409-90c522b147f9"
      },
      "source": [
        "for i in Y:\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.44943642 0.         0.6316672  0.6316672  0.        ]\n",
            "[0.89553242 0.31465989 0.         0.         0.31465989]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAKV_wxRxbk0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TrainList = TrainData['Processed Text'].tolist()"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vto3x_hb4E0y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "aae15f7d-3081-4638-8376-5e602ca7ce01"
      },
      "source": [
        "TrainList[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ho acquist confezion mascherin 19 99 quind 40 centesim mascherin prezz somm onest la qualit mascherin avvis discret prov altre consistt indubb maggior risult tatt morbid spess nell confezion present certific cines attest tipolog iir gli elast manteng molt ben già utilizz 5 senz nessun problem ven difett essenzial due 1 mascherin chius scatol senz imball isol nessun plastic protezion 2 ferrett string nas sembr esser metall quind pieg ben senz raggiung chiusur massim'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxCNCMILxkun",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d50e9b50-0c84-4970-ee0b-c0d707b89b19"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(TrainList)\n",
        "\n",
        "X #Matrix with each row TfIdf"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<613x38013 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 267849 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtaowPYY3cW_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import joblib\n",
        "joblib.dump( vectorizer, '/content/drive/My Drive/Topic detection/Vectorizer.pkl')\n",
        "\n",
        "vectorizer_loaded = joblib.load('/content/drive/My Drive/Topic detection/Vectorizer.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTVa9N202EZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SVD in 100/200/300 components"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVYNVo3czSYH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "from scipy.sparse import random as sparse_random\n",
        "from sklearn.random_projection import sparse_random_matrix\n",
        "import joblib\n",
        "comps = [100, 200, 300]\n",
        "def Svd(comps):\n",
        "  SVDMatrices = []\n",
        "  for i in comps:\n",
        "    svd = TruncatedSVD(n_components=i, n_iter=7, random_state=42)\n",
        "    a = svd.fit_transform(X)\n",
        "    SVDMatrices.append(a)\n",
        "    joblib.dump( svd, '/content/drive/My Drive/Topic detection/SVD'+str(i)+'.pkl')\n",
        "    print(comps, svd.explained_variance_ratio_.sum())\n",
        "  return (SVDMatrices)\n",
        "#print(svd.explained_variance_ratio_)\n",
        "\n",
        "\n",
        "\n",
        "#print(svd.singular_values_) A = USV^t S singular matrix (x0000000\n",
        "                                                      #      0y00000000000000000)\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECk2j9l663Cc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e8c4ec21-1e65-46f3-d1a1-880a2c32242f"
      },
      "source": [
        "SVDMatrices = Svd(comps)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[100, 200, 300] 0.9430592092080162\n",
            "[100, 200, 300] 0.9989350597501335\n",
            "[100, 200, 300] 0.9999170949846715\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8aOUO4X7zxi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fbe1202f-75e2-43bb-91f6-fc5a40c82ca6"
      },
      "source": [
        "#len(SVDMatrices[0][0][612])\n",
        "len(SVDMatrices[0])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "613"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOf_TrRrzSkT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def namescreator(matrices = SVDMatrices):\n",
        "  names = []\n",
        " # print(len(names))\n",
        "  for j in range(0,len(matrices)):\n",
        "      names.append([])\n",
        "  for i in range(len(matrices)):\n",
        "   #   print(i)\n",
        "     # print(len(matrices[i]))\n",
        "      ln = len(matrices[i][0])\n",
        "     # print(ln)\n",
        "     # print(names)\n",
        "      temp = []\n",
        "      for j in range(0,len(matrices[i][0])):\n",
        "         temp.append([])\n",
        "      print(len(temp))\n",
        "      for position in range(len(matrices[i][0])):\n",
        "       # print(position)\n",
        "        for row in range(613):\n",
        "       #  print(a[position][col])\n",
        "        # print(range(ln-1))\n",
        "         temp[position].append(matrices[i][row][position])\n",
        "      for k in temp:\n",
        "       names[i].append(k)\n",
        "\n",
        "  return names\n",
        "#print(len(a[0]))"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFPxxCeDYolR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "81716321-674a-4baa-a830-bf333d2db92b"
      },
      "source": [
        "ttry = namescreator([SVDMatrices[1]])\n",
        "len(ttry[0])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqsdeGz5_BWv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "52f5846a-796c-4e82-ce2a-69e17621e3b2"
      },
      "source": [
        "len(ttry)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qlon5LhcY7zl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = []\n",
        "for i in range(3):\n",
        "  l.append([])\n",
        "for i in range(1,101):\n",
        "    l[0].append('feat'+str(i))\n",
        "for i in range(1,201):\n",
        "    l[1].append('feat'+str(i))\n",
        "for i in range(1,301):\n",
        "    l[2].append('feat'+str(i))"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpCIruC0Y72L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5d6d3f75-0ff4-4f89-818c-8682b1743f58"
      },
      "source": [
        "len(l[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_hsfzxMY74W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#I have a list with 3 components and in every one 100/200/300 columns\n",
        "#I have a set of names\n",
        "df100 = TrainData.copy()\n",
        "df200 = TrainData.copy()\n",
        "df300 = TrainData.copy()"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYPIIg2HF5jM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def datafinal(l, a2, df):\n",
        "  j = 0\n",
        "  for i in l:\n",
        "  #  print(len(a2[j]))\n",
        "    df[i]= a2[j]\n",
        "    j = j+1\n",
        "  return df"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSCEeXheGMA2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "outputId": "5f80fda9-5b02-4bcb-c38b-c808eda3638b"
      },
      "source": [
        "df100 = datafinal(l[0], namescreator([SVDMatrices[0]])[0], df100 )\n",
        "df200 = datafinal(l[1], namescreator([SVDMatrices[1]])[0], df200 )\n",
        "df300 = datafinal(l[2], namescreator([SVDMatrices[2]])[0], df300 )\n",
        "\n",
        "df100.to_csv('/content/drive/My Drive/Topic detection/Df_count_100.csv')\n",
        "df200.to_csv('/content/drive/My Drive/Topic detection/Df_count_200.csv')\n",
        "df300.to_csv('/content/drive/My Drive/Topic detection/Df_count_300.csv')\n",
        "df100.head()\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n",
            "200\n",
            "300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Processed Text</th>\n",
              "      <th>feat1</th>\n",
              "      <th>feat2</th>\n",
              "      <th>feat3</th>\n",
              "      <th>feat4</th>\n",
              "      <th>feat5</th>\n",
              "      <th>feat6</th>\n",
              "      <th>feat7</th>\n",
              "      <th>feat8</th>\n",
              "      <th>feat9</th>\n",
              "      <th>feat10</th>\n",
              "      <th>feat11</th>\n",
              "      <th>feat12</th>\n",
              "      <th>feat13</th>\n",
              "      <th>feat14</th>\n",
              "      <th>feat15</th>\n",
              "      <th>feat16</th>\n",
              "      <th>feat17</th>\n",
              "      <th>feat18</th>\n",
              "      <th>feat19</th>\n",
              "      <th>feat20</th>\n",
              "      <th>feat21</th>\n",
              "      <th>feat22</th>\n",
              "      <th>feat23</th>\n",
              "      <th>feat24</th>\n",
              "      <th>feat25</th>\n",
              "      <th>feat26</th>\n",
              "      <th>feat27</th>\n",
              "      <th>feat28</th>\n",
              "      <th>feat29</th>\n",
              "      <th>feat30</th>\n",
              "      <th>feat31</th>\n",
              "      <th>feat32</th>\n",
              "      <th>feat33</th>\n",
              "      <th>feat34</th>\n",
              "      <th>feat35</th>\n",
              "      <th>feat36</th>\n",
              "      <th>feat37</th>\n",
              "      <th>...</th>\n",
              "      <th>feat61</th>\n",
              "      <th>feat62</th>\n",
              "      <th>feat63</th>\n",
              "      <th>feat64</th>\n",
              "      <th>feat65</th>\n",
              "      <th>feat66</th>\n",
              "      <th>feat67</th>\n",
              "      <th>feat68</th>\n",
              "      <th>feat69</th>\n",
              "      <th>feat70</th>\n",
              "      <th>feat71</th>\n",
              "      <th>feat72</th>\n",
              "      <th>feat73</th>\n",
              "      <th>feat74</th>\n",
              "      <th>feat75</th>\n",
              "      <th>feat76</th>\n",
              "      <th>feat77</th>\n",
              "      <th>feat78</th>\n",
              "      <th>feat79</th>\n",
              "      <th>feat80</th>\n",
              "      <th>feat81</th>\n",
              "      <th>feat82</th>\n",
              "      <th>feat83</th>\n",
              "      <th>feat84</th>\n",
              "      <th>feat85</th>\n",
              "      <th>feat86</th>\n",
              "      <th>feat87</th>\n",
              "      <th>feat88</th>\n",
              "      <th>feat89</th>\n",
              "      <th>feat90</th>\n",
              "      <th>feat91</th>\n",
              "      <th>feat92</th>\n",
              "      <th>feat93</th>\n",
              "      <th>feat94</th>\n",
              "      <th>feat95</th>\n",
              "      <th>feat96</th>\n",
              "      <th>feat97</th>\n",
              "      <th>feat98</th>\n",
              "      <th>feat99</th>\n",
              "      <th>feat100</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ho acquistato questa confezione di mascherine ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>ho acquist confezion mascherin 19 99 quind 40 ...</td>\n",
              "      <td>1.427502</td>\n",
              "      <td>-0.370022</td>\n",
              "      <td>-0.233726</td>\n",
              "      <td>0.252668</td>\n",
              "      <td>-0.055511</td>\n",
              "      <td>0.120081</td>\n",
              "      <td>0.113175</td>\n",
              "      <td>-0.183909</td>\n",
              "      <td>0.081472</td>\n",
              "      <td>0.053763</td>\n",
              "      <td>-0.084136</td>\n",
              "      <td>0.367972</td>\n",
              "      <td>0.198592</td>\n",
              "      <td>-0.130364</td>\n",
              "      <td>0.014773</td>\n",
              "      <td>0.204373</td>\n",
              "      <td>0.226742</td>\n",
              "      <td>-0.343141</td>\n",
              "      <td>-0.202350</td>\n",
              "      <td>-0.030855</td>\n",
              "      <td>-0.308528</td>\n",
              "      <td>-0.095435</td>\n",
              "      <td>-0.092722</td>\n",
              "      <td>0.071971</td>\n",
              "      <td>0.230464</td>\n",
              "      <td>-0.017840</td>\n",
              "      <td>0.005502</td>\n",
              "      <td>-0.033449</td>\n",
              "      <td>0.059802</td>\n",
              "      <td>-0.047421</td>\n",
              "      <td>0.384857</td>\n",
              "      <td>-0.087899</td>\n",
              "      <td>0.010465</td>\n",
              "      <td>-0.050799</td>\n",
              "      <td>-0.038882</td>\n",
              "      <td>-0.011152</td>\n",
              "      <td>-0.079164</td>\n",
              "      <td>...</td>\n",
              "      <td>0.041676</td>\n",
              "      <td>0.179925</td>\n",
              "      <td>0.003451</td>\n",
              "      <td>0.022776</td>\n",
              "      <td>-0.170455</td>\n",
              "      <td>0.103535</td>\n",
              "      <td>-0.072464</td>\n",
              "      <td>0.209546</td>\n",
              "      <td>-0.271023</td>\n",
              "      <td>-0.024815</td>\n",
              "      <td>-0.142619</td>\n",
              "      <td>-0.133407</td>\n",
              "      <td>-0.058681</td>\n",
              "      <td>0.361607</td>\n",
              "      <td>-0.257057</td>\n",
              "      <td>0.059104</td>\n",
              "      <td>-0.136282</td>\n",
              "      <td>0.009009</td>\n",
              "      <td>0.109203</td>\n",
              "      <td>-0.000459</td>\n",
              "      <td>0.198917</td>\n",
              "      <td>0.396337</td>\n",
              "      <td>0.046896</td>\n",
              "      <td>0.082224</td>\n",
              "      <td>-0.011540</td>\n",
              "      <td>0.063949</td>\n",
              "      <td>-0.095554</td>\n",
              "      <td>0.178738</td>\n",
              "      <td>-0.029847</td>\n",
              "      <td>0.056044</td>\n",
              "      <td>0.380342</td>\n",
              "      <td>-0.163314</td>\n",
              "      <td>0.157956</td>\n",
              "      <td>-0.086857</td>\n",
              "      <td>0.116819</td>\n",
              "      <td>0.157595</td>\n",
              "      <td>0.143719</td>\n",
              "      <td>-0.276645</td>\n",
              "      <td>0.172353</td>\n",
              "      <td>-0.003686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Attenzione, ha un ferretto nasale in plastica ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>attenzion ferrett nasal plastic permett far ad...</td>\n",
              "      <td>0.253651</td>\n",
              "      <td>-0.101982</td>\n",
              "      <td>-0.050235</td>\n",
              "      <td>0.003480</td>\n",
              "      <td>0.143325</td>\n",
              "      <td>0.082425</td>\n",
              "      <td>0.062176</td>\n",
              "      <td>-0.092046</td>\n",
              "      <td>0.016943</td>\n",
              "      <td>0.012091</td>\n",
              "      <td>-0.002194</td>\n",
              "      <td>0.054573</td>\n",
              "      <td>-0.049470</td>\n",
              "      <td>-0.128104</td>\n",
              "      <td>-0.099252</td>\n",
              "      <td>0.013316</td>\n",
              "      <td>0.004018</td>\n",
              "      <td>-0.022516</td>\n",
              "      <td>0.017719</td>\n",
              "      <td>0.011638</td>\n",
              "      <td>-0.076939</td>\n",
              "      <td>0.009712</td>\n",
              "      <td>0.006163</td>\n",
              "      <td>0.019075</td>\n",
              "      <td>0.048064</td>\n",
              "      <td>-0.073561</td>\n",
              "      <td>0.115640</td>\n",
              "      <td>-0.017993</td>\n",
              "      <td>0.030129</td>\n",
              "      <td>0.146818</td>\n",
              "      <td>-0.079095</td>\n",
              "      <td>-0.010895</td>\n",
              "      <td>-0.029244</td>\n",
              "      <td>0.014197</td>\n",
              "      <td>-0.046119</td>\n",
              "      <td>0.062291</td>\n",
              "      <td>-0.022305</td>\n",
              "      <td>...</td>\n",
              "      <td>0.025424</td>\n",
              "      <td>-0.060758</td>\n",
              "      <td>-0.030671</td>\n",
              "      <td>-0.007789</td>\n",
              "      <td>0.059872</td>\n",
              "      <td>0.090036</td>\n",
              "      <td>-0.016685</td>\n",
              "      <td>-0.006969</td>\n",
              "      <td>-0.034687</td>\n",
              "      <td>-0.093257</td>\n",
              "      <td>0.100818</td>\n",
              "      <td>-0.075917</td>\n",
              "      <td>0.009639</td>\n",
              "      <td>0.021281</td>\n",
              "      <td>-0.055811</td>\n",
              "      <td>0.038840</td>\n",
              "      <td>0.019450</td>\n",
              "      <td>-0.019292</td>\n",
              "      <td>0.128920</td>\n",
              "      <td>0.041976</td>\n",
              "      <td>0.025963</td>\n",
              "      <td>0.132659</td>\n",
              "      <td>0.024791</td>\n",
              "      <td>0.162403</td>\n",
              "      <td>-0.088455</td>\n",
              "      <td>-0.022426</td>\n",
              "      <td>0.086162</td>\n",
              "      <td>0.029144</td>\n",
              "      <td>0.001834</td>\n",
              "      <td>-0.082763</td>\n",
              "      <td>0.054588</td>\n",
              "      <td>0.023519</td>\n",
              "      <td>0.013995</td>\n",
              "      <td>0.078017</td>\n",
              "      <td>0.055800</td>\n",
              "      <td>-0.048837</td>\n",
              "      <td>-0.134814</td>\n",
              "      <td>-0.084424</td>\n",
              "      <td>0.000587</td>\n",
              "      <td>-0.023857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>La confezione di cartone era già aperta, appen...</td>\n",
              "      <td>negative</td>\n",
              "      <td>la confezion carton già apert appen pres lat t...</td>\n",
              "      <td>0.558062</td>\n",
              "      <td>-0.263552</td>\n",
              "      <td>-0.067233</td>\n",
              "      <td>0.067327</td>\n",
              "      <td>0.004616</td>\n",
              "      <td>0.156902</td>\n",
              "      <td>-0.120143</td>\n",
              "      <td>-0.099617</td>\n",
              "      <td>0.003482</td>\n",
              "      <td>0.009516</td>\n",
              "      <td>-0.021489</td>\n",
              "      <td>0.182076</td>\n",
              "      <td>0.112840</td>\n",
              "      <td>-0.090302</td>\n",
              "      <td>0.058019</td>\n",
              "      <td>0.009290</td>\n",
              "      <td>-0.099129</td>\n",
              "      <td>0.036877</td>\n",
              "      <td>-0.025316</td>\n",
              "      <td>-0.050083</td>\n",
              "      <td>-0.014155</td>\n",
              "      <td>0.101451</td>\n",
              "      <td>0.010536</td>\n",
              "      <td>0.096479</td>\n",
              "      <td>0.039429</td>\n",
              "      <td>0.059449</td>\n",
              "      <td>0.011060</td>\n",
              "      <td>0.030413</td>\n",
              "      <td>-0.066376</td>\n",
              "      <td>0.088273</td>\n",
              "      <td>0.305371</td>\n",
              "      <td>-0.030663</td>\n",
              "      <td>0.050772</td>\n",
              "      <td>-0.005288</td>\n",
              "      <td>-0.034873</td>\n",
              "      <td>-0.019671</td>\n",
              "      <td>-0.102220</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.118157</td>\n",
              "      <td>0.150951</td>\n",
              "      <td>0.006709</td>\n",
              "      <td>-0.036339</td>\n",
              "      <td>-0.027243</td>\n",
              "      <td>-0.055754</td>\n",
              "      <td>-0.077451</td>\n",
              "      <td>0.136845</td>\n",
              "      <td>-0.090835</td>\n",
              "      <td>0.098826</td>\n",
              "      <td>-0.049233</td>\n",
              "      <td>-0.067911</td>\n",
              "      <td>0.097297</td>\n",
              "      <td>-0.077203</td>\n",
              "      <td>-0.102887</td>\n",
              "      <td>-0.114337</td>\n",
              "      <td>-0.063928</td>\n",
              "      <td>0.107933</td>\n",
              "      <td>0.146414</td>\n",
              "      <td>0.013380</td>\n",
              "      <td>-0.087249</td>\n",
              "      <td>0.153794</td>\n",
              "      <td>0.022386</td>\n",
              "      <td>0.053159</td>\n",
              "      <td>-0.003084</td>\n",
              "      <td>-0.047596</td>\n",
              "      <td>-0.101165</td>\n",
              "      <td>0.014303</td>\n",
              "      <td>-0.125361</td>\n",
              "      <td>0.118699</td>\n",
              "      <td>0.002491</td>\n",
              "      <td>-0.108951</td>\n",
              "      <td>0.102431</td>\n",
              "      <td>-0.113705</td>\n",
              "      <td>0.048516</td>\n",
              "      <td>0.103985</td>\n",
              "      <td>-0.018513</td>\n",
              "      <td>0.037103</td>\n",
              "      <td>0.003996</td>\n",
              "      <td>-0.014728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mascherine vendute come \"Maschera Chirurgica 3...</td>\n",
              "      <td>negative</td>\n",
              "      <td>mascherin vend mascher chirurg 3p tip iir conf...</td>\n",
              "      <td>0.146057</td>\n",
              "      <td>0.015998</td>\n",
              "      <td>-0.021300</td>\n",
              "      <td>0.013654</td>\n",
              "      <td>0.021744</td>\n",
              "      <td>0.025829</td>\n",
              "      <td>0.029140</td>\n",
              "      <td>-0.025965</td>\n",
              "      <td>-0.038590</td>\n",
              "      <td>0.002674</td>\n",
              "      <td>0.060834</td>\n",
              "      <td>-0.026196</td>\n",
              "      <td>-0.026958</td>\n",
              "      <td>-0.020989</td>\n",
              "      <td>0.037587</td>\n",
              "      <td>0.085977</td>\n",
              "      <td>0.036384</td>\n",
              "      <td>-0.018741</td>\n",
              "      <td>0.053406</td>\n",
              "      <td>0.017906</td>\n",
              "      <td>0.001444</td>\n",
              "      <td>-0.013342</td>\n",
              "      <td>0.023833</td>\n",
              "      <td>0.015540</td>\n",
              "      <td>0.056572</td>\n",
              "      <td>-0.029786</td>\n",
              "      <td>-0.020398</td>\n",
              "      <td>0.072504</td>\n",
              "      <td>-0.001220</td>\n",
              "      <td>0.049278</td>\n",
              "      <td>-0.053712</td>\n",
              "      <td>-0.034026</td>\n",
              "      <td>-0.060402</td>\n",
              "      <td>-0.007239</td>\n",
              "      <td>-0.015536</td>\n",
              "      <td>-0.047765</td>\n",
              "      <td>0.059908</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.031412</td>\n",
              "      <td>0.070387</td>\n",
              "      <td>-0.015629</td>\n",
              "      <td>0.034991</td>\n",
              "      <td>-0.002477</td>\n",
              "      <td>0.083350</td>\n",
              "      <td>-0.017332</td>\n",
              "      <td>0.076785</td>\n",
              "      <td>-0.002593</td>\n",
              "      <td>0.044577</td>\n",
              "      <td>0.016665</td>\n",
              "      <td>-0.011128</td>\n",
              "      <td>0.021278</td>\n",
              "      <td>0.064578</td>\n",
              "      <td>0.043263</td>\n",
              "      <td>0.021864</td>\n",
              "      <td>0.069986</td>\n",
              "      <td>0.057550</td>\n",
              "      <td>0.046754</td>\n",
              "      <td>-0.032904</td>\n",
              "      <td>-0.012983</td>\n",
              "      <td>0.016001</td>\n",
              "      <td>-0.088428</td>\n",
              "      <td>-0.001354</td>\n",
              "      <td>-0.007196</td>\n",
              "      <td>-0.045124</td>\n",
              "      <td>-0.015672</td>\n",
              "      <td>0.044223</td>\n",
              "      <td>0.032871</td>\n",
              "      <td>0.042419</td>\n",
              "      <td>-0.031617</td>\n",
              "      <td>-0.000809</td>\n",
              "      <td>0.030728</td>\n",
              "      <td>0.011788</td>\n",
              "      <td>0.007540</td>\n",
              "      <td>0.015882</td>\n",
              "      <td>0.031511</td>\n",
              "      <td>-0.088760</td>\n",
              "      <td>-0.018687</td>\n",
              "      <td>-0.057438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ARRIVATO APERTO PESSIMO PRODOTTO</td>\n",
              "      <td>negative</td>\n",
              "      <td>arriv apert pessim prodott</td>\n",
              "      <td>0.060384</td>\n",
              "      <td>0.009057</td>\n",
              "      <td>-0.048833</td>\n",
              "      <td>0.043948</td>\n",
              "      <td>-0.023049</td>\n",
              "      <td>-0.000548</td>\n",
              "      <td>0.012094</td>\n",
              "      <td>0.014758</td>\n",
              "      <td>-0.010317</td>\n",
              "      <td>-0.030742</td>\n",
              "      <td>0.017119</td>\n",
              "      <td>-0.050940</td>\n",
              "      <td>-0.021693</td>\n",
              "      <td>-0.018210</td>\n",
              "      <td>0.003045</td>\n",
              "      <td>0.010558</td>\n",
              "      <td>-0.016423</td>\n",
              "      <td>0.016314</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.029436</td>\n",
              "      <td>0.005904</td>\n",
              "      <td>-0.062605</td>\n",
              "      <td>-0.036312</td>\n",
              "      <td>0.021830</td>\n",
              "      <td>0.078280</td>\n",
              "      <td>-0.044851</td>\n",
              "      <td>-0.024077</td>\n",
              "      <td>-0.024032</td>\n",
              "      <td>-0.016400</td>\n",
              "      <td>0.042238</td>\n",
              "      <td>0.055118</td>\n",
              "      <td>-0.003369</td>\n",
              "      <td>-0.012976</td>\n",
              "      <td>0.031376</td>\n",
              "      <td>-0.008344</td>\n",
              "      <td>0.039710</td>\n",
              "      <td>0.001095</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.025365</td>\n",
              "      <td>0.005858</td>\n",
              "      <td>-0.048971</td>\n",
              "      <td>-0.006500</td>\n",
              "      <td>-0.002841</td>\n",
              "      <td>0.021159</td>\n",
              "      <td>-0.035646</td>\n",
              "      <td>0.031215</td>\n",
              "      <td>-0.027502</td>\n",
              "      <td>0.018756</td>\n",
              "      <td>-0.016228</td>\n",
              "      <td>0.011525</td>\n",
              "      <td>-0.012032</td>\n",
              "      <td>0.012244</td>\n",
              "      <td>-0.014562</td>\n",
              "      <td>0.012718</td>\n",
              "      <td>-0.045203</td>\n",
              "      <td>0.013055</td>\n",
              "      <td>0.008563</td>\n",
              "      <td>-0.025577</td>\n",
              "      <td>0.021934</td>\n",
              "      <td>0.030754</td>\n",
              "      <td>-0.044975</td>\n",
              "      <td>-0.012444</td>\n",
              "      <td>-0.048695</td>\n",
              "      <td>0.024991</td>\n",
              "      <td>0.012814</td>\n",
              "      <td>0.013912</td>\n",
              "      <td>0.042675</td>\n",
              "      <td>0.038654</td>\n",
              "      <td>-0.048908</td>\n",
              "      <td>-0.037750</td>\n",
              "      <td>0.014132</td>\n",
              "      <td>0.001977</td>\n",
              "      <td>0.083843</td>\n",
              "      <td>-0.047450</td>\n",
              "      <td>-0.066161</td>\n",
              "      <td>-0.087423</td>\n",
              "      <td>-0.058479</td>\n",
              "      <td>-0.044963</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 103 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  ...   feat100\n",
              "0  Ho acquistato questa confezione di mascherine ...  ... -0.003686\n",
              "1  Attenzione, ha un ferretto nasale in plastica ...  ... -0.023857\n",
              "2  La confezione di cartone era già aperta, appen...  ... -0.014728\n",
              "3  Mascherine vendute come \"Maschera Chirurgica 3...  ... -0.057438\n",
              "4                   ARRIVATO APERTO PESSIMO PRODOTTO  ... -0.044963\n",
              "\n",
              "[5 rows x 103 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU62kCZSIKtF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "45f2fcb8-96d6-4a8a-82b2-f1ebbfcf83b4"
      },
      "source": [
        "len(df300.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "303"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 272
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrFG0pvOHwqW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "a8677224-f9b5-4aa6-f9dc-0e16fdcb02e5"
      },
      "source": [
        "df100.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Processed Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ho acquistato questa confezione di mascherine ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>ho acquist confezion mascherin 19 99 quind 40 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Attenzione, ha un ferretto nasale in plastica ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>attenzion ferrett nasal plastic permett far ad...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>La confezione di cartone era già aperta, appen...</td>\n",
              "      <td>negative</td>\n",
              "      <td>la confezion carton già apert appen pres lat t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mascherine vendute come \"Maschera Chirurgica 3...</td>\n",
              "      <td>negative</td>\n",
              "      <td>mascherin vend mascher chirurg 3p tip iir conf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ARRIVATO APERTO PESSIMO PRODOTTO</td>\n",
              "      <td>negative</td>\n",
              "      <td>arriv apert pessim prodott</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  ...                                     Processed Text\n",
              "0  Ho acquistato questa confezione di mascherine ...  ...  ho acquist confezion mascherin 19 99 quind 40 ...\n",
              "1  Attenzione, ha un ferretto nasale in plastica ...  ...  attenzion ferrett nasal plastic permett far ad...\n",
              "2  La confezione di cartone era già aperta, appen...  ...  la confezion carton già apert appen pres lat t...\n",
              "3  Mascherine vendute come \"Maschera Chirurgica 3...  ...  mascherin vend mascher chirurg 3p tip iir conf...\n",
              "4                   ARRIVATO APERTO PESSIMO PRODOTTO  ...                         arriv apert pessim prodott\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_D0VmFQFGMDO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7b0bc8fc-b682-47f6-896f-5c32e3beed1b"
      },
      "source": [
        "len(l[0])\n",
        "len(namescreator([SVDMatrices[0]])[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIRayp4DGMGV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFFTfgevGMLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJvJ2bA3GMNs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-20L6VTGMI5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jc6s9Uz7Y77K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "ff3d67fe-429b-4c57-a4c0-21bbca5c162e"
      },
      "source": [
        "df1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Processed Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ho acquistato questa confezione di mascherine ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>ho acquist confezion mascherin 19 99 quind 40 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Attenzione, ha un ferretto nasale in plastica ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>attenzion ferrett nasal plastic permett far ad...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>La confezione di cartone era già aperta, appen...</td>\n",
              "      <td>negative</td>\n",
              "      <td>la confezion carton già apert appen pres lat t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mascherine vendute come \"Maschera Chirurgica 3...</td>\n",
              "      <td>negative</td>\n",
              "      <td>mascherin vend mascher chirurg 3p tip iir conf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ARRIVATO APERTO PESSIMO PRODOTTO</td>\n",
              "      <td>negative</td>\n",
              "      <td>arriv apert pessim prodott</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>608</th>\n",
              "      <td>Coordinate:  06h 23m 57.109s, -52° 41′ 44.378″...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>coordin 06h 23m 57 109s 52 41 44 378 canop afi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>610</th>\n",
              "      <td>La Cometa Hyakutake (pronuncia giapponese: [ça...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>la comet hyakutak pronunc giappones çakɯtak de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>611</th>\n",
              "      <td>La cometa Shoemaker-Levy 9 (formalmente design...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>la comet shoemaker levy 9 formal design 1993e ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>612</th>\n",
              "      <td>Coordinate:  20h 20m 00s, +40° 00′ 00″\\n\\tIl C...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>coordin 20h 20m 00s 40 00 00 il compless nebul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>613</th>\n",
              "      <td>Coordinate:  22h 00m 00s, +60° 00′ 00″\\n\\tIl c...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>coordin 22h 00m 00s 60 00 00 il compless nebul...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>613 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Text  ...                                     Processed Text\n",
              "0    Ho acquistato questa confezione di mascherine ...  ...  ho acquist confezion mascherin 19 99 quind 40 ...\n",
              "1    Attenzione, ha un ferretto nasale in plastica ...  ...  attenzion ferrett nasal plastic permett far ad...\n",
              "2    La confezione di cartone era già aperta, appen...  ...  la confezion carton già apert appen pres lat t...\n",
              "3    Mascherine vendute come \"Maschera Chirurgica 3...  ...  mascherin vend mascher chirurg 3p tip iir conf...\n",
              "4                     ARRIVATO APERTO PESSIMO PRODOTTO  ...                         arriv apert pessim prodott\n",
              "..                                                 ...  ...                                                ...\n",
              "608  Coordinate:  06h 23m 57.109s, -52° 41′ 44.378″...  ...  coordin 06h 23m 57 109s 52 41 44 378 canop afi...\n",
              "610  La Cometa Hyakutake (pronuncia giapponese: [ça...  ...  la comet hyakutak pronunc giappones çakɯtak de...\n",
              "611  La cometa Shoemaker-Levy 9 (formalmente design...  ...  la comet shoemaker levy 9 formal design 1993e ...\n",
              "612  Coordinate:  20h 20m 00s, +40° 00′ 00″\\n\\tIl C...  ...  coordin 20h 20m 00s 40 00 00 il compless nebul...\n",
              "613  Coordinate:  22h 00m 00s, +60° 00′ 00″\\n\\tIl c...  ...  coordin 22h 00m 00s 60 00 00 il compless nebul...\n",
              "\n",
              "[613 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnEtkjEuGLCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iynYgzsqx39W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "96ea3c07-c830-4e96-98a3-dbc296297306"
      },
      "source": [
        "print(len(vectorizer.get_feature_names()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65508\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gpyqcb7-1Yjz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ff = a.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWgJUwdg1pK2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8d94f294-3e0e-40f9-b6c8-38a5c5cdc4d5"
      },
      "source": [
        "len(ff[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBoTIj82x68x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TrainData['TfIdfVectors'] = ff"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmXK0o04yJEn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "c059bb52-6124-4918-906f-7e69dfe6a5f6"
      },
      "source": [
        "TrainData['TfIdfVectors']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      [0.27247792065239457, 0.21972266346699976, 0.0...\n",
              "1      [0.16908623342662926, 0.09757413226524703, -0....\n",
              "2      [0.21797217894206228, 0.12299623105572668, 0.0...\n",
              "3      [0.07175741115385922, 0.03131215810517044, 0.0...\n",
              "4      [0.024622949971823467, 0.07720488916191945, 0....\n",
              "                             ...                        \n",
              "608    [0.54536226007737, -0.1105415812214581, -0.009...\n",
              "610    [0.4892127369919711, -0.10012123633633806, -0....\n",
              "611    [0.546481097862738, -0.12618325455039198, 0.01...\n",
              "612    [0.6077005403740513, -0.11272059821801586, 0.0...\n",
              "613    [0.60099227243804, -0.13276656037670811, 0.010...\n",
              "Name: TfIdfVectors, Length: 613, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Kc3VPgFZKwq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "a4d12f34-2100-4cb2-c828-82d415433844"
      },
      "source": [
        "TrainData"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Processed Text</th>\n",
              "      <th>TfIdfVectors</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ho acquistato questa confezione di mascherine ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>ho acquist confezion mascherin 19 99 quind 40 ...</td>\n",
              "      <td>[0.27247792065239457, 0.21972266346699976, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Attenzione, ha un ferretto nasale in plastica ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>attenzion ferrett nasal plastic permett far ad...</td>\n",
              "      <td>[0.16908623342662926, 0.09757413226524703, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>La confezione di cartone era già aperta, appen...</td>\n",
              "      <td>negative</td>\n",
              "      <td>la confezion carton già apert appen pres lat t...</td>\n",
              "      <td>[0.21797217894206228, 0.12299623105572668, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mascherine vendute come \"Maschera Chirurgica 3...</td>\n",
              "      <td>negative</td>\n",
              "      <td>mascherin vend mascher chirurg 3p tip iir conf...</td>\n",
              "      <td>[0.07175741115385922, 0.03131215810517044, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ARRIVATO APERTO PESSIMO PRODOTTO</td>\n",
              "      <td>negative</td>\n",
              "      <td>arriv apert pessim prodott</td>\n",
              "      <td>[0.024622949971823467, 0.07720488916191945, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>608</th>\n",
              "      <td>Coordinate:  06h 23m 57.109s, -52° 41′ 44.378″...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>coordin 06h 23m 57 109s 52 41 44 378 canop afi...</td>\n",
              "      <td>[0.54536226007737, -0.1105415812214581, -0.009...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>610</th>\n",
              "      <td>La Cometa Hyakutake (pronuncia giapponese: [ça...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>la comet hyakutak pronunc giappones çakɯtak de...</td>\n",
              "      <td>[0.4892127369919711, -0.10012123633633806, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>611</th>\n",
              "      <td>La cometa Shoemaker-Levy 9 (formalmente design...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>la comet shoemaker levy 9 formal design 1993e ...</td>\n",
              "      <td>[0.546481097862738, -0.12618325455039198, 0.01...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>612</th>\n",
              "      <td>Coordinate:  20h 20m 00s, +40° 00′ 00″\\n\\tIl C...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>coordin 20h 20m 00s 40 00 00 il compless nebul...</td>\n",
              "      <td>[0.6077005403740513, -0.11272059821801586, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>613</th>\n",
              "      <td>Coordinate:  22h 00m 00s, +60° 00′ 00″\\n\\tIl c...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>coordin 22h 00m 00s 60 00 00 il compless nebul...</td>\n",
              "      <td>[0.60099227243804, -0.13276656037670811, 0.010...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>613 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Text  ...                                       TfIdfVectors\n",
              "0    Ho acquistato questa confezione di mascherine ...  ...  [0.27247792065239457, 0.21972266346699976, 0.0...\n",
              "1    Attenzione, ha un ferretto nasale in plastica ...  ...  [0.16908623342662926, 0.09757413226524703, -0....\n",
              "2    La confezione di cartone era già aperta, appen...  ...  [0.21797217894206228, 0.12299623105572668, 0.0...\n",
              "3    Mascherine vendute come \"Maschera Chirurgica 3...  ...  [0.07175741115385922, 0.03131215810517044, 0.0...\n",
              "4                     ARRIVATO APERTO PESSIMO PRODOTTO  ...  [0.024622949971823467, 0.07720488916191945, 0....\n",
              "..                                                 ...  ...                                                ...\n",
              "608  Coordinate:  06h 23m 57.109s, -52° 41′ 44.378″...  ...  [0.54536226007737, -0.1105415812214581, -0.009...\n",
              "610  La Cometa Hyakutake (pronuncia giapponese: [ça...  ...  [0.4892127369919711, -0.10012123633633806, -0....\n",
              "611  La cometa Shoemaker-Levy 9 (formalmente design...  ...  [0.546481097862738, -0.12618325455039198, 0.01...\n",
              "612  Coordinate:  20h 20m 00s, +40° 00′ 00″\\n\\tIl C...  ...  [0.6077005403740513, -0.11272059821801586, 0.0...\n",
              "613  Coordinate:  22h 00m 00s, +60° 00′ 00″\\n\\tIl c...  ...  [0.60099227243804, -0.13276656037670811, 0.010...\n",
              "\n",
              "[613 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpoQtrmpZbua",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "aa510f53-5b83-47e4-8c0c-890ef3d8e553"
      },
      "source": [
        "len(a2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfzNickbZM1i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "j = 0\n",
        "for i in l:\n",
        "  TrainData[i]= a2[j]\n",
        "  j = j+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAiqoX_LyLR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TrainData.to_csv('/content/drive/My Drive/Topic detection/TfIdfData.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9Y6NsEkyT41",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "outputId": "91378c6e-a652-497b-a01f-ac994fbd1b21"
      },
      "source": [
        "TrainData.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Processed Text</th>\n",
              "      <th>TfIdfVectors</th>\n",
              "      <th>feat1</th>\n",
              "      <th>feat2</th>\n",
              "      <th>feat3</th>\n",
              "      <th>feat4</th>\n",
              "      <th>feat5</th>\n",
              "      <th>feat6</th>\n",
              "      <th>feat7</th>\n",
              "      <th>feat8</th>\n",
              "      <th>feat9</th>\n",
              "      <th>feat10</th>\n",
              "      <th>feat11</th>\n",
              "      <th>feat12</th>\n",
              "      <th>feat13</th>\n",
              "      <th>feat14</th>\n",
              "      <th>feat15</th>\n",
              "      <th>feat16</th>\n",
              "      <th>feat17</th>\n",
              "      <th>feat18</th>\n",
              "      <th>feat19</th>\n",
              "      <th>feat20</th>\n",
              "      <th>feat21</th>\n",
              "      <th>feat22</th>\n",
              "      <th>feat23</th>\n",
              "      <th>feat24</th>\n",
              "      <th>feat25</th>\n",
              "      <th>feat26</th>\n",
              "      <th>feat27</th>\n",
              "      <th>feat28</th>\n",
              "      <th>feat29</th>\n",
              "      <th>feat30</th>\n",
              "      <th>feat31</th>\n",
              "      <th>feat32</th>\n",
              "      <th>feat33</th>\n",
              "      <th>feat34</th>\n",
              "      <th>feat35</th>\n",
              "      <th>feat36</th>\n",
              "      <th>...</th>\n",
              "      <th>feat161</th>\n",
              "      <th>feat162</th>\n",
              "      <th>feat163</th>\n",
              "      <th>feat164</th>\n",
              "      <th>feat165</th>\n",
              "      <th>feat166</th>\n",
              "      <th>feat167</th>\n",
              "      <th>feat168</th>\n",
              "      <th>feat169</th>\n",
              "      <th>feat170</th>\n",
              "      <th>feat171</th>\n",
              "      <th>feat172</th>\n",
              "      <th>feat173</th>\n",
              "      <th>feat174</th>\n",
              "      <th>feat175</th>\n",
              "      <th>feat176</th>\n",
              "      <th>feat177</th>\n",
              "      <th>feat178</th>\n",
              "      <th>feat179</th>\n",
              "      <th>feat180</th>\n",
              "      <th>feat181</th>\n",
              "      <th>feat182</th>\n",
              "      <th>feat183</th>\n",
              "      <th>feat184</th>\n",
              "      <th>feat185</th>\n",
              "      <th>feat186</th>\n",
              "      <th>feat187</th>\n",
              "      <th>feat188</th>\n",
              "      <th>feat189</th>\n",
              "      <th>feat190</th>\n",
              "      <th>feat191</th>\n",
              "      <th>feat192</th>\n",
              "      <th>feat193</th>\n",
              "      <th>feat194</th>\n",
              "      <th>feat195</th>\n",
              "      <th>feat196</th>\n",
              "      <th>feat197</th>\n",
              "      <th>feat198</th>\n",
              "      <th>feat199</th>\n",
              "      <th>feat200</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ho acquistato questa confezione di mascherine ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>ho acquist confezion mascherin 19 99 quind 40 ...</td>\n",
              "      <td>[0.27247792065239457, 0.21972266346699976, 0.0...</td>\n",
              "      <td>0.272478</td>\n",
              "      <td>0.219723</td>\n",
              "      <td>0.024187</td>\n",
              "      <td>-0.035276</td>\n",
              "      <td>-0.060019</td>\n",
              "      <td>0.032466</td>\n",
              "      <td>-0.140034</td>\n",
              "      <td>-0.021274</td>\n",
              "      <td>0.010797</td>\n",
              "      <td>-0.139642</td>\n",
              "      <td>-0.248782</td>\n",
              "      <td>-0.112859</td>\n",
              "      <td>0.077791</td>\n",
              "      <td>-0.032370</td>\n",
              "      <td>-0.078478</td>\n",
              "      <td>0.049554</td>\n",
              "      <td>0.066917</td>\n",
              "      <td>-0.007913</td>\n",
              "      <td>-0.012080</td>\n",
              "      <td>-0.078611</td>\n",
              "      <td>0.038777</td>\n",
              "      <td>0.035575</td>\n",
              "      <td>-0.046226</td>\n",
              "      <td>0.047796</td>\n",
              "      <td>0.095787</td>\n",
              "      <td>-0.013445</td>\n",
              "      <td>0.033574</td>\n",
              "      <td>-0.046113</td>\n",
              "      <td>0.052642</td>\n",
              "      <td>0.079219</td>\n",
              "      <td>0.009382</td>\n",
              "      <td>0.105429</td>\n",
              "      <td>0.146709</td>\n",
              "      <td>0.016257</td>\n",
              "      <td>0.265021</td>\n",
              "      <td>0.183178</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000712</td>\n",
              "      <td>0.003130</td>\n",
              "      <td>0.007188</td>\n",
              "      <td>-0.002206</td>\n",
              "      <td>0.016861</td>\n",
              "      <td>0.005693</td>\n",
              "      <td>0.007154</td>\n",
              "      <td>-0.008933</td>\n",
              "      <td>-0.001005</td>\n",
              "      <td>-0.001717</td>\n",
              "      <td>-0.006622</td>\n",
              "      <td>0.010369</td>\n",
              "      <td>-0.006517</td>\n",
              "      <td>0.000171</td>\n",
              "      <td>-0.007744</td>\n",
              "      <td>-0.008937</td>\n",
              "      <td>-0.002413</td>\n",
              "      <td>-0.011081</td>\n",
              "      <td>-0.007513</td>\n",
              "      <td>0.016864</td>\n",
              "      <td>-0.013261</td>\n",
              "      <td>0.015795</td>\n",
              "      <td>-0.013149</td>\n",
              "      <td>-0.005551</td>\n",
              "      <td>0.005734</td>\n",
              "      <td>0.001783</td>\n",
              "      <td>0.001591</td>\n",
              "      <td>0.003175</td>\n",
              "      <td>-0.005366</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>0.007140</td>\n",
              "      <td>0.002043</td>\n",
              "      <td>-0.014306</td>\n",
              "      <td>-0.009748</td>\n",
              "      <td>0.001553</td>\n",
              "      <td>0.003029</td>\n",
              "      <td>0.013427</td>\n",
              "      <td>-0.001351</td>\n",
              "      <td>0.001680</td>\n",
              "      <td>0.010876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Attenzione, ha un ferretto nasale in plastica ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>attenzion ferrett nasal plastic permett far ad...</td>\n",
              "      <td>[0.16908623342662926, 0.09757413226524703, -0....</td>\n",
              "      <td>0.169086</td>\n",
              "      <td>0.097574</td>\n",
              "      <td>-0.005238</td>\n",
              "      <td>-0.042576</td>\n",
              "      <td>-0.009253</td>\n",
              "      <td>0.007023</td>\n",
              "      <td>-0.082983</td>\n",
              "      <td>-0.028276</td>\n",
              "      <td>0.077973</td>\n",
              "      <td>-0.068384</td>\n",
              "      <td>-0.041844</td>\n",
              "      <td>-0.048824</td>\n",
              "      <td>0.046407</td>\n",
              "      <td>-0.028404</td>\n",
              "      <td>-0.075385</td>\n",
              "      <td>0.050105</td>\n",
              "      <td>0.039076</td>\n",
              "      <td>-0.017067</td>\n",
              "      <td>0.119496</td>\n",
              "      <td>-0.014493</td>\n",
              "      <td>0.042645</td>\n",
              "      <td>0.027865</td>\n",
              "      <td>-0.005659</td>\n",
              "      <td>0.073627</td>\n",
              "      <td>0.059247</td>\n",
              "      <td>-0.073071</td>\n",
              "      <td>0.085659</td>\n",
              "      <td>-0.066784</td>\n",
              "      <td>0.108375</td>\n",
              "      <td>0.043017</td>\n",
              "      <td>-0.071770</td>\n",
              "      <td>0.073374</td>\n",
              "      <td>0.198330</td>\n",
              "      <td>-0.035712</td>\n",
              "      <td>0.394452</td>\n",
              "      <td>0.091456</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008430</td>\n",
              "      <td>-0.002051</td>\n",
              "      <td>0.005653</td>\n",
              "      <td>-0.001060</td>\n",
              "      <td>-0.001239</td>\n",
              "      <td>-0.003488</td>\n",
              "      <td>-0.000415</td>\n",
              "      <td>-0.009582</td>\n",
              "      <td>0.009058</td>\n",
              "      <td>-0.001457</td>\n",
              "      <td>-0.003282</td>\n",
              "      <td>-0.006317</td>\n",
              "      <td>0.003986</td>\n",
              "      <td>-0.007342</td>\n",
              "      <td>-0.003682</td>\n",
              "      <td>-0.001634</td>\n",
              "      <td>0.004405</td>\n",
              "      <td>-0.001732</td>\n",
              "      <td>0.009430</td>\n",
              "      <td>0.000913</td>\n",
              "      <td>0.002386</td>\n",
              "      <td>-0.002332</td>\n",
              "      <td>-0.004043</td>\n",
              "      <td>0.001671</td>\n",
              "      <td>0.004705</td>\n",
              "      <td>0.012583</td>\n",
              "      <td>-0.000720</td>\n",
              "      <td>0.003781</td>\n",
              "      <td>-0.000824</td>\n",
              "      <td>-0.007811</td>\n",
              "      <td>0.002804</td>\n",
              "      <td>0.002463</td>\n",
              "      <td>-0.001740</td>\n",
              "      <td>0.002401</td>\n",
              "      <td>-0.001963</td>\n",
              "      <td>0.001424</td>\n",
              "      <td>-0.007116</td>\n",
              "      <td>0.000450</td>\n",
              "      <td>0.004899</td>\n",
              "      <td>0.002939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>La confezione di cartone era già aperta, appen...</td>\n",
              "      <td>negative</td>\n",
              "      <td>la confezion carton già apert appen pres lat t...</td>\n",
              "      <td>[0.21797217894206228, 0.12299623105572668, 0.0...</td>\n",
              "      <td>0.217972</td>\n",
              "      <td>0.122996</td>\n",
              "      <td>0.065318</td>\n",
              "      <td>-0.045467</td>\n",
              "      <td>0.058404</td>\n",
              "      <td>0.044320</td>\n",
              "      <td>0.009989</td>\n",
              "      <td>0.067978</td>\n",
              "      <td>0.051968</td>\n",
              "      <td>-0.041222</td>\n",
              "      <td>-0.274352</td>\n",
              "      <td>-0.081080</td>\n",
              "      <td>0.066843</td>\n",
              "      <td>-0.117769</td>\n",
              "      <td>-0.090430</td>\n",
              "      <td>0.109259</td>\n",
              "      <td>0.094669</td>\n",
              "      <td>-0.007535</td>\n",
              "      <td>-0.113081</td>\n",
              "      <td>-0.007895</td>\n",
              "      <td>0.055765</td>\n",
              "      <td>-0.036258</td>\n",
              "      <td>-0.049051</td>\n",
              "      <td>-0.080781</td>\n",
              "      <td>0.004164</td>\n",
              "      <td>0.025648</td>\n",
              "      <td>-0.068258</td>\n",
              "      <td>0.020109</td>\n",
              "      <td>-0.114043</td>\n",
              "      <td>-0.034672</td>\n",
              "      <td>-0.062693</td>\n",
              "      <td>-0.048389</td>\n",
              "      <td>-0.086449</td>\n",
              "      <td>0.175677</td>\n",
              "      <td>-0.002588</td>\n",
              "      <td>-0.203799</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001298</td>\n",
              "      <td>0.008515</td>\n",
              "      <td>-0.013129</td>\n",
              "      <td>-0.005722</td>\n",
              "      <td>-0.000380</td>\n",
              "      <td>0.002795</td>\n",
              "      <td>0.006812</td>\n",
              "      <td>0.010063</td>\n",
              "      <td>-0.004645</td>\n",
              "      <td>0.002088</td>\n",
              "      <td>0.006688</td>\n",
              "      <td>0.011200</td>\n",
              "      <td>0.006949</td>\n",
              "      <td>0.002952</td>\n",
              "      <td>0.002058</td>\n",
              "      <td>-0.003507</td>\n",
              "      <td>0.005913</td>\n",
              "      <td>0.004957</td>\n",
              "      <td>0.003159</td>\n",
              "      <td>0.003091</td>\n",
              "      <td>-0.003575</td>\n",
              "      <td>-0.002152</td>\n",
              "      <td>-0.002908</td>\n",
              "      <td>0.003800</td>\n",
              "      <td>-0.002425</td>\n",
              "      <td>0.000170</td>\n",
              "      <td>-0.003258</td>\n",
              "      <td>0.003702</td>\n",
              "      <td>0.006239</td>\n",
              "      <td>-0.000163</td>\n",
              "      <td>0.004509</td>\n",
              "      <td>0.000061</td>\n",
              "      <td>0.003800</td>\n",
              "      <td>-0.000824</td>\n",
              "      <td>0.002099</td>\n",
              "      <td>-0.000275</td>\n",
              "      <td>-0.001592</td>\n",
              "      <td>0.004395</td>\n",
              "      <td>0.002083</td>\n",
              "      <td>0.001672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mascherine vendute come \"Maschera Chirurgica 3...</td>\n",
              "      <td>negative</td>\n",
              "      <td>mascherin vend mascher chirurg 3p tip iir conf...</td>\n",
              "      <td>[0.07175741115385922, 0.03131215810517044, 0.0...</td>\n",
              "      <td>0.071757</td>\n",
              "      <td>0.031312</td>\n",
              "      <td>0.035936</td>\n",
              "      <td>-0.057036</td>\n",
              "      <td>0.000778</td>\n",
              "      <td>-0.014077</td>\n",
              "      <td>-0.084098</td>\n",
              "      <td>0.079488</td>\n",
              "      <td>0.059257</td>\n",
              "      <td>-0.149626</td>\n",
              "      <td>-0.212587</td>\n",
              "      <td>-0.042393</td>\n",
              "      <td>0.069109</td>\n",
              "      <td>-0.001030</td>\n",
              "      <td>-0.024891</td>\n",
              "      <td>0.020581</td>\n",
              "      <td>0.087634</td>\n",
              "      <td>0.046171</td>\n",
              "      <td>-0.027870</td>\n",
              "      <td>-0.050561</td>\n",
              "      <td>-0.033546</td>\n",
              "      <td>0.017294</td>\n",
              "      <td>0.057090</td>\n",
              "      <td>0.016539</td>\n",
              "      <td>0.036593</td>\n",
              "      <td>0.041356</td>\n",
              "      <td>-0.170997</td>\n",
              "      <td>0.033856</td>\n",
              "      <td>-0.117031</td>\n",
              "      <td>-0.043175</td>\n",
              "      <td>0.032733</td>\n",
              "      <td>-0.043034</td>\n",
              "      <td>-0.032720</td>\n",
              "      <td>-0.122345</td>\n",
              "      <td>-0.123200</td>\n",
              "      <td>-0.045622</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.003952</td>\n",
              "      <td>-0.002479</td>\n",
              "      <td>0.001994</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.000913</td>\n",
              "      <td>0.001603</td>\n",
              "      <td>0.003920</td>\n",
              "      <td>0.002515</td>\n",
              "      <td>-0.005151</td>\n",
              "      <td>-0.003730</td>\n",
              "      <td>-0.000670</td>\n",
              "      <td>0.001214</td>\n",
              "      <td>-0.000396</td>\n",
              "      <td>-0.001674</td>\n",
              "      <td>0.005860</td>\n",
              "      <td>0.002220</td>\n",
              "      <td>0.001087</td>\n",
              "      <td>0.002812</td>\n",
              "      <td>-0.013707</td>\n",
              "      <td>0.005236</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>-0.007154</td>\n",
              "      <td>-0.001894</td>\n",
              "      <td>-0.000474</td>\n",
              "      <td>0.004815</td>\n",
              "      <td>-0.005157</td>\n",
              "      <td>-0.000861</td>\n",
              "      <td>0.002101</td>\n",
              "      <td>0.003857</td>\n",
              "      <td>0.004209</td>\n",
              "      <td>0.002201</td>\n",
              "      <td>-0.000673</td>\n",
              "      <td>-0.002494</td>\n",
              "      <td>0.000732</td>\n",
              "      <td>0.003137</td>\n",
              "      <td>-0.006297</td>\n",
              "      <td>-0.001338</td>\n",
              "      <td>0.000829</td>\n",
              "      <td>0.000068</td>\n",
              "      <td>0.002367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ARRIVATO APERTO PESSIMO PRODOTTO</td>\n",
              "      <td>negative</td>\n",
              "      <td>arriv apert pessim prodott</td>\n",
              "      <td>[0.024622949971823467, 0.07720488916191945, 0....</td>\n",
              "      <td>0.024623</td>\n",
              "      <td>0.077205</td>\n",
              "      <td>0.104754</td>\n",
              "      <td>-0.133077</td>\n",
              "      <td>0.261053</td>\n",
              "      <td>-0.116749</td>\n",
              "      <td>0.042607</td>\n",
              "      <td>-0.011968</td>\n",
              "      <td>-0.134939</td>\n",
              "      <td>0.107018</td>\n",
              "      <td>-0.065399</td>\n",
              "      <td>0.115100</td>\n",
              "      <td>0.007286</td>\n",
              "      <td>-0.036770</td>\n",
              "      <td>-0.028190</td>\n",
              "      <td>0.009106</td>\n",
              "      <td>0.038686</td>\n",
              "      <td>0.032256</td>\n",
              "      <td>0.056017</td>\n",
              "      <td>-0.048003</td>\n",
              "      <td>-0.017674</td>\n",
              "      <td>0.033227</td>\n",
              "      <td>-0.025836</td>\n",
              "      <td>-0.009794</td>\n",
              "      <td>0.107878</td>\n",
              "      <td>-0.045588</td>\n",
              "      <td>-0.018997</td>\n",
              "      <td>-0.053013</td>\n",
              "      <td>-0.125225</td>\n",
              "      <td>-0.050173</td>\n",
              "      <td>0.085992</td>\n",
              "      <td>-0.243862</td>\n",
              "      <td>0.090571</td>\n",
              "      <td>0.330075</td>\n",
              "      <td>0.078079</td>\n",
              "      <td>-0.182693</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001026</td>\n",
              "      <td>-0.008607</td>\n",
              "      <td>-0.004902</td>\n",
              "      <td>0.005900</td>\n",
              "      <td>0.008167</td>\n",
              "      <td>-0.013703</td>\n",
              "      <td>-0.000115</td>\n",
              "      <td>0.002053</td>\n",
              "      <td>0.012658</td>\n",
              "      <td>0.004097</td>\n",
              "      <td>0.018366</td>\n",
              "      <td>-0.002278</td>\n",
              "      <td>-0.009842</td>\n",
              "      <td>0.003966</td>\n",
              "      <td>-0.007308</td>\n",
              "      <td>0.006488</td>\n",
              "      <td>-0.021583</td>\n",
              "      <td>0.003343</td>\n",
              "      <td>0.003939</td>\n",
              "      <td>-0.007270</td>\n",
              "      <td>0.003429</td>\n",
              "      <td>-0.004072</td>\n",
              "      <td>0.006470</td>\n",
              "      <td>0.007423</td>\n",
              "      <td>-0.008437</td>\n",
              "      <td>0.004770</td>\n",
              "      <td>0.007399</td>\n",
              "      <td>-0.006165</td>\n",
              "      <td>-0.004514</td>\n",
              "      <td>0.005003</td>\n",
              "      <td>-0.002977</td>\n",
              "      <td>-0.004988</td>\n",
              "      <td>0.001843</td>\n",
              "      <td>-0.003085</td>\n",
              "      <td>-0.005825</td>\n",
              "      <td>0.000523</td>\n",
              "      <td>0.005671</td>\n",
              "      <td>-0.007125</td>\n",
              "      <td>-0.004923</td>\n",
              "      <td>0.000338</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 204 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  ...   feat200\n",
              "0  Ho acquistato questa confezione di mascherine ...  ...  0.010876\n",
              "1  Attenzione, ha un ferretto nasale in plastica ...  ...  0.002939\n",
              "2  La confezione di cartone era già aperta, appen...  ...  0.001672\n",
              "3  Mascherine vendute come \"Maschera Chirurgica 3...  ...  0.002367\n",
              "4                   ARRIVATO APERTO PESSIMO PRODOTTO  ...  0.000338\n",
              "\n",
              "[5 rows x 204 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anU8cJk03TGO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "74771bf0-6e44-466b-ba07-00cc1b280cc3"
      },
      "source": [
        "dd = [1]*613\n",
        "dd[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7zG5Hzw31W1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "0d18d61f-ea73-4e02-838b-a927f0224236"
      },
      "source": [
        "[TrainData['TfIdfVectors']].shape()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-6179568f5f14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mTrainData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TfIdfVectors'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn6BtqdV30UY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "outputId": "c54116d5-a3e4-4fe7-af5a-419cc94565ba"
      },
      "source": [
        "TrainData.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Processed Text</th>\n",
              "      <th>TfIdfVectors</th>\n",
              "      <th>feat1</th>\n",
              "      <th>feat2</th>\n",
              "      <th>feat3</th>\n",
              "      <th>feat4</th>\n",
              "      <th>feat5</th>\n",
              "      <th>feat6</th>\n",
              "      <th>feat7</th>\n",
              "      <th>feat8</th>\n",
              "      <th>feat9</th>\n",
              "      <th>feat10</th>\n",
              "      <th>feat11</th>\n",
              "      <th>feat12</th>\n",
              "      <th>feat13</th>\n",
              "      <th>feat14</th>\n",
              "      <th>feat15</th>\n",
              "      <th>feat16</th>\n",
              "      <th>feat17</th>\n",
              "      <th>feat18</th>\n",
              "      <th>feat19</th>\n",
              "      <th>feat20</th>\n",
              "      <th>feat21</th>\n",
              "      <th>feat22</th>\n",
              "      <th>feat23</th>\n",
              "      <th>feat24</th>\n",
              "      <th>feat25</th>\n",
              "      <th>feat26</th>\n",
              "      <th>feat27</th>\n",
              "      <th>feat28</th>\n",
              "      <th>feat29</th>\n",
              "      <th>feat30</th>\n",
              "      <th>feat31</th>\n",
              "      <th>feat32</th>\n",
              "      <th>feat33</th>\n",
              "      <th>feat34</th>\n",
              "      <th>feat35</th>\n",
              "      <th>feat36</th>\n",
              "      <th>...</th>\n",
              "      <th>feat161</th>\n",
              "      <th>feat162</th>\n",
              "      <th>feat163</th>\n",
              "      <th>feat164</th>\n",
              "      <th>feat165</th>\n",
              "      <th>feat166</th>\n",
              "      <th>feat167</th>\n",
              "      <th>feat168</th>\n",
              "      <th>feat169</th>\n",
              "      <th>feat170</th>\n",
              "      <th>feat171</th>\n",
              "      <th>feat172</th>\n",
              "      <th>feat173</th>\n",
              "      <th>feat174</th>\n",
              "      <th>feat175</th>\n",
              "      <th>feat176</th>\n",
              "      <th>feat177</th>\n",
              "      <th>feat178</th>\n",
              "      <th>feat179</th>\n",
              "      <th>feat180</th>\n",
              "      <th>feat181</th>\n",
              "      <th>feat182</th>\n",
              "      <th>feat183</th>\n",
              "      <th>feat184</th>\n",
              "      <th>feat185</th>\n",
              "      <th>feat186</th>\n",
              "      <th>feat187</th>\n",
              "      <th>feat188</th>\n",
              "      <th>feat189</th>\n",
              "      <th>feat190</th>\n",
              "      <th>feat191</th>\n",
              "      <th>feat192</th>\n",
              "      <th>feat193</th>\n",
              "      <th>feat194</th>\n",
              "      <th>feat195</th>\n",
              "      <th>feat196</th>\n",
              "      <th>feat197</th>\n",
              "      <th>feat198</th>\n",
              "      <th>feat199</th>\n",
              "      <th>feat200</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ho acquistato questa confezione di mascherine ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>ho acquist confezion mascherin 19 99 quind 40 ...</td>\n",
              "      <td>[0.27247792065239457, 0.21972266346699976, 0.0...</td>\n",
              "      <td>0.272478</td>\n",
              "      <td>0.219723</td>\n",
              "      <td>0.024187</td>\n",
              "      <td>-0.035276</td>\n",
              "      <td>-0.060019</td>\n",
              "      <td>0.032466</td>\n",
              "      <td>-0.140034</td>\n",
              "      <td>-0.021274</td>\n",
              "      <td>0.010797</td>\n",
              "      <td>-0.139642</td>\n",
              "      <td>-0.248782</td>\n",
              "      <td>-0.112859</td>\n",
              "      <td>0.077791</td>\n",
              "      <td>-0.032370</td>\n",
              "      <td>-0.078478</td>\n",
              "      <td>0.049554</td>\n",
              "      <td>0.066917</td>\n",
              "      <td>-0.007913</td>\n",
              "      <td>-0.012080</td>\n",
              "      <td>-0.078611</td>\n",
              "      <td>0.038777</td>\n",
              "      <td>0.035575</td>\n",
              "      <td>-0.046226</td>\n",
              "      <td>0.047796</td>\n",
              "      <td>0.095787</td>\n",
              "      <td>-0.013445</td>\n",
              "      <td>0.033574</td>\n",
              "      <td>-0.046113</td>\n",
              "      <td>0.052642</td>\n",
              "      <td>0.079219</td>\n",
              "      <td>0.009382</td>\n",
              "      <td>0.105429</td>\n",
              "      <td>0.146709</td>\n",
              "      <td>0.016257</td>\n",
              "      <td>0.265021</td>\n",
              "      <td>0.183178</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000712</td>\n",
              "      <td>0.003130</td>\n",
              "      <td>0.007188</td>\n",
              "      <td>-0.002206</td>\n",
              "      <td>0.016861</td>\n",
              "      <td>0.005693</td>\n",
              "      <td>0.007154</td>\n",
              "      <td>-0.008933</td>\n",
              "      <td>-0.001005</td>\n",
              "      <td>-0.001717</td>\n",
              "      <td>-0.006622</td>\n",
              "      <td>0.010369</td>\n",
              "      <td>-0.006517</td>\n",
              "      <td>0.000171</td>\n",
              "      <td>-0.007744</td>\n",
              "      <td>-0.008937</td>\n",
              "      <td>-0.002413</td>\n",
              "      <td>-0.011081</td>\n",
              "      <td>-0.007513</td>\n",
              "      <td>0.016864</td>\n",
              "      <td>-0.013261</td>\n",
              "      <td>0.015795</td>\n",
              "      <td>-0.013149</td>\n",
              "      <td>-0.005551</td>\n",
              "      <td>0.005734</td>\n",
              "      <td>0.001783</td>\n",
              "      <td>0.001591</td>\n",
              "      <td>0.003175</td>\n",
              "      <td>-0.005366</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>0.007140</td>\n",
              "      <td>0.002043</td>\n",
              "      <td>-0.014306</td>\n",
              "      <td>-0.009748</td>\n",
              "      <td>0.001553</td>\n",
              "      <td>0.003029</td>\n",
              "      <td>0.013427</td>\n",
              "      <td>-0.001351</td>\n",
              "      <td>0.001680</td>\n",
              "      <td>0.010876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Attenzione, ha un ferretto nasale in plastica ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>attenzion ferrett nasal plastic permett far ad...</td>\n",
              "      <td>[0.16908623342662926, 0.09757413226524703, -0....</td>\n",
              "      <td>0.169086</td>\n",
              "      <td>0.097574</td>\n",
              "      <td>-0.005238</td>\n",
              "      <td>-0.042576</td>\n",
              "      <td>-0.009253</td>\n",
              "      <td>0.007023</td>\n",
              "      <td>-0.082983</td>\n",
              "      <td>-0.028276</td>\n",
              "      <td>0.077973</td>\n",
              "      <td>-0.068384</td>\n",
              "      <td>-0.041844</td>\n",
              "      <td>-0.048824</td>\n",
              "      <td>0.046407</td>\n",
              "      <td>-0.028404</td>\n",
              "      <td>-0.075385</td>\n",
              "      <td>0.050105</td>\n",
              "      <td>0.039076</td>\n",
              "      <td>-0.017067</td>\n",
              "      <td>0.119496</td>\n",
              "      <td>-0.014493</td>\n",
              "      <td>0.042645</td>\n",
              "      <td>0.027865</td>\n",
              "      <td>-0.005659</td>\n",
              "      <td>0.073627</td>\n",
              "      <td>0.059247</td>\n",
              "      <td>-0.073071</td>\n",
              "      <td>0.085659</td>\n",
              "      <td>-0.066784</td>\n",
              "      <td>0.108375</td>\n",
              "      <td>0.043017</td>\n",
              "      <td>-0.071770</td>\n",
              "      <td>0.073374</td>\n",
              "      <td>0.198330</td>\n",
              "      <td>-0.035712</td>\n",
              "      <td>0.394452</td>\n",
              "      <td>0.091456</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008430</td>\n",
              "      <td>-0.002051</td>\n",
              "      <td>0.005653</td>\n",
              "      <td>-0.001060</td>\n",
              "      <td>-0.001239</td>\n",
              "      <td>-0.003488</td>\n",
              "      <td>-0.000415</td>\n",
              "      <td>-0.009582</td>\n",
              "      <td>0.009058</td>\n",
              "      <td>-0.001457</td>\n",
              "      <td>-0.003282</td>\n",
              "      <td>-0.006317</td>\n",
              "      <td>0.003986</td>\n",
              "      <td>-0.007342</td>\n",
              "      <td>-0.003682</td>\n",
              "      <td>-0.001634</td>\n",
              "      <td>0.004405</td>\n",
              "      <td>-0.001732</td>\n",
              "      <td>0.009430</td>\n",
              "      <td>0.000913</td>\n",
              "      <td>0.002386</td>\n",
              "      <td>-0.002332</td>\n",
              "      <td>-0.004043</td>\n",
              "      <td>0.001671</td>\n",
              "      <td>0.004705</td>\n",
              "      <td>0.012583</td>\n",
              "      <td>-0.000720</td>\n",
              "      <td>0.003781</td>\n",
              "      <td>-0.000824</td>\n",
              "      <td>-0.007811</td>\n",
              "      <td>0.002804</td>\n",
              "      <td>0.002463</td>\n",
              "      <td>-0.001740</td>\n",
              "      <td>0.002401</td>\n",
              "      <td>-0.001963</td>\n",
              "      <td>0.001424</td>\n",
              "      <td>-0.007116</td>\n",
              "      <td>0.000450</td>\n",
              "      <td>0.004899</td>\n",
              "      <td>0.002939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>La confezione di cartone era già aperta, appen...</td>\n",
              "      <td>negative</td>\n",
              "      <td>la confezion carton già apert appen pres lat t...</td>\n",
              "      <td>[0.21797217894206228, 0.12299623105572668, 0.0...</td>\n",
              "      <td>0.217972</td>\n",
              "      <td>0.122996</td>\n",
              "      <td>0.065318</td>\n",
              "      <td>-0.045467</td>\n",
              "      <td>0.058404</td>\n",
              "      <td>0.044320</td>\n",
              "      <td>0.009989</td>\n",
              "      <td>0.067978</td>\n",
              "      <td>0.051968</td>\n",
              "      <td>-0.041222</td>\n",
              "      <td>-0.274352</td>\n",
              "      <td>-0.081080</td>\n",
              "      <td>0.066843</td>\n",
              "      <td>-0.117769</td>\n",
              "      <td>-0.090430</td>\n",
              "      <td>0.109259</td>\n",
              "      <td>0.094669</td>\n",
              "      <td>-0.007535</td>\n",
              "      <td>-0.113081</td>\n",
              "      <td>-0.007895</td>\n",
              "      <td>0.055765</td>\n",
              "      <td>-0.036258</td>\n",
              "      <td>-0.049051</td>\n",
              "      <td>-0.080781</td>\n",
              "      <td>0.004164</td>\n",
              "      <td>0.025648</td>\n",
              "      <td>-0.068258</td>\n",
              "      <td>0.020109</td>\n",
              "      <td>-0.114043</td>\n",
              "      <td>-0.034672</td>\n",
              "      <td>-0.062693</td>\n",
              "      <td>-0.048389</td>\n",
              "      <td>-0.086449</td>\n",
              "      <td>0.175677</td>\n",
              "      <td>-0.002588</td>\n",
              "      <td>-0.203799</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001298</td>\n",
              "      <td>0.008515</td>\n",
              "      <td>-0.013129</td>\n",
              "      <td>-0.005722</td>\n",
              "      <td>-0.000380</td>\n",
              "      <td>0.002795</td>\n",
              "      <td>0.006812</td>\n",
              "      <td>0.010063</td>\n",
              "      <td>-0.004645</td>\n",
              "      <td>0.002088</td>\n",
              "      <td>0.006688</td>\n",
              "      <td>0.011200</td>\n",
              "      <td>0.006949</td>\n",
              "      <td>0.002952</td>\n",
              "      <td>0.002058</td>\n",
              "      <td>-0.003507</td>\n",
              "      <td>0.005913</td>\n",
              "      <td>0.004957</td>\n",
              "      <td>0.003159</td>\n",
              "      <td>0.003091</td>\n",
              "      <td>-0.003575</td>\n",
              "      <td>-0.002152</td>\n",
              "      <td>-0.002908</td>\n",
              "      <td>0.003800</td>\n",
              "      <td>-0.002425</td>\n",
              "      <td>0.000170</td>\n",
              "      <td>-0.003258</td>\n",
              "      <td>0.003702</td>\n",
              "      <td>0.006239</td>\n",
              "      <td>-0.000163</td>\n",
              "      <td>0.004509</td>\n",
              "      <td>0.000061</td>\n",
              "      <td>0.003800</td>\n",
              "      <td>-0.000824</td>\n",
              "      <td>0.002099</td>\n",
              "      <td>-0.000275</td>\n",
              "      <td>-0.001592</td>\n",
              "      <td>0.004395</td>\n",
              "      <td>0.002083</td>\n",
              "      <td>0.001672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mascherine vendute come \"Maschera Chirurgica 3...</td>\n",
              "      <td>negative</td>\n",
              "      <td>mascherin vend mascher chirurg 3p tip iir conf...</td>\n",
              "      <td>[0.07175741115385922, 0.03131215810517044, 0.0...</td>\n",
              "      <td>0.071757</td>\n",
              "      <td>0.031312</td>\n",
              "      <td>0.035936</td>\n",
              "      <td>-0.057036</td>\n",
              "      <td>0.000778</td>\n",
              "      <td>-0.014077</td>\n",
              "      <td>-0.084098</td>\n",
              "      <td>0.079488</td>\n",
              "      <td>0.059257</td>\n",
              "      <td>-0.149626</td>\n",
              "      <td>-0.212587</td>\n",
              "      <td>-0.042393</td>\n",
              "      <td>0.069109</td>\n",
              "      <td>-0.001030</td>\n",
              "      <td>-0.024891</td>\n",
              "      <td>0.020581</td>\n",
              "      <td>0.087634</td>\n",
              "      <td>0.046171</td>\n",
              "      <td>-0.027870</td>\n",
              "      <td>-0.050561</td>\n",
              "      <td>-0.033546</td>\n",
              "      <td>0.017294</td>\n",
              "      <td>0.057090</td>\n",
              "      <td>0.016539</td>\n",
              "      <td>0.036593</td>\n",
              "      <td>0.041356</td>\n",
              "      <td>-0.170997</td>\n",
              "      <td>0.033856</td>\n",
              "      <td>-0.117031</td>\n",
              "      <td>-0.043175</td>\n",
              "      <td>0.032733</td>\n",
              "      <td>-0.043034</td>\n",
              "      <td>-0.032720</td>\n",
              "      <td>-0.122345</td>\n",
              "      <td>-0.123200</td>\n",
              "      <td>-0.045622</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.003952</td>\n",
              "      <td>-0.002479</td>\n",
              "      <td>0.001994</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.000913</td>\n",
              "      <td>0.001603</td>\n",
              "      <td>0.003920</td>\n",
              "      <td>0.002515</td>\n",
              "      <td>-0.005151</td>\n",
              "      <td>-0.003730</td>\n",
              "      <td>-0.000670</td>\n",
              "      <td>0.001214</td>\n",
              "      <td>-0.000396</td>\n",
              "      <td>-0.001674</td>\n",
              "      <td>0.005860</td>\n",
              "      <td>0.002220</td>\n",
              "      <td>0.001087</td>\n",
              "      <td>0.002812</td>\n",
              "      <td>-0.013707</td>\n",
              "      <td>0.005236</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>-0.007154</td>\n",
              "      <td>-0.001894</td>\n",
              "      <td>-0.000474</td>\n",
              "      <td>0.004815</td>\n",
              "      <td>-0.005157</td>\n",
              "      <td>-0.000861</td>\n",
              "      <td>0.002101</td>\n",
              "      <td>0.003857</td>\n",
              "      <td>0.004209</td>\n",
              "      <td>0.002201</td>\n",
              "      <td>-0.000673</td>\n",
              "      <td>-0.002494</td>\n",
              "      <td>0.000732</td>\n",
              "      <td>0.003137</td>\n",
              "      <td>-0.006297</td>\n",
              "      <td>-0.001338</td>\n",
              "      <td>0.000829</td>\n",
              "      <td>0.000068</td>\n",
              "      <td>0.002367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ARRIVATO APERTO PESSIMO PRODOTTO</td>\n",
              "      <td>negative</td>\n",
              "      <td>arriv apert pessim prodott</td>\n",
              "      <td>[0.024622949971823467, 0.07720488916191945, 0....</td>\n",
              "      <td>0.024623</td>\n",
              "      <td>0.077205</td>\n",
              "      <td>0.104754</td>\n",
              "      <td>-0.133077</td>\n",
              "      <td>0.261053</td>\n",
              "      <td>-0.116749</td>\n",
              "      <td>0.042607</td>\n",
              "      <td>-0.011968</td>\n",
              "      <td>-0.134939</td>\n",
              "      <td>0.107018</td>\n",
              "      <td>-0.065399</td>\n",
              "      <td>0.115100</td>\n",
              "      <td>0.007286</td>\n",
              "      <td>-0.036770</td>\n",
              "      <td>-0.028190</td>\n",
              "      <td>0.009106</td>\n",
              "      <td>0.038686</td>\n",
              "      <td>0.032256</td>\n",
              "      <td>0.056017</td>\n",
              "      <td>-0.048003</td>\n",
              "      <td>-0.017674</td>\n",
              "      <td>0.033227</td>\n",
              "      <td>-0.025836</td>\n",
              "      <td>-0.009794</td>\n",
              "      <td>0.107878</td>\n",
              "      <td>-0.045588</td>\n",
              "      <td>-0.018997</td>\n",
              "      <td>-0.053013</td>\n",
              "      <td>-0.125225</td>\n",
              "      <td>-0.050173</td>\n",
              "      <td>0.085992</td>\n",
              "      <td>-0.243862</td>\n",
              "      <td>0.090571</td>\n",
              "      <td>0.330075</td>\n",
              "      <td>0.078079</td>\n",
              "      <td>-0.182693</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001026</td>\n",
              "      <td>-0.008607</td>\n",
              "      <td>-0.004902</td>\n",
              "      <td>0.005900</td>\n",
              "      <td>0.008167</td>\n",
              "      <td>-0.013703</td>\n",
              "      <td>-0.000115</td>\n",
              "      <td>0.002053</td>\n",
              "      <td>0.012658</td>\n",
              "      <td>0.004097</td>\n",
              "      <td>0.018366</td>\n",
              "      <td>-0.002278</td>\n",
              "      <td>-0.009842</td>\n",
              "      <td>0.003966</td>\n",
              "      <td>-0.007308</td>\n",
              "      <td>0.006488</td>\n",
              "      <td>-0.021583</td>\n",
              "      <td>0.003343</td>\n",
              "      <td>0.003939</td>\n",
              "      <td>-0.007270</td>\n",
              "      <td>0.003429</td>\n",
              "      <td>-0.004072</td>\n",
              "      <td>0.006470</td>\n",
              "      <td>0.007423</td>\n",
              "      <td>-0.008437</td>\n",
              "      <td>0.004770</td>\n",
              "      <td>0.007399</td>\n",
              "      <td>-0.006165</td>\n",
              "      <td>-0.004514</td>\n",
              "      <td>0.005003</td>\n",
              "      <td>-0.002977</td>\n",
              "      <td>-0.004988</td>\n",
              "      <td>0.001843</td>\n",
              "      <td>-0.003085</td>\n",
              "      <td>-0.005825</td>\n",
              "      <td>0.000523</td>\n",
              "      <td>0.005671</td>\n",
              "      <td>-0.007125</td>\n",
              "      <td>-0.004923</td>\n",
              "      <td>0.000338</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 204 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  ...   feat200\n",
              "0  Ho acquistato questa confezione di mascherine ...  ...  0.010876\n",
              "1  Attenzione, ha un ferretto nasale in plastica ...  ...  0.002939\n",
              "2  La confezione di cartone era già aperta, appen...  ...  0.001672\n",
              "3  Mascherine vendute come \"Maschera Chirurgica 3...  ...  0.002367\n",
              "4                   ARRIVATO APERTO PESSIMO PRODOTTO  ...  0.000338\n",
              "\n",
              "[5 rows x 204 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ_xa7LZ8sh7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "outputId": "fe3a7a4b-f08f-4de5-89a1-dc21b435b20a"
      },
      "source": [
        "import pandas as pd\n",
        "TrainData = pd.read_csv('/content/drive/My Drive/Topic detection/TfIdfData.csv', index_col = 0 )\n",
        "TrainData.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Processed Text</th>\n",
              "      <th>TfIdfVectors</th>\n",
              "      <th>feat1</th>\n",
              "      <th>feat2</th>\n",
              "      <th>feat3</th>\n",
              "      <th>feat4</th>\n",
              "      <th>feat5</th>\n",
              "      <th>feat6</th>\n",
              "      <th>feat7</th>\n",
              "      <th>feat8</th>\n",
              "      <th>feat9</th>\n",
              "      <th>feat10</th>\n",
              "      <th>feat11</th>\n",
              "      <th>feat12</th>\n",
              "      <th>feat13</th>\n",
              "      <th>feat14</th>\n",
              "      <th>feat15</th>\n",
              "      <th>feat16</th>\n",
              "      <th>feat17</th>\n",
              "      <th>feat18</th>\n",
              "      <th>feat19</th>\n",
              "      <th>feat20</th>\n",
              "      <th>feat21</th>\n",
              "      <th>feat22</th>\n",
              "      <th>feat23</th>\n",
              "      <th>feat24</th>\n",
              "      <th>feat25</th>\n",
              "      <th>feat26</th>\n",
              "      <th>feat27</th>\n",
              "      <th>feat28</th>\n",
              "      <th>feat29</th>\n",
              "      <th>feat30</th>\n",
              "      <th>feat31</th>\n",
              "      <th>feat32</th>\n",
              "      <th>feat33</th>\n",
              "      <th>feat34</th>\n",
              "      <th>feat35</th>\n",
              "      <th>feat36</th>\n",
              "      <th>...</th>\n",
              "      <th>feat161</th>\n",
              "      <th>feat162</th>\n",
              "      <th>feat163</th>\n",
              "      <th>feat164</th>\n",
              "      <th>feat165</th>\n",
              "      <th>feat166</th>\n",
              "      <th>feat167</th>\n",
              "      <th>feat168</th>\n",
              "      <th>feat169</th>\n",
              "      <th>feat170</th>\n",
              "      <th>feat171</th>\n",
              "      <th>feat172</th>\n",
              "      <th>feat173</th>\n",
              "      <th>feat174</th>\n",
              "      <th>feat175</th>\n",
              "      <th>feat176</th>\n",
              "      <th>feat177</th>\n",
              "      <th>feat178</th>\n",
              "      <th>feat179</th>\n",
              "      <th>feat180</th>\n",
              "      <th>feat181</th>\n",
              "      <th>feat182</th>\n",
              "      <th>feat183</th>\n",
              "      <th>feat184</th>\n",
              "      <th>feat185</th>\n",
              "      <th>feat186</th>\n",
              "      <th>feat187</th>\n",
              "      <th>feat188</th>\n",
              "      <th>feat189</th>\n",
              "      <th>feat190</th>\n",
              "      <th>feat191</th>\n",
              "      <th>feat192</th>\n",
              "      <th>feat193</th>\n",
              "      <th>feat194</th>\n",
              "      <th>feat195</th>\n",
              "      <th>feat196</th>\n",
              "      <th>feat197</th>\n",
              "      <th>feat198</th>\n",
              "      <th>feat199</th>\n",
              "      <th>feat200</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ho acquistato questa confezione di mascherine ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>ho acquist confezion mascherin 19 99 quind 40 ...</td>\n",
              "      <td>[0.27247792065239457, 0.21972266346699976, 0.0...</td>\n",
              "      <td>0.272478</td>\n",
              "      <td>0.219723</td>\n",
              "      <td>0.024187</td>\n",
              "      <td>-0.035276</td>\n",
              "      <td>-0.060019</td>\n",
              "      <td>0.032466</td>\n",
              "      <td>-0.140034</td>\n",
              "      <td>-0.021274</td>\n",
              "      <td>0.010797</td>\n",
              "      <td>-0.139642</td>\n",
              "      <td>-0.248782</td>\n",
              "      <td>-0.112859</td>\n",
              "      <td>0.077791</td>\n",
              "      <td>-0.032370</td>\n",
              "      <td>-0.078478</td>\n",
              "      <td>0.049554</td>\n",
              "      <td>0.066917</td>\n",
              "      <td>-0.007913</td>\n",
              "      <td>-0.012080</td>\n",
              "      <td>-0.078611</td>\n",
              "      <td>0.038777</td>\n",
              "      <td>0.035575</td>\n",
              "      <td>-0.046226</td>\n",
              "      <td>0.047796</td>\n",
              "      <td>0.095787</td>\n",
              "      <td>-0.013445</td>\n",
              "      <td>0.033574</td>\n",
              "      <td>-0.046113</td>\n",
              "      <td>0.052642</td>\n",
              "      <td>0.079219</td>\n",
              "      <td>0.009382</td>\n",
              "      <td>0.105429</td>\n",
              "      <td>0.146709</td>\n",
              "      <td>0.016257</td>\n",
              "      <td>0.265021</td>\n",
              "      <td>0.183178</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000712</td>\n",
              "      <td>0.003130</td>\n",
              "      <td>0.007188</td>\n",
              "      <td>-0.002206</td>\n",
              "      <td>0.016861</td>\n",
              "      <td>0.005693</td>\n",
              "      <td>0.007154</td>\n",
              "      <td>-0.008933</td>\n",
              "      <td>-0.001005</td>\n",
              "      <td>-0.001717</td>\n",
              "      <td>-0.006622</td>\n",
              "      <td>0.010369</td>\n",
              "      <td>-0.006517</td>\n",
              "      <td>0.000171</td>\n",
              "      <td>-0.007744</td>\n",
              "      <td>-0.008937</td>\n",
              "      <td>-0.002413</td>\n",
              "      <td>-0.011081</td>\n",
              "      <td>-0.007513</td>\n",
              "      <td>0.016864</td>\n",
              "      <td>-0.013261</td>\n",
              "      <td>0.015795</td>\n",
              "      <td>-0.013149</td>\n",
              "      <td>-0.005551</td>\n",
              "      <td>0.005734</td>\n",
              "      <td>0.001783</td>\n",
              "      <td>0.001591</td>\n",
              "      <td>0.003175</td>\n",
              "      <td>-0.005366</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>0.007140</td>\n",
              "      <td>0.002043</td>\n",
              "      <td>-0.014306</td>\n",
              "      <td>-0.009748</td>\n",
              "      <td>0.001553</td>\n",
              "      <td>0.003029</td>\n",
              "      <td>0.013427</td>\n",
              "      <td>-0.001351</td>\n",
              "      <td>0.001680</td>\n",
              "      <td>0.010876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Attenzione, ha un ferretto nasale in plastica ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>attenzion ferrett nasal plastic permett far ad...</td>\n",
              "      <td>[0.16908623342662926, 0.09757413226524703, -0....</td>\n",
              "      <td>0.169086</td>\n",
              "      <td>0.097574</td>\n",
              "      <td>-0.005238</td>\n",
              "      <td>-0.042576</td>\n",
              "      <td>-0.009253</td>\n",
              "      <td>0.007023</td>\n",
              "      <td>-0.082983</td>\n",
              "      <td>-0.028276</td>\n",
              "      <td>0.077973</td>\n",
              "      <td>-0.068384</td>\n",
              "      <td>-0.041844</td>\n",
              "      <td>-0.048824</td>\n",
              "      <td>0.046407</td>\n",
              "      <td>-0.028404</td>\n",
              "      <td>-0.075385</td>\n",
              "      <td>0.050105</td>\n",
              "      <td>0.039076</td>\n",
              "      <td>-0.017067</td>\n",
              "      <td>0.119496</td>\n",
              "      <td>-0.014493</td>\n",
              "      <td>0.042645</td>\n",
              "      <td>0.027865</td>\n",
              "      <td>-0.005659</td>\n",
              "      <td>0.073627</td>\n",
              "      <td>0.059247</td>\n",
              "      <td>-0.073071</td>\n",
              "      <td>0.085659</td>\n",
              "      <td>-0.066784</td>\n",
              "      <td>0.108375</td>\n",
              "      <td>0.043017</td>\n",
              "      <td>-0.071770</td>\n",
              "      <td>0.073374</td>\n",
              "      <td>0.198330</td>\n",
              "      <td>-0.035712</td>\n",
              "      <td>0.394452</td>\n",
              "      <td>0.091456</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008430</td>\n",
              "      <td>-0.002051</td>\n",
              "      <td>0.005653</td>\n",
              "      <td>-0.001060</td>\n",
              "      <td>-0.001239</td>\n",
              "      <td>-0.003488</td>\n",
              "      <td>-0.000415</td>\n",
              "      <td>-0.009582</td>\n",
              "      <td>0.009058</td>\n",
              "      <td>-0.001457</td>\n",
              "      <td>-0.003282</td>\n",
              "      <td>-0.006317</td>\n",
              "      <td>0.003986</td>\n",
              "      <td>-0.007342</td>\n",
              "      <td>-0.003682</td>\n",
              "      <td>-0.001634</td>\n",
              "      <td>0.004405</td>\n",
              "      <td>-0.001732</td>\n",
              "      <td>0.009430</td>\n",
              "      <td>0.000913</td>\n",
              "      <td>0.002386</td>\n",
              "      <td>-0.002332</td>\n",
              "      <td>-0.004043</td>\n",
              "      <td>0.001671</td>\n",
              "      <td>0.004705</td>\n",
              "      <td>0.012583</td>\n",
              "      <td>-0.000720</td>\n",
              "      <td>0.003781</td>\n",
              "      <td>-0.000824</td>\n",
              "      <td>-0.007811</td>\n",
              "      <td>0.002804</td>\n",
              "      <td>0.002463</td>\n",
              "      <td>-0.001740</td>\n",
              "      <td>0.002401</td>\n",
              "      <td>-0.001963</td>\n",
              "      <td>0.001424</td>\n",
              "      <td>-0.007116</td>\n",
              "      <td>0.000450</td>\n",
              "      <td>0.004899</td>\n",
              "      <td>0.002939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>La confezione di cartone era già aperta, appen...</td>\n",
              "      <td>negative</td>\n",
              "      <td>la confezion carton già apert appen pres lat t...</td>\n",
              "      <td>[0.21797217894206228, 0.12299623105572668, 0.0...</td>\n",
              "      <td>0.217972</td>\n",
              "      <td>0.122996</td>\n",
              "      <td>0.065318</td>\n",
              "      <td>-0.045467</td>\n",
              "      <td>0.058404</td>\n",
              "      <td>0.044320</td>\n",
              "      <td>0.009989</td>\n",
              "      <td>0.067978</td>\n",
              "      <td>0.051968</td>\n",
              "      <td>-0.041222</td>\n",
              "      <td>-0.274352</td>\n",
              "      <td>-0.081080</td>\n",
              "      <td>0.066843</td>\n",
              "      <td>-0.117769</td>\n",
              "      <td>-0.090430</td>\n",
              "      <td>0.109259</td>\n",
              "      <td>0.094669</td>\n",
              "      <td>-0.007535</td>\n",
              "      <td>-0.113081</td>\n",
              "      <td>-0.007895</td>\n",
              "      <td>0.055765</td>\n",
              "      <td>-0.036258</td>\n",
              "      <td>-0.049051</td>\n",
              "      <td>-0.080781</td>\n",
              "      <td>0.004164</td>\n",
              "      <td>0.025648</td>\n",
              "      <td>-0.068258</td>\n",
              "      <td>0.020109</td>\n",
              "      <td>-0.114043</td>\n",
              "      <td>-0.034672</td>\n",
              "      <td>-0.062693</td>\n",
              "      <td>-0.048389</td>\n",
              "      <td>-0.086449</td>\n",
              "      <td>0.175677</td>\n",
              "      <td>-0.002588</td>\n",
              "      <td>-0.203799</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001298</td>\n",
              "      <td>0.008515</td>\n",
              "      <td>-0.013129</td>\n",
              "      <td>-0.005722</td>\n",
              "      <td>-0.000380</td>\n",
              "      <td>0.002795</td>\n",
              "      <td>0.006812</td>\n",
              "      <td>0.010063</td>\n",
              "      <td>-0.004645</td>\n",
              "      <td>0.002088</td>\n",
              "      <td>0.006688</td>\n",
              "      <td>0.011200</td>\n",
              "      <td>0.006949</td>\n",
              "      <td>0.002952</td>\n",
              "      <td>0.002058</td>\n",
              "      <td>-0.003507</td>\n",
              "      <td>0.005913</td>\n",
              "      <td>0.004957</td>\n",
              "      <td>0.003159</td>\n",
              "      <td>0.003091</td>\n",
              "      <td>-0.003575</td>\n",
              "      <td>-0.002152</td>\n",
              "      <td>-0.002908</td>\n",
              "      <td>0.003800</td>\n",
              "      <td>-0.002425</td>\n",
              "      <td>0.000170</td>\n",
              "      <td>-0.003258</td>\n",
              "      <td>0.003702</td>\n",
              "      <td>0.006239</td>\n",
              "      <td>-0.000163</td>\n",
              "      <td>0.004509</td>\n",
              "      <td>0.000061</td>\n",
              "      <td>0.003800</td>\n",
              "      <td>-0.000824</td>\n",
              "      <td>0.002099</td>\n",
              "      <td>-0.000275</td>\n",
              "      <td>-0.001592</td>\n",
              "      <td>0.004395</td>\n",
              "      <td>0.002083</td>\n",
              "      <td>0.001672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mascherine vendute come \"Maschera Chirurgica 3...</td>\n",
              "      <td>negative</td>\n",
              "      <td>mascherin vend mascher chirurg 3p tip iir conf...</td>\n",
              "      <td>[0.07175741115385922, 0.03131215810517044, 0.0...</td>\n",
              "      <td>0.071757</td>\n",
              "      <td>0.031312</td>\n",
              "      <td>0.035936</td>\n",
              "      <td>-0.057036</td>\n",
              "      <td>0.000778</td>\n",
              "      <td>-0.014077</td>\n",
              "      <td>-0.084098</td>\n",
              "      <td>0.079488</td>\n",
              "      <td>0.059257</td>\n",
              "      <td>-0.149626</td>\n",
              "      <td>-0.212587</td>\n",
              "      <td>-0.042393</td>\n",
              "      <td>0.069109</td>\n",
              "      <td>-0.001030</td>\n",
              "      <td>-0.024891</td>\n",
              "      <td>0.020581</td>\n",
              "      <td>0.087634</td>\n",
              "      <td>0.046171</td>\n",
              "      <td>-0.027870</td>\n",
              "      <td>-0.050561</td>\n",
              "      <td>-0.033546</td>\n",
              "      <td>0.017294</td>\n",
              "      <td>0.057090</td>\n",
              "      <td>0.016539</td>\n",
              "      <td>0.036593</td>\n",
              "      <td>0.041356</td>\n",
              "      <td>-0.170997</td>\n",
              "      <td>0.033856</td>\n",
              "      <td>-0.117031</td>\n",
              "      <td>-0.043175</td>\n",
              "      <td>0.032733</td>\n",
              "      <td>-0.043034</td>\n",
              "      <td>-0.032720</td>\n",
              "      <td>-0.122345</td>\n",
              "      <td>-0.123200</td>\n",
              "      <td>-0.045622</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.003952</td>\n",
              "      <td>-0.002479</td>\n",
              "      <td>0.001994</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.000913</td>\n",
              "      <td>0.001603</td>\n",
              "      <td>0.003920</td>\n",
              "      <td>0.002515</td>\n",
              "      <td>-0.005151</td>\n",
              "      <td>-0.003730</td>\n",
              "      <td>-0.000670</td>\n",
              "      <td>0.001214</td>\n",
              "      <td>-0.000396</td>\n",
              "      <td>-0.001674</td>\n",
              "      <td>0.005860</td>\n",
              "      <td>0.002220</td>\n",
              "      <td>0.001087</td>\n",
              "      <td>0.002812</td>\n",
              "      <td>-0.013707</td>\n",
              "      <td>0.005236</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>-0.007154</td>\n",
              "      <td>-0.001894</td>\n",
              "      <td>-0.000474</td>\n",
              "      <td>0.004815</td>\n",
              "      <td>-0.005157</td>\n",
              "      <td>-0.000861</td>\n",
              "      <td>0.002101</td>\n",
              "      <td>0.003857</td>\n",
              "      <td>0.004209</td>\n",
              "      <td>0.002201</td>\n",
              "      <td>-0.000673</td>\n",
              "      <td>-0.002494</td>\n",
              "      <td>0.000732</td>\n",
              "      <td>0.003137</td>\n",
              "      <td>-0.006297</td>\n",
              "      <td>-0.001338</td>\n",
              "      <td>0.000829</td>\n",
              "      <td>0.000068</td>\n",
              "      <td>0.002367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ARRIVATO APERTO PESSIMO PRODOTTO</td>\n",
              "      <td>negative</td>\n",
              "      <td>arriv apert pessim prodott</td>\n",
              "      <td>[0.024622949971823467, 0.07720488916191945, 0....</td>\n",
              "      <td>0.024623</td>\n",
              "      <td>0.077205</td>\n",
              "      <td>0.104754</td>\n",
              "      <td>-0.133077</td>\n",
              "      <td>0.261053</td>\n",
              "      <td>-0.116749</td>\n",
              "      <td>0.042607</td>\n",
              "      <td>-0.011968</td>\n",
              "      <td>-0.134939</td>\n",
              "      <td>0.107018</td>\n",
              "      <td>-0.065399</td>\n",
              "      <td>0.115100</td>\n",
              "      <td>0.007286</td>\n",
              "      <td>-0.036770</td>\n",
              "      <td>-0.028190</td>\n",
              "      <td>0.009106</td>\n",
              "      <td>0.038686</td>\n",
              "      <td>0.032256</td>\n",
              "      <td>0.056017</td>\n",
              "      <td>-0.048003</td>\n",
              "      <td>-0.017674</td>\n",
              "      <td>0.033227</td>\n",
              "      <td>-0.025836</td>\n",
              "      <td>-0.009794</td>\n",
              "      <td>0.107878</td>\n",
              "      <td>-0.045588</td>\n",
              "      <td>-0.018997</td>\n",
              "      <td>-0.053013</td>\n",
              "      <td>-0.125225</td>\n",
              "      <td>-0.050173</td>\n",
              "      <td>0.085992</td>\n",
              "      <td>-0.243862</td>\n",
              "      <td>0.090571</td>\n",
              "      <td>0.330075</td>\n",
              "      <td>0.078079</td>\n",
              "      <td>-0.182693</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001026</td>\n",
              "      <td>-0.008607</td>\n",
              "      <td>-0.004902</td>\n",
              "      <td>0.005900</td>\n",
              "      <td>0.008167</td>\n",
              "      <td>-0.013703</td>\n",
              "      <td>-0.000115</td>\n",
              "      <td>0.002053</td>\n",
              "      <td>0.012658</td>\n",
              "      <td>0.004097</td>\n",
              "      <td>0.018366</td>\n",
              "      <td>-0.002278</td>\n",
              "      <td>-0.009842</td>\n",
              "      <td>0.003966</td>\n",
              "      <td>-0.007308</td>\n",
              "      <td>0.006488</td>\n",
              "      <td>-0.021583</td>\n",
              "      <td>0.003343</td>\n",
              "      <td>0.003939</td>\n",
              "      <td>-0.007270</td>\n",
              "      <td>0.003429</td>\n",
              "      <td>-0.004072</td>\n",
              "      <td>0.006470</td>\n",
              "      <td>0.007423</td>\n",
              "      <td>-0.008437</td>\n",
              "      <td>0.004770</td>\n",
              "      <td>0.007399</td>\n",
              "      <td>-0.006165</td>\n",
              "      <td>-0.004514</td>\n",
              "      <td>0.005003</td>\n",
              "      <td>-0.002977</td>\n",
              "      <td>-0.004988</td>\n",
              "      <td>0.001843</td>\n",
              "      <td>-0.003085</td>\n",
              "      <td>-0.005825</td>\n",
              "      <td>0.000523</td>\n",
              "      <td>0.005671</td>\n",
              "      <td>-0.007125</td>\n",
              "      <td>-0.004923</td>\n",
              "      <td>0.000338</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 204 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  ...   feat200\n",
              "0  Ho acquistato questa confezione di mascherine ...  ...  0.010876\n",
              "1  Attenzione, ha un ferretto nasale in plastica ...  ...  0.002939\n",
              "2  La confezione di cartone era già aperta, appen...  ...  0.001672\n",
              "3  Mascherine vendute come \"Maschera Chirurgica 3...  ...  0.002367\n",
              "4                   ARRIVATO APERTO PESSIMO PRODOTTO  ...  0.000338\n",
              "\n",
              "[5 rows x 204 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDEzNQwCUluK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "outputId": "eb197a63-cbb9-4440-8858-c1a1e8736cbe"
      },
      "source": [
        "TrainData.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Processed Text</th>\n",
              "      <th>TfIdfVectors</th>\n",
              "      <th>feat1</th>\n",
              "      <th>feat2</th>\n",
              "      <th>feat3</th>\n",
              "      <th>feat4</th>\n",
              "      <th>feat5</th>\n",
              "      <th>feat6</th>\n",
              "      <th>feat7</th>\n",
              "      <th>feat8</th>\n",
              "      <th>feat9</th>\n",
              "      <th>feat10</th>\n",
              "      <th>feat11</th>\n",
              "      <th>feat12</th>\n",
              "      <th>feat13</th>\n",
              "      <th>feat14</th>\n",
              "      <th>feat15</th>\n",
              "      <th>feat16</th>\n",
              "      <th>feat17</th>\n",
              "      <th>feat18</th>\n",
              "      <th>feat19</th>\n",
              "      <th>feat20</th>\n",
              "      <th>feat21</th>\n",
              "      <th>feat22</th>\n",
              "      <th>feat23</th>\n",
              "      <th>feat24</th>\n",
              "      <th>feat25</th>\n",
              "      <th>feat26</th>\n",
              "      <th>feat27</th>\n",
              "      <th>feat28</th>\n",
              "      <th>feat29</th>\n",
              "      <th>feat30</th>\n",
              "      <th>feat31</th>\n",
              "      <th>feat32</th>\n",
              "      <th>feat33</th>\n",
              "      <th>feat34</th>\n",
              "      <th>feat35</th>\n",
              "      <th>feat36</th>\n",
              "      <th>...</th>\n",
              "      <th>feat161</th>\n",
              "      <th>feat162</th>\n",
              "      <th>feat163</th>\n",
              "      <th>feat164</th>\n",
              "      <th>feat165</th>\n",
              "      <th>feat166</th>\n",
              "      <th>feat167</th>\n",
              "      <th>feat168</th>\n",
              "      <th>feat169</th>\n",
              "      <th>feat170</th>\n",
              "      <th>feat171</th>\n",
              "      <th>feat172</th>\n",
              "      <th>feat173</th>\n",
              "      <th>feat174</th>\n",
              "      <th>feat175</th>\n",
              "      <th>feat176</th>\n",
              "      <th>feat177</th>\n",
              "      <th>feat178</th>\n",
              "      <th>feat179</th>\n",
              "      <th>feat180</th>\n",
              "      <th>feat181</th>\n",
              "      <th>feat182</th>\n",
              "      <th>feat183</th>\n",
              "      <th>feat184</th>\n",
              "      <th>feat185</th>\n",
              "      <th>feat186</th>\n",
              "      <th>feat187</th>\n",
              "      <th>feat188</th>\n",
              "      <th>feat189</th>\n",
              "      <th>feat190</th>\n",
              "      <th>feat191</th>\n",
              "      <th>feat192</th>\n",
              "      <th>feat193</th>\n",
              "      <th>feat194</th>\n",
              "      <th>feat195</th>\n",
              "      <th>feat196</th>\n",
              "      <th>feat197</th>\n",
              "      <th>feat198</th>\n",
              "      <th>feat199</th>\n",
              "      <th>feat200</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ho acquistato questa confezione di mascherine ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>ho acquist confezion mascherin 19 99 quind 40 ...</td>\n",
              "      <td>[0.27247792065239457, 0.21972266346699976, 0.0...</td>\n",
              "      <td>0.272478</td>\n",
              "      <td>0.219723</td>\n",
              "      <td>0.024187</td>\n",
              "      <td>-0.035276</td>\n",
              "      <td>-0.060019</td>\n",
              "      <td>0.032466</td>\n",
              "      <td>-0.140034</td>\n",
              "      <td>-0.021274</td>\n",
              "      <td>0.010797</td>\n",
              "      <td>-0.139642</td>\n",
              "      <td>-0.248782</td>\n",
              "      <td>-0.112859</td>\n",
              "      <td>0.077791</td>\n",
              "      <td>-0.032370</td>\n",
              "      <td>-0.078478</td>\n",
              "      <td>0.049554</td>\n",
              "      <td>0.066917</td>\n",
              "      <td>-0.007913</td>\n",
              "      <td>-0.012080</td>\n",
              "      <td>-0.078611</td>\n",
              "      <td>0.038777</td>\n",
              "      <td>0.035575</td>\n",
              "      <td>-0.046226</td>\n",
              "      <td>0.047796</td>\n",
              "      <td>0.095787</td>\n",
              "      <td>-0.013445</td>\n",
              "      <td>0.033574</td>\n",
              "      <td>-0.046113</td>\n",
              "      <td>0.052642</td>\n",
              "      <td>0.079219</td>\n",
              "      <td>0.009382</td>\n",
              "      <td>0.105429</td>\n",
              "      <td>0.146709</td>\n",
              "      <td>0.016257</td>\n",
              "      <td>0.265021</td>\n",
              "      <td>0.183178</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000712</td>\n",
              "      <td>0.003130</td>\n",
              "      <td>0.007188</td>\n",
              "      <td>-0.002206</td>\n",
              "      <td>0.016861</td>\n",
              "      <td>0.005693</td>\n",
              "      <td>0.007154</td>\n",
              "      <td>-0.008933</td>\n",
              "      <td>-0.001005</td>\n",
              "      <td>-0.001717</td>\n",
              "      <td>-0.006622</td>\n",
              "      <td>0.010369</td>\n",
              "      <td>-0.006517</td>\n",
              "      <td>0.000171</td>\n",
              "      <td>-0.007744</td>\n",
              "      <td>-0.008937</td>\n",
              "      <td>-0.002413</td>\n",
              "      <td>-0.011081</td>\n",
              "      <td>-0.007513</td>\n",
              "      <td>0.016864</td>\n",
              "      <td>-0.013261</td>\n",
              "      <td>0.015795</td>\n",
              "      <td>-0.013149</td>\n",
              "      <td>-0.005551</td>\n",
              "      <td>0.005734</td>\n",
              "      <td>0.001783</td>\n",
              "      <td>0.001591</td>\n",
              "      <td>0.003175</td>\n",
              "      <td>-0.005366</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>0.007140</td>\n",
              "      <td>0.002043</td>\n",
              "      <td>-0.014306</td>\n",
              "      <td>-0.009748</td>\n",
              "      <td>0.001553</td>\n",
              "      <td>0.003029</td>\n",
              "      <td>0.013427</td>\n",
              "      <td>-0.001351</td>\n",
              "      <td>0.001680</td>\n",
              "      <td>0.010876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Attenzione, ha un ferretto nasale in plastica ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>attenzion ferrett nasal plastic permett far ad...</td>\n",
              "      <td>[0.16908623342662926, 0.09757413226524703, -0....</td>\n",
              "      <td>0.169086</td>\n",
              "      <td>0.097574</td>\n",
              "      <td>-0.005238</td>\n",
              "      <td>-0.042576</td>\n",
              "      <td>-0.009253</td>\n",
              "      <td>0.007023</td>\n",
              "      <td>-0.082983</td>\n",
              "      <td>-0.028276</td>\n",
              "      <td>0.077973</td>\n",
              "      <td>-0.068384</td>\n",
              "      <td>-0.041844</td>\n",
              "      <td>-0.048824</td>\n",
              "      <td>0.046407</td>\n",
              "      <td>-0.028404</td>\n",
              "      <td>-0.075385</td>\n",
              "      <td>0.050105</td>\n",
              "      <td>0.039076</td>\n",
              "      <td>-0.017067</td>\n",
              "      <td>0.119496</td>\n",
              "      <td>-0.014493</td>\n",
              "      <td>0.042645</td>\n",
              "      <td>0.027865</td>\n",
              "      <td>-0.005659</td>\n",
              "      <td>0.073627</td>\n",
              "      <td>0.059247</td>\n",
              "      <td>-0.073071</td>\n",
              "      <td>0.085659</td>\n",
              "      <td>-0.066784</td>\n",
              "      <td>0.108375</td>\n",
              "      <td>0.043017</td>\n",
              "      <td>-0.071770</td>\n",
              "      <td>0.073374</td>\n",
              "      <td>0.198330</td>\n",
              "      <td>-0.035712</td>\n",
              "      <td>0.394452</td>\n",
              "      <td>0.091456</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008430</td>\n",
              "      <td>-0.002051</td>\n",
              "      <td>0.005653</td>\n",
              "      <td>-0.001060</td>\n",
              "      <td>-0.001239</td>\n",
              "      <td>-0.003488</td>\n",
              "      <td>-0.000415</td>\n",
              "      <td>-0.009582</td>\n",
              "      <td>0.009058</td>\n",
              "      <td>-0.001457</td>\n",
              "      <td>-0.003282</td>\n",
              "      <td>-0.006317</td>\n",
              "      <td>0.003986</td>\n",
              "      <td>-0.007342</td>\n",
              "      <td>-0.003682</td>\n",
              "      <td>-0.001634</td>\n",
              "      <td>0.004405</td>\n",
              "      <td>-0.001732</td>\n",
              "      <td>0.009430</td>\n",
              "      <td>0.000913</td>\n",
              "      <td>0.002386</td>\n",
              "      <td>-0.002332</td>\n",
              "      <td>-0.004043</td>\n",
              "      <td>0.001671</td>\n",
              "      <td>0.004705</td>\n",
              "      <td>0.012583</td>\n",
              "      <td>-0.000720</td>\n",
              "      <td>0.003781</td>\n",
              "      <td>-0.000824</td>\n",
              "      <td>-0.007811</td>\n",
              "      <td>0.002804</td>\n",
              "      <td>0.002463</td>\n",
              "      <td>-0.001740</td>\n",
              "      <td>0.002401</td>\n",
              "      <td>-0.001963</td>\n",
              "      <td>0.001424</td>\n",
              "      <td>-0.007116</td>\n",
              "      <td>0.000450</td>\n",
              "      <td>0.004899</td>\n",
              "      <td>0.002939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>La confezione di cartone era già aperta, appen...</td>\n",
              "      <td>negative</td>\n",
              "      <td>la confezion carton già apert appen pres lat t...</td>\n",
              "      <td>[0.21797217894206228, 0.12299623105572668, 0.0...</td>\n",
              "      <td>0.217972</td>\n",
              "      <td>0.122996</td>\n",
              "      <td>0.065318</td>\n",
              "      <td>-0.045467</td>\n",
              "      <td>0.058404</td>\n",
              "      <td>0.044320</td>\n",
              "      <td>0.009989</td>\n",
              "      <td>0.067978</td>\n",
              "      <td>0.051968</td>\n",
              "      <td>-0.041222</td>\n",
              "      <td>-0.274352</td>\n",
              "      <td>-0.081080</td>\n",
              "      <td>0.066843</td>\n",
              "      <td>-0.117769</td>\n",
              "      <td>-0.090430</td>\n",
              "      <td>0.109259</td>\n",
              "      <td>0.094669</td>\n",
              "      <td>-0.007535</td>\n",
              "      <td>-0.113081</td>\n",
              "      <td>-0.007895</td>\n",
              "      <td>0.055765</td>\n",
              "      <td>-0.036258</td>\n",
              "      <td>-0.049051</td>\n",
              "      <td>-0.080781</td>\n",
              "      <td>0.004164</td>\n",
              "      <td>0.025648</td>\n",
              "      <td>-0.068258</td>\n",
              "      <td>0.020109</td>\n",
              "      <td>-0.114043</td>\n",
              "      <td>-0.034672</td>\n",
              "      <td>-0.062693</td>\n",
              "      <td>-0.048389</td>\n",
              "      <td>-0.086449</td>\n",
              "      <td>0.175677</td>\n",
              "      <td>-0.002588</td>\n",
              "      <td>-0.203799</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001298</td>\n",
              "      <td>0.008515</td>\n",
              "      <td>-0.013129</td>\n",
              "      <td>-0.005722</td>\n",
              "      <td>-0.000380</td>\n",
              "      <td>0.002795</td>\n",
              "      <td>0.006812</td>\n",
              "      <td>0.010063</td>\n",
              "      <td>-0.004645</td>\n",
              "      <td>0.002088</td>\n",
              "      <td>0.006688</td>\n",
              "      <td>0.011200</td>\n",
              "      <td>0.006949</td>\n",
              "      <td>0.002952</td>\n",
              "      <td>0.002058</td>\n",
              "      <td>-0.003507</td>\n",
              "      <td>0.005913</td>\n",
              "      <td>0.004957</td>\n",
              "      <td>0.003159</td>\n",
              "      <td>0.003091</td>\n",
              "      <td>-0.003575</td>\n",
              "      <td>-0.002152</td>\n",
              "      <td>-0.002908</td>\n",
              "      <td>0.003800</td>\n",
              "      <td>-0.002425</td>\n",
              "      <td>0.000170</td>\n",
              "      <td>-0.003258</td>\n",
              "      <td>0.003702</td>\n",
              "      <td>0.006239</td>\n",
              "      <td>-0.000163</td>\n",
              "      <td>0.004509</td>\n",
              "      <td>0.000061</td>\n",
              "      <td>0.003800</td>\n",
              "      <td>-0.000824</td>\n",
              "      <td>0.002099</td>\n",
              "      <td>-0.000275</td>\n",
              "      <td>-0.001592</td>\n",
              "      <td>0.004395</td>\n",
              "      <td>0.002083</td>\n",
              "      <td>0.001672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mascherine vendute come \"Maschera Chirurgica 3...</td>\n",
              "      <td>negative</td>\n",
              "      <td>mascherin vend mascher chirurg 3p tip iir conf...</td>\n",
              "      <td>[0.07175741115385922, 0.03131215810517044, 0.0...</td>\n",
              "      <td>0.071757</td>\n",
              "      <td>0.031312</td>\n",
              "      <td>0.035936</td>\n",
              "      <td>-0.057036</td>\n",
              "      <td>0.000778</td>\n",
              "      <td>-0.014077</td>\n",
              "      <td>-0.084098</td>\n",
              "      <td>0.079488</td>\n",
              "      <td>0.059257</td>\n",
              "      <td>-0.149626</td>\n",
              "      <td>-0.212587</td>\n",
              "      <td>-0.042393</td>\n",
              "      <td>0.069109</td>\n",
              "      <td>-0.001030</td>\n",
              "      <td>-0.024891</td>\n",
              "      <td>0.020581</td>\n",
              "      <td>0.087634</td>\n",
              "      <td>0.046171</td>\n",
              "      <td>-0.027870</td>\n",
              "      <td>-0.050561</td>\n",
              "      <td>-0.033546</td>\n",
              "      <td>0.017294</td>\n",
              "      <td>0.057090</td>\n",
              "      <td>0.016539</td>\n",
              "      <td>0.036593</td>\n",
              "      <td>0.041356</td>\n",
              "      <td>-0.170997</td>\n",
              "      <td>0.033856</td>\n",
              "      <td>-0.117031</td>\n",
              "      <td>-0.043175</td>\n",
              "      <td>0.032733</td>\n",
              "      <td>-0.043034</td>\n",
              "      <td>-0.032720</td>\n",
              "      <td>-0.122345</td>\n",
              "      <td>-0.123200</td>\n",
              "      <td>-0.045622</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.003952</td>\n",
              "      <td>-0.002479</td>\n",
              "      <td>0.001994</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.000913</td>\n",
              "      <td>0.001603</td>\n",
              "      <td>0.003920</td>\n",
              "      <td>0.002515</td>\n",
              "      <td>-0.005151</td>\n",
              "      <td>-0.003730</td>\n",
              "      <td>-0.000670</td>\n",
              "      <td>0.001214</td>\n",
              "      <td>-0.000396</td>\n",
              "      <td>-0.001674</td>\n",
              "      <td>0.005860</td>\n",
              "      <td>0.002220</td>\n",
              "      <td>0.001087</td>\n",
              "      <td>0.002812</td>\n",
              "      <td>-0.013707</td>\n",
              "      <td>0.005236</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>-0.007154</td>\n",
              "      <td>-0.001894</td>\n",
              "      <td>-0.000474</td>\n",
              "      <td>0.004815</td>\n",
              "      <td>-0.005157</td>\n",
              "      <td>-0.000861</td>\n",
              "      <td>0.002101</td>\n",
              "      <td>0.003857</td>\n",
              "      <td>0.004209</td>\n",
              "      <td>0.002201</td>\n",
              "      <td>-0.000673</td>\n",
              "      <td>-0.002494</td>\n",
              "      <td>0.000732</td>\n",
              "      <td>0.003137</td>\n",
              "      <td>-0.006297</td>\n",
              "      <td>-0.001338</td>\n",
              "      <td>0.000829</td>\n",
              "      <td>0.000068</td>\n",
              "      <td>0.002367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ARRIVATO APERTO PESSIMO PRODOTTO</td>\n",
              "      <td>negative</td>\n",
              "      <td>arriv apert pessim prodott</td>\n",
              "      <td>[0.024622949971823467, 0.07720488916191945, 0....</td>\n",
              "      <td>0.024623</td>\n",
              "      <td>0.077205</td>\n",
              "      <td>0.104754</td>\n",
              "      <td>-0.133077</td>\n",
              "      <td>0.261053</td>\n",
              "      <td>-0.116749</td>\n",
              "      <td>0.042607</td>\n",
              "      <td>-0.011968</td>\n",
              "      <td>-0.134939</td>\n",
              "      <td>0.107018</td>\n",
              "      <td>-0.065399</td>\n",
              "      <td>0.115100</td>\n",
              "      <td>0.007286</td>\n",
              "      <td>-0.036770</td>\n",
              "      <td>-0.028190</td>\n",
              "      <td>0.009106</td>\n",
              "      <td>0.038686</td>\n",
              "      <td>0.032256</td>\n",
              "      <td>0.056017</td>\n",
              "      <td>-0.048003</td>\n",
              "      <td>-0.017674</td>\n",
              "      <td>0.033227</td>\n",
              "      <td>-0.025836</td>\n",
              "      <td>-0.009794</td>\n",
              "      <td>0.107878</td>\n",
              "      <td>-0.045588</td>\n",
              "      <td>-0.018997</td>\n",
              "      <td>-0.053013</td>\n",
              "      <td>-0.125225</td>\n",
              "      <td>-0.050173</td>\n",
              "      <td>0.085992</td>\n",
              "      <td>-0.243862</td>\n",
              "      <td>0.090571</td>\n",
              "      <td>0.330075</td>\n",
              "      <td>0.078079</td>\n",
              "      <td>-0.182693</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001026</td>\n",
              "      <td>-0.008607</td>\n",
              "      <td>-0.004902</td>\n",
              "      <td>0.005900</td>\n",
              "      <td>0.008167</td>\n",
              "      <td>-0.013703</td>\n",
              "      <td>-0.000115</td>\n",
              "      <td>0.002053</td>\n",
              "      <td>0.012658</td>\n",
              "      <td>0.004097</td>\n",
              "      <td>0.018366</td>\n",
              "      <td>-0.002278</td>\n",
              "      <td>-0.009842</td>\n",
              "      <td>0.003966</td>\n",
              "      <td>-0.007308</td>\n",
              "      <td>0.006488</td>\n",
              "      <td>-0.021583</td>\n",
              "      <td>0.003343</td>\n",
              "      <td>0.003939</td>\n",
              "      <td>-0.007270</td>\n",
              "      <td>0.003429</td>\n",
              "      <td>-0.004072</td>\n",
              "      <td>0.006470</td>\n",
              "      <td>0.007423</td>\n",
              "      <td>-0.008437</td>\n",
              "      <td>0.004770</td>\n",
              "      <td>0.007399</td>\n",
              "      <td>-0.006165</td>\n",
              "      <td>-0.004514</td>\n",
              "      <td>0.005003</td>\n",
              "      <td>-0.002977</td>\n",
              "      <td>-0.004988</td>\n",
              "      <td>0.001843</td>\n",
              "      <td>-0.003085</td>\n",
              "      <td>-0.005825</td>\n",
              "      <td>0.000523</td>\n",
              "      <td>0.005671</td>\n",
              "      <td>-0.007125</td>\n",
              "      <td>-0.004923</td>\n",
              "      <td>0.000338</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 204 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  ...   feat200\n",
              "0  Ho acquistato questa confezione di mascherine ...  ...  0.010876\n",
              "1  Attenzione, ha un ferretto nasale in plastica ...  ...  0.002939\n",
              "2  La confezione di cartone era già aperta, appen...  ...  0.001672\n",
              "3  Mascherine vendute come \"Maschera Chirurgica 3...  ...  0.002367\n",
              "4                   ARRIVATO APERTO PESSIMO PRODOTTO  ...  0.000338\n",
              "\n",
              "[5 rows x 204 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWVhONDE8sqq",
        "colab_type": "text"
      },
      "source": [
        "## Find the best"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eX5hCTitOXYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYN1oaQiOXre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df100 = pd.read_csv('/content/drive/My Drive/Topic detection/Df100.csv', index_col=0)\n",
        "df200 = pd.read_csv('/content/drive/My Drive/Topic detection/Df200.csv', index_col=0)\n",
        "df300 = pd.read_csv('/content/drive/My Drive/Topic detection/Df300.csv', index_col=0)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wCEJYO7OXyU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "17837ee3-4bc6-4a14-fe86-79d6969b5956"
      },
      "source": [
        "import numpy as np\n",
        "import pylab as pl\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUoMeuiPOX4u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C-q2haU-SlL7",
        "colab": {}
      },
      "source": [
        "def SVM_model(TrainData):\n",
        "\n",
        "    X_train2, X_test2, y_train2, y_test2 = train_test_split( TrainData.drop(['Text', 'Sentiment', 'Processed Text'], axis = 1),\n",
        "    TrainData['Sentiment'], test_size=0.3, random_state=42)\n",
        "\n",
        "    from sklearn import preprocessing\n",
        "    encoder = preprocessing.LabelEncoder()\n",
        "\n",
        "    # encoding train labels \n",
        "    encoder.fit(y_train2)\n",
        "    Y_train2 = encoder.transform(y_train2)\n",
        "\n",
        "    encoder = preprocessing.LabelEncoder()\n",
        "\n",
        "    # encoding y_test2 labels \n",
        "    encoder.fit(y_test2)\n",
        "    Y_test2 = encoder.transform(y_test2)\n",
        "\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled2 = scaler.fit_transform(X_train2)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_test_scaled2 = scaler.fit_transform(X_test2)\n",
        "\n",
        "\n",
        "    params_grid = [{'kernel': ['rbf', 'poly', 'linear', 'sigmoid'], 'gamma': [5e-3, 3e-4, 1e-5],\n",
        "                        'C': [10, 20, 50, 100, 200]} ]\n",
        "\n",
        "\n",
        "\n",
        "    svm_model = GridSearchCV(SVC(), params_grid, cv=5,  n_jobs = 12, verbose = 12)\n",
        "    svm_model.fit(X_train_scaled2, y_train2)\n",
        "\n",
        "\n",
        "    final_model = svm_model.best_estimator_\n",
        "\n",
        "    Y_pred = final_model.predict(X_test_scaled2)\n",
        "    #Y_pred_label = list(encoder.inverse_transform(Y_pred))\n",
        "    #Y_pred is cathegorical\n",
        "\n",
        "    print(confusion_matrix(y_test2,Y_pred))\n",
        "    print(\"\\n\")\n",
        "    print(classification_report(y_test2,Y_pred))\n",
        "\n",
        "    print(\"Training set score for SVM: %f\" % final_model.score(X_train_scaled2 , y_train2))\n",
        "    print(\"Testing  set score for SVM: %f\" % final_model.score(X_test_scaled2  , y_test2 ))\n",
        "    from sklearn.metrics import accuracy_score\n",
        "\n",
        "    return(accuracy_score(Y_pred ,y_test2))\n",
        "    #svm_model.score\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Tx9A_L_ZSlM0",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "def bernouli(TrainData):\n",
        "\n",
        "    X_train2, X_test2, y_train2, y_test2 = train_test_split( TrainData.drop(['Text', 'Sentiment', 'Processed Text'], axis = 1),\n",
        "    TrainData['Sentiment'], test_size=0.3, random_state=42)\n",
        "\n",
        "    from sklearn import preprocessing\n",
        "    encoder = preprocessing.LabelEncoder()\n",
        "\n",
        "    # encoding train labels \n",
        "    encoder.fit(y_train2)\n",
        "    Y_train2 = encoder.transform(y_train2)\n",
        "\n",
        "    encoder = preprocessing.LabelEncoder()\n",
        "\n",
        "    # encoding y_test2 labels \n",
        "    encoder.fit(y_test2)\n",
        "    Y_test2 = encoder.transform(y_test2)\n",
        "\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled2 = scaler.fit_transform(X_train2)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_test_scaled2 = scaler.fit_transform(X_test2)\n",
        "\n",
        "    gnb =   BernoulliNB()\n",
        "    Y_pred = gnb.fit(X_train2, y_train2).predict(X_test2)\n",
        "\n",
        "    print(confusion_matrix(y_test2,Y_pred))\n",
        "    print(\"\\n\")\n",
        "    print(classification_report(y_test2,Y_pred))\n",
        "\n",
        "    print(\"Training set score for BNB: %f\" % gnb.score(X_train_scaled2 , y_train2))\n",
        "    print(\"Testing  set score for BNB: %f\" % gnb.score(X_test_scaled2  , y_test2 ))\n",
        "    return(accuracy_score(Y_pred ,y_test2))\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3it5XUYj6yO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "\n",
        "def multinomial(TrainData):\n",
        "\n",
        "    X_train2, X_test2, y_train2, y_test2 = train_test_split( TrainData.drop(['Text', 'Sentiment', 'Processed Text'], axis = 1),\n",
        "    TrainData['Sentiment'], test_size=0.3, random_state=42)\n",
        "\n",
        "    from sklearn import preprocessing\n",
        "    encoder = preprocessing.LabelEncoder()\n",
        "\n",
        "    # encoding train labels \n",
        "    encoder.fit(y_train2)\n",
        "    Y_train2 = encoder.transform(y_train2)\n",
        "\n",
        "    encoder = preprocessing.LabelEncoder()\n",
        "\n",
        "    # encoding y_test2 labels \n",
        "    encoder.fit(y_test2)\n",
        "    Y_test2 = encoder.transform(y_test2)\n",
        "\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled2 = scaler.fit_transform(X_train2)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_test_scaled2 = scaler.fit_transform(X_test2)\n",
        "\n",
        "    \n",
        "    clf = MultinomialNB()\n",
        "    Y_pred = clf.fit(X_train2, y_train2).predict(X_test2)\n",
        "    Y_pred = gnb.fit(X_train2, y_train2).predict(X_test2)\n",
        "\n",
        "    print(confusion_matrix(y_test2,Y_pred))\n",
        "    print(\"\\n\")\n",
        "    print(classification_report(y_test2,Y_pred))\n",
        "\n",
        "    print(\"Training set score for BNB: %f\" % gnb.score(X_train_scaled2 , y_train2))\n",
        "    print(\"Testing  set score for BNB: %f\" % gnb.score(X_test_scaled2  , y_test2 ))\n",
        "    return(accuracy_score(Y_pred ,y_test2))\n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHnKM8nLOX-e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "405a255f-ead9-4529-87f9-a8d9bbb308ab"
      },
      "source": [
        "svm_scores=[]\n",
        "docs = [df100,df200,df300]\n",
        "for i in docs:\n",
        "  svm_scores.append(SVM_model(i))\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=12)]: Done   1 tasks      | elapsed:    4.9s\n",
            "[Parallel(n_jobs=12)]: Done   2 tasks      | elapsed:    5.0s\n",
            "[Parallel(n_jobs=12)]: Done   3 tasks      | elapsed:    5.3s\n",
            "[Parallel(n_jobs=12)]: Done   4 tasks      | elapsed:    5.3s\n",
            "[Parallel(n_jobs=12)]: Done   5 tasks      | elapsed:    5.4s\n",
            "[Parallel(n_jobs=12)]: Done   6 tasks      | elapsed:    5.4s\n",
            "[Parallel(n_jobs=12)]: Done   7 tasks      | elapsed:    5.5s\n",
            "[Parallel(n_jobs=12)]: Done   8 tasks      | elapsed:    5.6s\n",
            "[Parallel(n_jobs=12)]: Done   9 tasks      | elapsed:    5.6s\n",
            "[Parallel(n_jobs=12)]: Done  10 tasks      | elapsed:    5.7s\n",
            "[Parallel(n_jobs=12)]: Done  11 tasks      | elapsed:    5.8s\n",
            "[Parallel(n_jobs=12)]: Done  12 tasks      | elapsed:    5.9s\n",
            "[Parallel(n_jobs=12)]: Done  13 tasks      | elapsed:    5.9s\n",
            "[Parallel(n_jobs=12)]: Done  14 tasks      | elapsed:    5.9s\n",
            "[Parallel(n_jobs=12)]: Done  15 tasks      | elapsed:    6.1s\n",
            "[Parallel(n_jobs=12)]: Done  16 tasks      | elapsed:    6.1s\n",
            "[Parallel(n_jobs=12)]: Done  17 tasks      | elapsed:    6.1s\n",
            "[Parallel(n_jobs=12)]: Done  18 tasks      | elapsed:    6.2s\n",
            "[Parallel(n_jobs=12)]: Done  19 tasks      | elapsed:    6.2s\n",
            "[Parallel(n_jobs=12)]: Done  20 tasks      | elapsed:    6.4s\n",
            "[Parallel(n_jobs=12)]: Done  21 tasks      | elapsed:    6.4s\n",
            "[Parallel(n_jobs=12)]: Done  22 tasks      | elapsed:    6.4s\n",
            "[Parallel(n_jobs=12)]: Done  23 tasks      | elapsed:    6.4s\n",
            "[Parallel(n_jobs=12)]: Done  24 tasks      | elapsed:    6.4s\n",
            "[Parallel(n_jobs=12)]: Done  25 tasks      | elapsed:    6.5s\n",
            "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    6.6s\n",
            "[Parallel(n_jobs=12)]: Done  27 tasks      | elapsed:    6.6s\n",
            "[Parallel(n_jobs=12)]: Done  28 tasks      | elapsed:    6.6s\n",
            "[Parallel(n_jobs=12)]: Done  29 tasks      | elapsed:    6.7s\n",
            "[Parallel(n_jobs=12)]: Done  30 tasks      | elapsed:    6.8s\n",
            "[Parallel(n_jobs=12)]: Done  31 tasks      | elapsed:    6.9s\n",
            "[Parallel(n_jobs=12)]: Done  32 tasks      | elapsed:    6.9s\n",
            "[Parallel(n_jobs=12)]: Done  33 tasks      | elapsed:    6.9s\n",
            "[Parallel(n_jobs=12)]: Done  34 tasks      | elapsed:    7.0s\n",
            "[Parallel(n_jobs=12)]: Done  35 tasks      | elapsed:    7.1s\n",
            "[Parallel(n_jobs=12)]: Done  36 tasks      | elapsed:    7.2s\n",
            "[Parallel(n_jobs=12)]: Done  37 tasks      | elapsed:    7.2s\n",
            "[Parallel(n_jobs=12)]: Done  38 tasks      | elapsed:    7.2s\n",
            "[Parallel(n_jobs=12)]: Done  39 tasks      | elapsed:    7.3s\n",
            "[Parallel(n_jobs=12)]: Done  40 tasks      | elapsed:    7.4s\n",
            "[Parallel(n_jobs=12)]: Done  41 tasks      | elapsed:    7.5s\n",
            "[Parallel(n_jobs=12)]: Done  42 tasks      | elapsed:    7.5s\n",
            "[Parallel(n_jobs=12)]: Done  43 tasks      | elapsed:    7.5s\n",
            "[Parallel(n_jobs=12)]: Done  44 tasks      | elapsed:    7.5s\n",
            "[Parallel(n_jobs=12)]: Done  45 tasks      | elapsed:    7.5s\n",
            "[Parallel(n_jobs=12)]: Done  46 tasks      | elapsed:    7.7s\n",
            "[Parallel(n_jobs=12)]: Done  47 tasks      | elapsed:    7.7s\n",
            "[Parallel(n_jobs=12)]: Done  48 tasks      | elapsed:    7.7s\n",
            "[Parallel(n_jobs=12)]: Done  49 tasks      | elapsed:    7.8s\n",
            "[Parallel(n_jobs=12)]: Done  50 tasks      | elapsed:    7.8s\n",
            "[Parallel(n_jobs=12)]: Done  51 tasks      | elapsed:    8.0s\n",
            "[Parallel(n_jobs=12)]: Done  52 tasks      | elapsed:    8.0s\n",
            "[Parallel(n_jobs=12)]: Done  53 tasks      | elapsed:    8.0s\n",
            "[Parallel(n_jobs=12)]: Done  54 tasks      | elapsed:    8.0s\n",
            "[Parallel(n_jobs=12)]: Done  55 tasks      | elapsed:    8.0s\n",
            "[Parallel(n_jobs=12)]: Done  56 tasks      | elapsed:    8.2s\n",
            "[Parallel(n_jobs=12)]: Done  57 tasks      | elapsed:    8.2s\n",
            "[Parallel(n_jobs=12)]: Done  58 tasks      | elapsed:    8.2s\n",
            "[Parallel(n_jobs=12)]: Done  59 tasks      | elapsed:    8.3s\n",
            "[Parallel(n_jobs=12)]: Done  60 tasks      | elapsed:    8.3s\n",
            "[Parallel(n_jobs=12)]: Done  61 tasks      | elapsed:    8.4s\n",
            "[Parallel(n_jobs=12)]: Done  62 tasks      | elapsed:    8.4s\n",
            "[Parallel(n_jobs=12)]: Done  63 tasks      | elapsed:    8.4s\n",
            "[Parallel(n_jobs=12)]: Done  64 tasks      | elapsed:    8.4s\n",
            "[Parallel(n_jobs=12)]: Done  65 tasks      | elapsed:    8.5s\n",
            "[Parallel(n_jobs=12)]: Done  66 tasks      | elapsed:    8.5s\n",
            "[Parallel(n_jobs=12)]: Done  67 tasks      | elapsed:    8.6s\n",
            "[Parallel(n_jobs=12)]: Done  68 tasks      | elapsed:    8.6s\n",
            "[Parallel(n_jobs=12)]: Done  69 tasks      | elapsed:    8.6s\n",
            "[Parallel(n_jobs=12)]: Done  70 tasks      | elapsed:    8.7s\n",
            "[Parallel(n_jobs=12)]: Done  71 tasks      | elapsed:    8.7s\n",
            "[Parallel(n_jobs=12)]: Done  72 tasks      | elapsed:    8.7s\n",
            "[Parallel(n_jobs=12)]: Done  73 tasks      | elapsed:    8.7s\n",
            "[Parallel(n_jobs=12)]: Done  74 tasks      | elapsed:    8.9s\n",
            "[Parallel(n_jobs=12)]: Done  75 tasks      | elapsed:    8.9s\n",
            "[Parallel(n_jobs=12)]: Done  76 tasks      | elapsed:    9.0s\n",
            "[Parallel(n_jobs=12)]: Done  77 tasks      | elapsed:    9.0s\n",
            "[Parallel(n_jobs=12)]: Done  78 tasks      | elapsed:    9.0s\n",
            "[Parallel(n_jobs=12)]: Done  79 tasks      | elapsed:    9.1s\n",
            "[Parallel(n_jobs=12)]: Done  80 tasks      | elapsed:    9.2s\n",
            "[Parallel(n_jobs=12)]: Done  81 tasks      | elapsed:    9.2s\n",
            "[Parallel(n_jobs=12)]: Done  82 tasks      | elapsed:    9.2s\n",
            "[Parallel(n_jobs=12)]: Done  83 tasks      | elapsed:    9.3s\n",
            "[Parallel(n_jobs=12)]: Done  84 tasks      | elapsed:    9.3s\n",
            "[Parallel(n_jobs=12)]: Done  85 tasks      | elapsed:    9.4s\n",
            "[Parallel(n_jobs=12)]: Done  86 tasks      | elapsed:    9.4s\n",
            "[Parallel(n_jobs=12)]: Done  87 tasks      | elapsed:    9.4s\n",
            "[Parallel(n_jobs=12)]: Done  88 tasks      | elapsed:    9.5s\n",
            "[Parallel(n_jobs=12)]: Done  89 tasks      | elapsed:    9.5s\n",
            "[Parallel(n_jobs=12)]: Done  90 tasks      | elapsed:    9.6s\n",
            "[Parallel(n_jobs=12)]: Done  91 tasks      | elapsed:    9.6s\n",
            "[Parallel(n_jobs=12)]: Done  92 tasks      | elapsed:    9.7s\n",
            "[Parallel(n_jobs=12)]: Done  93 tasks      | elapsed:    9.7s\n",
            "[Parallel(n_jobs=12)]: Done  94 tasks      | elapsed:    9.9s\n",
            "[Parallel(n_jobs=12)]: Done  95 tasks      | elapsed:    9.9s\n",
            "[Parallel(n_jobs=12)]: Done  96 tasks      | elapsed:   10.0s\n",
            "[Parallel(n_jobs=12)]: Done  97 tasks      | elapsed:   10.0s\n",
            "[Parallel(n_jobs=12)]: Done  98 tasks      | elapsed:   10.0s\n",
            "[Parallel(n_jobs=12)]: Done  99 tasks      | elapsed:   10.1s\n",
            "[Parallel(n_jobs=12)]: Done 100 tasks      | elapsed:   10.2s\n",
            "[Parallel(n_jobs=12)]: Done 101 tasks      | elapsed:   10.2s\n",
            "[Parallel(n_jobs=12)]: Done 102 tasks      | elapsed:   10.3s\n",
            "[Parallel(n_jobs=12)]: Done 103 tasks      | elapsed:   10.3s\n",
            "[Parallel(n_jobs=12)]: Done 104 tasks      | elapsed:   10.3s\n",
            "[Parallel(n_jobs=12)]: Done 105 tasks      | elapsed:   10.4s\n",
            "[Parallel(n_jobs=12)]: Done 106 tasks      | elapsed:   10.4s\n",
            "[Parallel(n_jobs=12)]: Done 107 tasks      | elapsed:   10.4s\n",
            "[Parallel(n_jobs=12)]: Done 108 tasks      | elapsed:   10.4s\n",
            "[Parallel(n_jobs=12)]: Done 109 tasks      | elapsed:   10.6s\n",
            "[Parallel(n_jobs=12)]: Done 110 tasks      | elapsed:   10.7s\n",
            "[Parallel(n_jobs=12)]: Done 111 tasks      | elapsed:   10.7s\n",
            "[Parallel(n_jobs=12)]: Done 112 tasks      | elapsed:   10.7s\n",
            "[Parallel(n_jobs=12)]: Done 113 tasks      | elapsed:   10.7s\n",
            "[Parallel(n_jobs=12)]: Done 114 tasks      | elapsed:   10.7s\n",
            "[Parallel(n_jobs=12)]: Done 115 tasks      | elapsed:   10.8s\n",
            "[Parallel(n_jobs=12)]: Done 116 tasks      | elapsed:   10.8s\n",
            "[Parallel(n_jobs=12)]: Done 117 tasks      | elapsed:   10.8s\n",
            "[Parallel(n_jobs=12)]: Done 118 tasks      | elapsed:   10.8s\n",
            "[Parallel(n_jobs=12)]: Done 119 tasks      | elapsed:   10.8s\n",
            "[Parallel(n_jobs=12)]: Done 120 tasks      | elapsed:   10.9s\n",
            "[Parallel(n_jobs=12)]: Done 121 tasks      | elapsed:   10.9s\n",
            "[Parallel(n_jobs=12)]: Done 122 tasks      | elapsed:   10.9s\n",
            "[Parallel(n_jobs=12)]: Done 123 tasks      | elapsed:   10.9s\n",
            "[Parallel(n_jobs=12)]: Done 124 tasks      | elapsed:   11.0s\n",
            "[Parallel(n_jobs=12)]: Done 125 tasks      | elapsed:   11.1s\n",
            "[Parallel(n_jobs=12)]: Done 126 tasks      | elapsed:   11.1s\n",
            "[Parallel(n_jobs=12)]: Done 127 tasks      | elapsed:   11.1s\n",
            "[Parallel(n_jobs=12)]: Done 128 tasks      | elapsed:   11.1s\n",
            "[Parallel(n_jobs=12)]: Done 129 tasks      | elapsed:   11.1s\n",
            "[Parallel(n_jobs=12)]: Done 130 tasks      | elapsed:   11.2s\n",
            "[Parallel(n_jobs=12)]: Done 131 tasks      | elapsed:   11.2s\n",
            "[Parallel(n_jobs=12)]: Done 132 tasks      | elapsed:   11.2s\n",
            "[Parallel(n_jobs=12)]: Done 133 tasks      | elapsed:   11.2s\n",
            "[Parallel(n_jobs=12)]: Done 134 tasks      | elapsed:   11.2s\n",
            "[Parallel(n_jobs=12)]: Done 135 tasks      | elapsed:   11.3s\n",
            "[Parallel(n_jobs=12)]: Done 136 tasks      | elapsed:   11.3s\n",
            "[Parallel(n_jobs=12)]: Done 137 tasks      | elapsed:   11.3s\n",
            "[Parallel(n_jobs=12)]: Done 138 tasks      | elapsed:   11.3s\n",
            "[Parallel(n_jobs=12)]: Done 139 tasks      | elapsed:   11.3s\n",
            "[Parallel(n_jobs=12)]: Done 140 tasks      | elapsed:   11.3s\n",
            "[Parallel(n_jobs=12)]: Done 141 tasks      | elapsed:   11.3s\n",
            "[Parallel(n_jobs=12)]: Done 142 tasks      | elapsed:   11.4s\n",
            "[Parallel(n_jobs=12)]: Done 143 tasks      | elapsed:   11.4s\n",
            "[Parallel(n_jobs=12)]: Done 144 tasks      | elapsed:   11.4s\n",
            "[Parallel(n_jobs=12)]: Done 145 tasks      | elapsed:   11.4s\n",
            "[Parallel(n_jobs=12)]: Done 146 tasks      | elapsed:   11.5s\n",
            "[Parallel(n_jobs=12)]: Done 147 tasks      | elapsed:   11.5s\n",
            "[Parallel(n_jobs=12)]: Done 148 tasks      | elapsed:   11.5s\n",
            "[Parallel(n_jobs=12)]: Done 149 tasks      | elapsed:   11.5s\n",
            "[Parallel(n_jobs=12)]: Done 150 tasks      | elapsed:   11.6s\n",
            "[Parallel(n_jobs=12)]: Done 151 tasks      | elapsed:   11.6s\n",
            "[Parallel(n_jobs=12)]: Done 152 tasks      | elapsed:   11.6s\n",
            "[Parallel(n_jobs=12)]: Done 153 tasks      | elapsed:   11.6s\n",
            "[Parallel(n_jobs=12)]: Done 154 tasks      | elapsed:   11.6s\n",
            "[Parallel(n_jobs=12)]: Done 155 tasks      | elapsed:   11.6s\n",
            "[Parallel(n_jobs=12)]: Done 156 tasks      | elapsed:   11.7s\n",
            "[Parallel(n_jobs=12)]: Done 157 tasks      | elapsed:   11.7s\n",
            "[Parallel(n_jobs=12)]: Done 158 tasks      | elapsed:   11.7s\n",
            "[Parallel(n_jobs=12)]: Done 159 tasks      | elapsed:   11.8s\n",
            "[Parallel(n_jobs=12)]: Done 160 tasks      | elapsed:   11.9s\n",
            "[Parallel(n_jobs=12)]: Done 161 tasks      | elapsed:   11.9s\n",
            "[Parallel(n_jobs=12)]: Done 162 tasks      | elapsed:   11.9s\n",
            "[Parallel(n_jobs=12)]: Done 163 tasks      | elapsed:   11.9s\n",
            "[Parallel(n_jobs=12)]: Done 164 tasks      | elapsed:   11.9s\n",
            "[Parallel(n_jobs=12)]: Done 165 tasks      | elapsed:   11.9s\n",
            "[Parallel(n_jobs=12)]: Done 166 tasks      | elapsed:   11.9s\n",
            "[Parallel(n_jobs=12)]: Done 167 tasks      | elapsed:   12.0s\n",
            "[Parallel(n_jobs=12)]: Done 168 tasks      | elapsed:   12.0s\n",
            "[Parallel(n_jobs=12)]: Done 169 tasks      | elapsed:   12.0s\n",
            "[Parallel(n_jobs=12)]: Done 170 tasks      | elapsed:   12.0s\n",
            "[Parallel(n_jobs=12)]: Done 171 tasks      | elapsed:   12.0s\n",
            "[Parallel(n_jobs=12)]: Done 172 tasks      | elapsed:   12.0s\n",
            "[Parallel(n_jobs=12)]: Done 173 tasks      | elapsed:   12.0s\n",
            "[Parallel(n_jobs=12)]: Done 174 tasks      | elapsed:   12.0s\n",
            "[Parallel(n_jobs=12)]: Done 175 tasks      | elapsed:   12.0s\n",
            "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:   12.1s\n",
            "[Parallel(n_jobs=12)]: Done 177 tasks      | elapsed:   12.1s\n",
            "[Parallel(n_jobs=12)]: Done 178 tasks      | elapsed:   12.2s\n",
            "[Parallel(n_jobs=12)]: Done 179 tasks      | elapsed:   12.2s\n",
            "[Parallel(n_jobs=12)]: Done 180 tasks      | elapsed:   12.2s\n",
            "[Parallel(n_jobs=12)]: Done 181 tasks      | elapsed:   12.2s\n",
            "[Parallel(n_jobs=12)]: Done 182 tasks      | elapsed:   12.2s\n",
            "[Parallel(n_jobs=12)]: Done 183 tasks      | elapsed:   12.2s\n",
            "[Parallel(n_jobs=12)]: Done 184 tasks      | elapsed:   12.2s\n",
            "[Parallel(n_jobs=12)]: Done 185 tasks      | elapsed:   12.2s\n",
            "[Parallel(n_jobs=12)]: Done 186 tasks      | elapsed:   12.3s\n",
            "[Parallel(n_jobs=12)]: Done 187 tasks      | elapsed:   12.3s\n",
            "[Parallel(n_jobs=12)]: Done 188 tasks      | elapsed:   12.3s\n",
            "[Parallel(n_jobs=12)]: Done 189 tasks      | elapsed:   12.3s\n",
            "[Parallel(n_jobs=12)]: Done 190 tasks      | elapsed:   12.3s\n",
            "[Parallel(n_jobs=12)]: Done 191 tasks      | elapsed:   12.4s\n",
            "[Parallel(n_jobs=12)]: Done 192 tasks      | elapsed:   12.4s\n",
            "[Parallel(n_jobs=12)]: Done 193 tasks      | elapsed:   12.4s\n",
            "[Parallel(n_jobs=12)]: Done 194 tasks      | elapsed:   12.4s\n",
            "[Parallel(n_jobs=12)]: Done 195 tasks      | elapsed:   12.4s\n",
            "[Parallel(n_jobs=12)]: Done 196 tasks      | elapsed:   12.4s\n",
            "[Parallel(n_jobs=12)]: Done 197 tasks      | elapsed:   12.4s\n",
            "[Parallel(n_jobs=12)]: Done 198 tasks      | elapsed:   12.4s\n",
            "[Parallel(n_jobs=12)]: Done 199 tasks      | elapsed:   12.5s\n",
            "[Parallel(n_jobs=12)]: Done 200 tasks      | elapsed:   12.5s\n",
            "[Parallel(n_jobs=12)]: Done 201 tasks      | elapsed:   12.5s\n",
            "[Parallel(n_jobs=12)]: Done 202 tasks      | elapsed:   12.5s\n",
            "[Parallel(n_jobs=12)]: Done 203 tasks      | elapsed:   12.5s\n",
            "[Parallel(n_jobs=12)]: Done 204 tasks      | elapsed:   12.6s\n",
            "[Parallel(n_jobs=12)]: Done 205 tasks      | elapsed:   12.6s\n",
            "[Parallel(n_jobs=12)]: Done 206 tasks      | elapsed:   12.7s\n",
            "[Parallel(n_jobs=12)]: Done 207 tasks      | elapsed:   12.7s\n",
            "[Parallel(n_jobs=12)]: Done 208 tasks      | elapsed:   12.7s\n",
            "[Parallel(n_jobs=12)]: Done 209 tasks      | elapsed:   12.7s\n",
            "[Parallel(n_jobs=12)]: Done 210 tasks      | elapsed:   12.8s\n",
            "[Parallel(n_jobs=12)]: Done 211 tasks      | elapsed:   12.8s\n",
            "[Parallel(n_jobs=12)]: Done 212 tasks      | elapsed:   12.8s\n",
            "[Parallel(n_jobs=12)]: Done 213 tasks      | elapsed:   12.8s\n",
            "[Parallel(n_jobs=12)]: Done 214 tasks      | elapsed:   12.8s\n",
            "[Parallel(n_jobs=12)]: Done 215 tasks      | elapsed:   12.8s\n",
            "[Parallel(n_jobs=12)]: Done 216 tasks      | elapsed:   12.8s\n",
            "[Parallel(n_jobs=12)]: Done 217 tasks      | elapsed:   12.8s\n",
            "[Parallel(n_jobs=12)]: Done 218 tasks      | elapsed:   12.9s\n",
            "[Parallel(n_jobs=12)]: Done 219 tasks      | elapsed:   12.9s\n",
            "[Parallel(n_jobs=12)]: Done 220 tasks      | elapsed:   12.9s\n",
            "[Parallel(n_jobs=12)]: Done 221 tasks      | elapsed:   13.0s\n",
            "[Parallel(n_jobs=12)]: Done 222 tasks      | elapsed:   13.0s\n",
            "[Parallel(n_jobs=12)]: Done 223 tasks      | elapsed:   13.0s\n",
            "[Parallel(n_jobs=12)]: Done 224 tasks      | elapsed:   13.1s\n",
            "[Parallel(n_jobs=12)]: Done 225 tasks      | elapsed:   13.1s\n",
            "[Parallel(n_jobs=12)]: Done 226 tasks      | elapsed:   13.1s\n",
            "[Parallel(n_jobs=12)]: Done 227 tasks      | elapsed:   13.1s\n",
            "[Parallel(n_jobs=12)]: Done 228 tasks      | elapsed:   13.1s\n",
            "[Parallel(n_jobs=12)]: Done 229 tasks      | elapsed:   13.1s\n",
            "[Parallel(n_jobs=12)]: Done 230 tasks      | elapsed:   13.2s\n",
            "[Parallel(n_jobs=12)]: Done 231 tasks      | elapsed:   13.2s\n",
            "[Parallel(n_jobs=12)]: Done 232 tasks      | elapsed:   13.2s\n",
            "[Parallel(n_jobs=12)]: Done 233 tasks      | elapsed:   13.2s\n",
            "[Parallel(n_jobs=12)]: Done 234 tasks      | elapsed:   13.2s\n",
            "[Parallel(n_jobs=12)]: Done 235 tasks      | elapsed:   13.2s\n",
            "[Parallel(n_jobs=12)]: Done 236 tasks      | elapsed:   13.2s\n",
            "[Parallel(n_jobs=12)]: Done 237 tasks      | elapsed:   13.3s\n",
            "[Parallel(n_jobs=12)]: Done 238 tasks      | elapsed:   13.3s\n",
            "[Parallel(n_jobs=12)]: Done 239 tasks      | elapsed:   13.3s\n",
            "[Parallel(n_jobs=12)]: Done 240 tasks      | elapsed:   13.4s\n",
            "[Parallel(n_jobs=12)]: Done 241 tasks      | elapsed:   13.4s\n",
            "[Parallel(n_jobs=12)]: Done 242 tasks      | elapsed:   13.4s\n",
            "[Parallel(n_jobs=12)]: Done 243 tasks      | elapsed:   13.4s\n",
            "[Parallel(n_jobs=12)]: Done 244 tasks      | elapsed:   13.5s\n",
            "[Parallel(n_jobs=12)]: Done 245 tasks      | elapsed:   13.5s\n",
            "[Parallel(n_jobs=12)]: Done 246 tasks      | elapsed:   13.5s\n",
            "[Parallel(n_jobs=12)]: Done 247 tasks      | elapsed:   13.5s\n",
            "[Parallel(n_jobs=12)]: Done 248 tasks      | elapsed:   13.6s\n",
            "[Parallel(n_jobs=12)]: Done 249 tasks      | elapsed:   13.7s\n",
            "[Parallel(n_jobs=12)]: Done 250 tasks      | elapsed:   13.7s\n",
            "[Parallel(n_jobs=12)]: Done 251 tasks      | elapsed:   13.7s\n",
            "[Parallel(n_jobs=12)]: Done 252 tasks      | elapsed:   13.7s\n",
            "[Parallel(n_jobs=12)]: Done 253 tasks      | elapsed:   13.7s\n",
            "[Parallel(n_jobs=12)]: Done 254 tasks      | elapsed:   13.7s\n",
            "[Parallel(n_jobs=12)]: Done 255 tasks      | elapsed:   13.7s\n",
            "[Parallel(n_jobs=12)]: Done 256 tasks      | elapsed:   13.8s\n",
            "[Parallel(n_jobs=12)]: Done 257 tasks      | elapsed:   13.8s\n",
            "[Parallel(n_jobs=12)]: Done 258 tasks      | elapsed:   13.8s\n",
            "[Parallel(n_jobs=12)]: Done 259 tasks      | elapsed:   13.8s\n",
            "[Parallel(n_jobs=12)]: Done 260 tasks      | elapsed:   13.8s\n",
            "[Parallel(n_jobs=12)]: Done 261 tasks      | elapsed:   13.8s\n",
            "[Parallel(n_jobs=12)]: Done 262 tasks      | elapsed:   13.8s\n",
            "[Parallel(n_jobs=12)]: Done 263 tasks      | elapsed:   13.8s\n",
            "[Parallel(n_jobs=12)]: Done 264 tasks      | elapsed:   13.8s\n",
            "[Parallel(n_jobs=12)]: Done 265 tasks      | elapsed:   13.8s\n",
            "[Parallel(n_jobs=12)]: Done 266 tasks      | elapsed:   13.9s\n",
            "[Parallel(n_jobs=12)]: Done 267 tasks      | elapsed:   14.0s\n",
            "[Parallel(n_jobs=12)]: Done 268 tasks      | elapsed:   14.0s\n",
            "[Parallel(n_jobs=12)]: Done 269 tasks      | elapsed:   14.0s\n",
            "[Parallel(n_jobs=12)]: Done 270 tasks      | elapsed:   14.0s\n",
            "[Parallel(n_jobs=12)]: Done 271 tasks      | elapsed:   14.0s\n",
            "[Parallel(n_jobs=12)]: Done 272 tasks      | elapsed:   14.0s\n",
            "[Parallel(n_jobs=12)]: Done 273 tasks      | elapsed:   14.0s\n",
            "[Parallel(n_jobs=12)]: Done 274 tasks      | elapsed:   14.1s\n",
            "[Parallel(n_jobs=12)]: Done 275 tasks      | elapsed:   14.1s\n",
            "[Parallel(n_jobs=12)]: Done 276 tasks      | elapsed:   14.1s\n",
            "[Parallel(n_jobs=12)]: Done 277 tasks      | elapsed:   14.1s\n",
            "[Parallel(n_jobs=12)]: Done 300 out of 300 | elapsed:   14.5s finished\n",
            "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=12)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=12)]: Batch computation too fast (0.0683s.) Setting batch_size=2.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[55  0  4]\n",
            " [ 0 41  0]\n",
            " [ 8  1 75]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.87      0.93      0.90        59\n",
            "     neutral       0.98      1.00      0.99        41\n",
            "    positive       0.95      0.89      0.92        84\n",
            "\n",
            "    accuracy                           0.93       184\n",
            "   macro avg       0.93      0.94      0.94       184\n",
            "weighted avg       0.93      0.93      0.93       184\n",
            "\n",
            "Training set score for SVM: 1.000000\n",
            "Testing  set score for SVM: 0.929348\n",
            "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=12)]: Done   2 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=12)]: Done   3 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=12)]: Done   4 tasks      | elapsed:    0.4s\n",
            "[Parallel(n_jobs=12)]: Done   5 tasks      | elapsed:    0.4s\n",
            "[Parallel(n_jobs=12)]: Done   6 tasks      | elapsed:    0.4s\n",
            "[Parallel(n_jobs=12)]: Done   7 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=12)]: Done   8 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=12)]: Done   9 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=12)]: Done  10 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=12)]: Done  11 tasks      | elapsed:    0.6s\n",
            "[Parallel(n_jobs=12)]: Done  12 tasks      | elapsed:    0.6s\n",
            "[Parallel(n_jobs=12)]: Done  13 tasks      | elapsed:    0.6s\n",
            "[Parallel(n_jobs=12)]: Done  14 tasks      | elapsed:    0.6s\n",
            "[Parallel(n_jobs=12)]: Done  15 tasks      | elapsed:    0.7s\n",
            "[Parallel(n_jobs=12)]: Done  16 tasks      | elapsed:    0.7s\n",
            "[Parallel(n_jobs=12)]: Done  17 tasks      | elapsed:    0.7s\n",
            "[Parallel(n_jobs=12)]: Done  18 tasks      | elapsed:    0.8s\n",
            "[Parallel(n_jobs=12)]: Done  19 tasks      | elapsed:    0.8s\n",
            "[Parallel(n_jobs=12)]: Done  20 tasks      | elapsed:    0.8s\n",
            "[Parallel(n_jobs=12)]: Done  21 tasks      | elapsed:    0.9s\n",
            "[Parallel(n_jobs=12)]: Done  22 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=12)]: Done  23 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=12)]: Done  24 tasks      | elapsed:    1.1s\n",
            "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=12)]: Done  28 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=12)]: Done  30 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=12)]: Done  32 tasks      | elapsed:    1.6s\n",
            "[Parallel(n_jobs=12)]: Done  34 tasks      | elapsed:    1.7s\n",
            "[Parallel(n_jobs=12)]: Done  36 tasks      | elapsed:    1.7s\n",
            "[Parallel(n_jobs=12)]: Done  38 tasks      | elapsed:    1.8s\n",
            "[Parallel(n_jobs=12)]: Done  40 tasks      | elapsed:    1.9s\n",
            "[Parallel(n_jobs=12)]: Done  42 tasks      | elapsed:    1.9s\n",
            "[Parallel(n_jobs=12)]: Done  44 tasks      | elapsed:    2.0s\n",
            "[Parallel(n_jobs=12)]: Done  46 tasks      | elapsed:    2.0s\n",
            "[Parallel(n_jobs=12)]: Done  48 tasks      | elapsed:    2.0s\n",
            "[Parallel(n_jobs=12)]: Done  50 tasks      | elapsed:    2.3s\n",
            "[Parallel(n_jobs=12)]: Done  52 tasks      | elapsed:    2.3s\n",
            "[Parallel(n_jobs=12)]: Done  54 tasks      | elapsed:    2.3s\n",
            "[Parallel(n_jobs=12)]: Done  56 tasks      | elapsed:    2.5s\n",
            "[Parallel(n_jobs=12)]: Done  58 tasks      | elapsed:    2.6s\n",
            "[Parallel(n_jobs=12)]: Done  60 tasks      | elapsed:    2.6s\n",
            "[Parallel(n_jobs=12)]: Done  62 tasks      | elapsed:    2.7s\n",
            "[Parallel(n_jobs=12)]: Done  64 tasks      | elapsed:    2.7s\n",
            "[Parallel(n_jobs=12)]: Done  66 tasks      | elapsed:    2.7s\n",
            "[Parallel(n_jobs=12)]: Done  68 tasks      | elapsed:    2.8s\n",
            "[Parallel(n_jobs=12)]: Done  70 tasks      | elapsed:    2.8s\n",
            "[Parallel(n_jobs=12)]: Done  72 tasks      | elapsed:    2.9s\n",
            "[Parallel(n_jobs=12)]: Done  74 tasks      | elapsed:    2.9s\n",
            "[Parallel(n_jobs=12)]: Done  76 tasks      | elapsed:    3.0s\n",
            "[Parallel(n_jobs=12)]: Done  78 tasks      | elapsed:    3.1s\n",
            "[Parallel(n_jobs=12)]: Done  80 tasks      | elapsed:    3.2s\n",
            "[Parallel(n_jobs=12)]: Done  82 tasks      | elapsed:    3.4s\n",
            "[Parallel(n_jobs=12)]: Done  84 tasks      | elapsed:    3.4s\n",
            "[Parallel(n_jobs=12)]: Done  86 tasks      | elapsed:    3.5s\n",
            "[Parallel(n_jobs=12)]: Done  88 tasks      | elapsed:    3.5s\n",
            "[Parallel(n_jobs=12)]: Done  90 tasks      | elapsed:    3.6s\n",
            "[Parallel(n_jobs=12)]: Done  92 tasks      | elapsed:    3.7s\n",
            "[Parallel(n_jobs=12)]: Done  94 tasks      | elapsed:    3.7s\n",
            "[Parallel(n_jobs=12)]: Done  96 tasks      | elapsed:    3.7s\n",
            "[Parallel(n_jobs=12)]: Done  98 tasks      | elapsed:    3.8s\n",
            "[Parallel(n_jobs=12)]: Done 100 tasks      | elapsed:    3.9s\n",
            "[Parallel(n_jobs=12)]: Done 102 tasks      | elapsed:    4.2s\n",
            "[Parallel(n_jobs=12)]: Done 104 tasks      | elapsed:    4.2s\n",
            "[Parallel(n_jobs=12)]: Done 106 tasks      | elapsed:    4.2s\n",
            "[Parallel(n_jobs=12)]: Done 108 tasks      | elapsed:    4.3s\n",
            "[Parallel(n_jobs=12)]: Done 110 tasks      | elapsed:    4.3s\n",
            "[Parallel(n_jobs=12)]: Done 112 tasks      | elapsed:    4.3s\n",
            "[Parallel(n_jobs=12)]: Done 114 tasks      | elapsed:    4.5s\n",
            "[Parallel(n_jobs=12)]: Done 116 tasks      | elapsed:    4.6s\n",
            "[Parallel(n_jobs=12)]: Done 118 tasks      | elapsed:    4.6s\n",
            "[Parallel(n_jobs=12)]: Done 120 tasks      | elapsed:    4.7s\n",
            "[Parallel(n_jobs=12)]: Done 122 tasks      | elapsed:    4.7s\n",
            "[Parallel(n_jobs=12)]: Done 124 tasks      | elapsed:    4.8s\n",
            "[Parallel(n_jobs=12)]: Done 126 tasks      | elapsed:    5.0s\n",
            "[Parallel(n_jobs=12)]: Done 128 tasks      | elapsed:    5.0s\n",
            "[Parallel(n_jobs=12)]: Done 130 tasks      | elapsed:    5.0s\n",
            "[Parallel(n_jobs=12)]: Done 132 tasks      | elapsed:    5.1s\n",
            "[Parallel(n_jobs=12)]: Done 134 tasks      | elapsed:    5.1s\n",
            "[Parallel(n_jobs=12)]: Done 136 tasks      | elapsed:    5.1s\n",
            "[Parallel(n_jobs=12)]: Done 138 tasks      | elapsed:    5.1s\n",
            "[Parallel(n_jobs=12)]: Done 140 tasks      | elapsed:    5.3s\n",
            "[Parallel(n_jobs=12)]: Done 142 tasks      | elapsed:    5.4s\n",
            "[Parallel(n_jobs=12)]: Done 144 tasks      | elapsed:    5.6s\n",
            "[Parallel(n_jobs=12)]: Done 146 tasks      | elapsed:    5.6s\n",
            "[Parallel(n_jobs=12)]: Done 148 tasks      | elapsed:    5.8s\n",
            "[Parallel(n_jobs=12)]: Done 150 tasks      | elapsed:    5.8s\n",
            "[Parallel(n_jobs=12)]: Done 152 tasks      | elapsed:    5.9s\n",
            "[Parallel(n_jobs=12)]: Done 154 tasks      | elapsed:    5.9s\n",
            "[Parallel(n_jobs=12)]: Done 156 tasks      | elapsed:    5.9s\n",
            "[Parallel(n_jobs=12)]: Done 158 tasks      | elapsed:    6.0s\n",
            "[Parallel(n_jobs=12)]: Done 160 tasks      | elapsed:    6.0s\n",
            "[Parallel(n_jobs=12)]: Done 162 tasks      | elapsed:    6.2s\n",
            "[Parallel(n_jobs=12)]: Done 164 tasks      | elapsed:    6.3s\n",
            "[Parallel(n_jobs=12)]: Done 166 tasks      | elapsed:    6.4s\n",
            "[Parallel(n_jobs=12)]: Done 168 tasks      | elapsed:    6.5s\n",
            "[Parallel(n_jobs=12)]: Done 170 tasks      | elapsed:    6.5s\n",
            "[Parallel(n_jobs=12)]: Done 172 tasks      | elapsed:    6.5s\n",
            "[Parallel(n_jobs=12)]: Done 174 tasks      | elapsed:    6.6s\n",
            "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    6.7s\n",
            "[Parallel(n_jobs=12)]: Done 178 tasks      | elapsed:    6.7s\n",
            "[Parallel(n_jobs=12)]: Done 180 tasks      | elapsed:    6.8s\n",
            "[Parallel(n_jobs=12)]: Done 182 tasks      | elapsed:    6.9s\n",
            "[Parallel(n_jobs=12)]: Done 184 tasks      | elapsed:    6.9s\n",
            "[Parallel(n_jobs=12)]: Done 186 tasks      | elapsed:    7.0s\n",
            "[Parallel(n_jobs=12)]: Done 188 tasks      | elapsed:    7.0s\n",
            "[Parallel(n_jobs=12)]: Done 190 tasks      | elapsed:    7.1s\n",
            "[Parallel(n_jobs=12)]: Done 192 tasks      | elapsed:    7.1s\n",
            "[Parallel(n_jobs=12)]: Done 194 tasks      | elapsed:    7.2s\n",
            "[Parallel(n_jobs=12)]: Done 196 tasks      | elapsed:    7.2s\n",
            "[Parallel(n_jobs=12)]: Done 198 tasks      | elapsed:    7.3s\n",
            "[Parallel(n_jobs=12)]: Done 200 tasks      | elapsed:    7.3s\n",
            "[Parallel(n_jobs=12)]: Done 202 tasks      | elapsed:    7.5s\n",
            "[Parallel(n_jobs=12)]: Done 204 tasks      | elapsed:    7.6s\n",
            "[Parallel(n_jobs=12)]: Done 206 tasks      | elapsed:    7.8s\n",
            "[Parallel(n_jobs=12)]: Done 208 tasks      | elapsed:    7.8s\n",
            "[Parallel(n_jobs=12)]: Done 210 tasks      | elapsed:    7.9s\n",
            "[Parallel(n_jobs=12)]: Done 212 tasks      | elapsed:    7.9s\n",
            "[Parallel(n_jobs=12)]: Done 214 tasks      | elapsed:    7.9s\n",
            "[Parallel(n_jobs=12)]: Done 216 tasks      | elapsed:    8.0s\n",
            "[Parallel(n_jobs=12)]: Done 218 tasks      | elapsed:    8.0s\n",
            "[Parallel(n_jobs=12)]: Done 220 tasks      | elapsed:    8.1s\n",
            "[Parallel(n_jobs=12)]: Done 222 tasks      | elapsed:    8.4s\n",
            "[Parallel(n_jobs=12)]: Done 224 tasks      | elapsed:    8.4s\n",
            "[Parallel(n_jobs=12)]: Done 226 tasks      | elapsed:    8.5s\n",
            "[Parallel(n_jobs=12)]: Done 228 tasks      | elapsed:    8.5s\n",
            "[Parallel(n_jobs=12)]: Done 230 tasks      | elapsed:    8.7s\n",
            "[Parallel(n_jobs=12)]: Done 232 tasks      | elapsed:    8.7s\n",
            "[Parallel(n_jobs=12)]: Done 234 tasks      | elapsed:    8.8s\n",
            "[Parallel(n_jobs=12)]: Done 236 tasks      | elapsed:    8.8s\n",
            "[Parallel(n_jobs=12)]: Done 238 tasks      | elapsed:    8.8s\n",
            "[Parallel(n_jobs=12)]: Done 240 tasks      | elapsed:    8.8s\n",
            "[Parallel(n_jobs=12)]: Done 242 tasks      | elapsed:    9.0s\n",
            "[Parallel(n_jobs=12)]: Done 244 tasks      | elapsed:    9.1s\n",
            "[Parallel(n_jobs=12)]: Done 246 tasks      | elapsed:    9.1s\n",
            "[Parallel(n_jobs=12)]: Done 248 tasks      | elapsed:    9.2s\n",
            "[Parallel(n_jobs=12)]: Done 250 tasks      | elapsed:    9.3s\n",
            "[Parallel(n_jobs=12)]: Done 252 tasks      | elapsed:    9.3s\n",
            "[Parallel(n_jobs=12)]: Done 254 tasks      | elapsed:    9.4s\n",
            "[Parallel(n_jobs=12)]: Done 256 tasks      | elapsed:    9.4s\n",
            "[Parallel(n_jobs=12)]: Done 258 tasks      | elapsed:    9.4s\n",
            "[Parallel(n_jobs=12)]: Done 260 tasks      | elapsed:    9.4s\n",
            "[Parallel(n_jobs=12)]: Done 262 tasks      | elapsed:    9.6s\n",
            "[Parallel(n_jobs=12)]: Done 264 tasks      | elapsed:    9.6s\n",
            "[Parallel(n_jobs=12)]: Done 266 tasks      | elapsed:    9.9s\n",
            "[Parallel(n_jobs=12)]: Done 300 out of 300 | elapsed:   10.6s finished\n",
            "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[55  0  4]\n",
            " [ 1 40  0]\n",
            " [14  1 69]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.79      0.93      0.85        59\n",
            "     neutral       0.98      0.98      0.98        41\n",
            "    positive       0.95      0.82      0.88        84\n",
            "\n",
            "    accuracy                           0.89       184\n",
            "   macro avg       0.90      0.91      0.90       184\n",
            "weighted avg       0.90      0.89      0.89       184\n",
            "\n",
            "Training set score for SVM: 0.997669\n",
            "Testing  set score for SVM: 0.891304\n",
            "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=12)]: Done   1 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=12)]: Batch computation too fast (0.1812s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=12)]: Done   2 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=12)]: Done   3 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=12)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=12)]: Done   5 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=12)]: Done   6 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=12)]: Done   7 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=12)]: Done   8 tasks      | elapsed:    0.6s\n",
            "[Parallel(n_jobs=12)]: Done   9 tasks      | elapsed:    0.8s\n",
            "[Parallel(n_jobs=12)]: Done  10 tasks      | elapsed:    0.8s\n",
            "[Parallel(n_jobs=12)]: Done  11 tasks      | elapsed:    0.8s\n",
            "[Parallel(n_jobs=12)]: Done  12 tasks      | elapsed:    0.8s\n",
            "[Parallel(n_jobs=12)]: Done  13 tasks      | elapsed:    0.9s\n",
            "[Parallel(n_jobs=12)]: Done  14 tasks      | elapsed:    0.9s\n",
            "[Parallel(n_jobs=12)]: Done  15 tasks      | elapsed:    0.9s\n",
            "[Parallel(n_jobs=12)]: Done  16 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=12)]: Done  17 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=12)]: Done  18 tasks      | elapsed:    1.1s\n",
            "[Parallel(n_jobs=12)]: Done  19 tasks      | elapsed:    1.2s\n",
            "[Parallel(n_jobs=12)]: Done  20 tasks      | elapsed:    1.3s\n",
            "[Parallel(n_jobs=12)]: Done  21 tasks      | elapsed:    1.3s\n",
            "[Parallel(n_jobs=12)]: Done  22 tasks      | elapsed:    1.3s\n",
            "[Parallel(n_jobs=12)]: Done  23 tasks      | elapsed:    1.4s\n",
            "[Parallel(n_jobs=12)]: Done  24 tasks      | elapsed:    1.4s\n",
            "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    2.0s\n",
            "[Parallel(n_jobs=12)]: Done  28 tasks      | elapsed:    2.1s\n",
            "[Parallel(n_jobs=12)]: Done  30 tasks      | elapsed:    2.1s\n",
            "[Parallel(n_jobs=12)]: Done  32 tasks      | elapsed:    2.3s\n",
            "[Parallel(n_jobs=12)]: Done  34 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=12)]: Done  36 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=12)]: Done  38 tasks      | elapsed:    2.6s\n",
            "[Parallel(n_jobs=12)]: Done  40 tasks      | elapsed:    2.6s\n",
            "[Parallel(n_jobs=12)]: Done  42 tasks      | elapsed:    2.7s\n",
            "[Parallel(n_jobs=12)]: Done  44 tasks      | elapsed:    2.7s\n",
            "[Parallel(n_jobs=12)]: Done  46 tasks      | elapsed:    2.8s\n",
            "[Parallel(n_jobs=12)]: Done  48 tasks      | elapsed:    2.8s\n",
            "[Parallel(n_jobs=12)]: Done  50 tasks      | elapsed:    3.0s\n",
            "[Parallel(n_jobs=12)]: Done  52 tasks      | elapsed:    3.1s\n",
            "[Parallel(n_jobs=12)]: Batch computation too slow (2.0141s.) Setting batch_size=1.\n",
            "[Parallel(n_jobs=12)]: Done  54 tasks      | elapsed:    3.3s\n",
            "[Parallel(n_jobs=12)]: Done  56 tasks      | elapsed:    3.5s\n",
            "[Parallel(n_jobs=12)]: Done  58 tasks      | elapsed:    3.6s\n",
            "[Parallel(n_jobs=12)]: Done  60 tasks      | elapsed:    3.6s\n",
            "[Parallel(n_jobs=12)]: Done  62 tasks      | elapsed:    3.7s\n",
            "[Parallel(n_jobs=12)]: Done  64 tasks      | elapsed:    3.7s\n",
            "[Parallel(n_jobs=12)]: Done  66 tasks      | elapsed:    3.8s\n",
            "[Parallel(n_jobs=12)]: Done  68 tasks      | elapsed:    3.8s\n",
            "[Parallel(n_jobs=12)]: Done  70 tasks      | elapsed:    3.8s\n",
            "[Parallel(n_jobs=12)]: Done  72 tasks      | elapsed:    3.9s\n",
            "[Parallel(n_jobs=12)]: Done  74 tasks      | elapsed:    4.0s\n",
            "[Parallel(n_jobs=12)]: Done  76 tasks      | elapsed:    4.0s\n",
            "[Parallel(n_jobs=12)]: Done  78 tasks      | elapsed:    4.2s\n",
            "[Parallel(n_jobs=12)]: Done  80 tasks      | elapsed:    4.6s\n",
            "[Parallel(n_jobs=12)]: Done  82 tasks      | elapsed:    4.7s\n",
            "[Parallel(n_jobs=12)]: Done  84 tasks      | elapsed:    4.8s\n",
            "[Parallel(n_jobs=12)]: Done  86 tasks      | elapsed:    4.8s\n",
            "[Parallel(n_jobs=12)]: Done  88 tasks      | elapsed:    4.9s\n",
            "[Parallel(n_jobs=12)]: Done  90 tasks      | elapsed:    5.0s\n",
            "[Parallel(n_jobs=12)]: Done  92 tasks      | elapsed:    5.0s\n",
            "[Parallel(n_jobs=12)]: Done  94 tasks      | elapsed:    5.1s\n",
            "[Parallel(n_jobs=12)]: Done  96 tasks      | elapsed:    5.2s\n",
            "[Parallel(n_jobs=12)]: Done  98 tasks      | elapsed:    5.2s\n",
            "[Parallel(n_jobs=12)]: Done 100 tasks      | elapsed:    5.2s\n",
            "[Parallel(n_jobs=12)]: Done 102 tasks      | elapsed:    5.7s\n",
            "[Parallel(n_jobs=12)]: Done 103 tasks      | elapsed:    5.7s\n",
            "[Parallel(n_jobs=12)]: Done 104 tasks      | elapsed:    5.7s\n",
            "[Parallel(n_jobs=12)]: Done 106 tasks      | elapsed:    5.9s\n",
            "[Parallel(n_jobs=12)]: Done 108 tasks      | elapsed:    5.9s\n",
            "[Parallel(n_jobs=12)]: Done 110 tasks      | elapsed:    6.0s\n",
            "[Parallel(n_jobs=12)]: Done 112 tasks      | elapsed:    6.0s\n",
            "[Parallel(n_jobs=12)]: Done 114 tasks      | elapsed:    6.1s\n",
            "[Parallel(n_jobs=12)]: Done 116 tasks      | elapsed:    6.1s\n",
            "[Parallel(n_jobs=12)]: Done 118 tasks      | elapsed:    6.2s\n",
            "[Parallel(n_jobs=12)]: Done 119 tasks      | elapsed:    6.3s\n",
            "[Parallel(n_jobs=12)]: Done 120 tasks      | elapsed:    6.3s\n",
            "[Parallel(n_jobs=12)]: Done 121 tasks      | elapsed:    6.3s\n",
            "[Parallel(n_jobs=12)]: Done 122 tasks      | elapsed:    6.5s\n",
            "[Parallel(n_jobs=12)]: Done 123 tasks      | elapsed:    6.5s\n",
            "[Parallel(n_jobs=12)]: Done 124 tasks      | elapsed:    6.5s\n",
            "[Parallel(n_jobs=12)]: Done 125 tasks      | elapsed:    6.5s\n",
            "[Parallel(n_jobs=12)]: Done 126 tasks      | elapsed:    6.6s\n",
            "[Parallel(n_jobs=12)]: Done 128 tasks      | elapsed:    6.6s\n",
            "[Parallel(n_jobs=12)]: Done 129 tasks      | elapsed:    6.6s\n",
            "[Parallel(n_jobs=12)]: Done 131 tasks      | elapsed:    6.6s\n",
            "[Parallel(n_jobs=12)]: Done 132 tasks      | elapsed:    6.8s\n",
            "[Parallel(n_jobs=12)]: Done 133 tasks      | elapsed:    6.8s\n",
            "[Parallel(n_jobs=12)]: Done 134 tasks      | elapsed:    6.8s\n",
            "[Parallel(n_jobs=12)]: Done 135 tasks      | elapsed:    6.9s\n",
            "[Parallel(n_jobs=12)]: Done 136 tasks      | elapsed:    7.0s\n",
            "[Parallel(n_jobs=12)]: Done 137 tasks      | elapsed:    7.0s\n",
            "[Parallel(n_jobs=12)]: Done 138 tasks      | elapsed:    7.0s\n",
            "[Parallel(n_jobs=12)]: Done 139 tasks      | elapsed:    7.1s\n",
            "[Parallel(n_jobs=12)]: Done 140 tasks      | elapsed:    7.1s\n",
            "[Parallel(n_jobs=12)]: Done 141 tasks      | elapsed:    7.1s\n",
            "[Parallel(n_jobs=12)]: Done 142 tasks      | elapsed:    7.2s\n",
            "[Parallel(n_jobs=12)]: Done 143 tasks      | elapsed:    7.2s\n",
            "[Parallel(n_jobs=12)]: Done 144 tasks      | elapsed:    7.3s\n",
            "[Parallel(n_jobs=12)]: Done 145 tasks      | elapsed:    7.4s\n",
            "[Parallel(n_jobs=12)]: Done 146 tasks      | elapsed:    7.6s\n",
            "[Parallel(n_jobs=12)]: Done 147 tasks      | elapsed:    7.6s\n",
            "[Parallel(n_jobs=12)]: Done 148 tasks      | elapsed:    7.6s\n",
            "[Parallel(n_jobs=12)]: Done 149 tasks      | elapsed:    7.7s\n",
            "[Parallel(n_jobs=12)]: Done 150 tasks      | elapsed:    7.7s\n",
            "[Parallel(n_jobs=12)]: Done 151 tasks      | elapsed:    7.7s\n",
            "[Parallel(n_jobs=12)]: Done 152 tasks      | elapsed:    7.7s\n",
            "[Parallel(n_jobs=12)]: Done 153 tasks      | elapsed:    7.7s\n",
            "[Parallel(n_jobs=12)]: Done 154 tasks      | elapsed:    7.7s\n",
            "[Parallel(n_jobs=12)]: Done 155 tasks      | elapsed:    7.7s\n",
            "[Parallel(n_jobs=12)]: Done 156 tasks      | elapsed:    7.9s\n",
            "[Parallel(n_jobs=12)]: Done 157 tasks      | elapsed:    8.0s\n",
            "[Parallel(n_jobs=12)]: Done 158 tasks      | elapsed:    8.1s\n",
            "[Parallel(n_jobs=12)]: Done 159 tasks      | elapsed:    8.1s\n",
            "[Parallel(n_jobs=12)]: Done 160 tasks      | elapsed:    8.2s\n",
            "[Parallel(n_jobs=12)]: Done 161 tasks      | elapsed:    8.4s\n",
            "[Parallel(n_jobs=12)]: Done 162 tasks      | elapsed:    8.4s\n",
            "[Parallel(n_jobs=12)]: Done 163 tasks      | elapsed:    8.5s\n",
            "[Parallel(n_jobs=12)]: Done 164 tasks      | elapsed:    8.5s\n",
            "[Parallel(n_jobs=12)]: Done 165 tasks      | elapsed:    8.5s\n",
            "[Parallel(n_jobs=12)]: Done 166 tasks      | elapsed:    8.5s\n",
            "[Parallel(n_jobs=12)]: Done 167 tasks      | elapsed:    8.6s\n",
            "[Parallel(n_jobs=12)]: Done 168 tasks      | elapsed:    8.6s\n",
            "[Parallel(n_jobs=12)]: Done 169 tasks      | elapsed:    8.7s\n",
            "[Parallel(n_jobs=12)]: Done 170 tasks      | elapsed:    8.7s\n",
            "[Parallel(n_jobs=12)]: Done 171 tasks      | elapsed:    8.7s\n",
            "[Parallel(n_jobs=12)]: Done 172 tasks      | elapsed:    8.7s\n",
            "[Parallel(n_jobs=12)]: Done 173 tasks      | elapsed:    8.9s\n",
            "[Parallel(n_jobs=12)]: Done 174 tasks      | elapsed:    8.9s\n",
            "[Parallel(n_jobs=12)]: Done 175 tasks      | elapsed:    9.0s\n",
            "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    9.2s\n",
            "[Parallel(n_jobs=12)]: Done 177 tasks      | elapsed:    9.3s\n",
            "[Parallel(n_jobs=12)]: Done 178 tasks      | elapsed:    9.3s\n",
            "[Parallel(n_jobs=12)]: Done 179 tasks      | elapsed:    9.4s\n",
            "[Parallel(n_jobs=12)]: Done 180 tasks      | elapsed:    9.4s\n",
            "[Parallel(n_jobs=12)]: Done 181 tasks      | elapsed:    9.4s\n",
            "[Parallel(n_jobs=12)]: Done 182 tasks      | elapsed:    9.4s\n",
            "[Parallel(n_jobs=12)]: Done 183 tasks      | elapsed:    9.4s\n",
            "[Parallel(n_jobs=12)]: Done 184 tasks      | elapsed:    9.4s\n",
            "[Parallel(n_jobs=12)]: Done 185 tasks      | elapsed:    9.6s\n",
            "[Parallel(n_jobs=12)]: Done 186 tasks      | elapsed:    9.6s\n",
            "[Parallel(n_jobs=12)]: Done 187 tasks      | elapsed:    9.6s\n",
            "[Parallel(n_jobs=12)]: Done 188 tasks      | elapsed:    9.8s\n",
            "[Parallel(n_jobs=12)]: Done 189 tasks      | elapsed:    9.8s\n",
            "[Parallel(n_jobs=12)]: Done 190 tasks      | elapsed:    9.8s\n",
            "[Parallel(n_jobs=12)]: Done 191 tasks      | elapsed:    9.9s\n",
            "[Parallel(n_jobs=12)]: Done 192 tasks      | elapsed:    9.9s\n",
            "[Parallel(n_jobs=12)]: Done 193 tasks      | elapsed:   10.0s\n",
            "[Parallel(n_jobs=12)]: Done 194 tasks      | elapsed:   10.0s\n",
            "[Parallel(n_jobs=12)]: Done 195 tasks      | elapsed:   10.1s\n",
            "[Parallel(n_jobs=12)]: Done 196 tasks      | elapsed:   10.1s\n",
            "[Parallel(n_jobs=12)]: Done 197 tasks      | elapsed:   10.1s\n",
            "[Parallel(n_jobs=12)]: Done 198 tasks      | elapsed:   10.2s\n",
            "[Parallel(n_jobs=12)]: Done 199 tasks      | elapsed:   10.2s\n",
            "[Parallel(n_jobs=12)]: Done 200 tasks      | elapsed:   10.3s\n",
            "[Parallel(n_jobs=12)]: Done 201 tasks      | elapsed:   10.3s\n",
            "[Parallel(n_jobs=12)]: Done 202 tasks      | elapsed:   10.4s\n",
            "[Parallel(n_jobs=12)]: Done 203 tasks      | elapsed:   10.5s\n",
            "[Parallel(n_jobs=12)]: Done 204 tasks      | elapsed:   10.6s\n",
            "[Parallel(n_jobs=12)]: Done 205 tasks      | elapsed:   10.6s\n",
            "[Parallel(n_jobs=12)]: Done 206 tasks      | elapsed:   10.8s\n",
            "[Parallel(n_jobs=12)]: Done 207 tasks      | elapsed:   10.9s\n",
            "[Parallel(n_jobs=12)]: Done 208 tasks      | elapsed:   10.9s\n",
            "[Parallel(n_jobs=12)]: Done 209 tasks      | elapsed:   11.0s\n",
            "[Parallel(n_jobs=12)]: Done 210 tasks      | elapsed:   11.0s\n",
            "[Parallel(n_jobs=12)]: Done 211 tasks      | elapsed:   11.0s\n",
            "[Parallel(n_jobs=12)]: Done 212 tasks      | elapsed:   11.0s\n",
            "[Parallel(n_jobs=12)]: Done 213 tasks      | elapsed:   11.1s\n",
            "[Parallel(n_jobs=12)]: Done 214 tasks      | elapsed:   11.1s\n",
            "[Parallel(n_jobs=12)]: Done 215 tasks      | elapsed:   11.1s\n",
            "[Parallel(n_jobs=12)]: Done 216 tasks      | elapsed:   11.1s\n",
            "[Parallel(n_jobs=12)]: Done 217 tasks      | elapsed:   11.2s\n",
            "[Parallel(n_jobs=12)]: Done 218 tasks      | elapsed:   11.4s\n",
            "[Parallel(n_jobs=12)]: Done 219 tasks      | elapsed:   11.5s\n",
            "[Parallel(n_jobs=12)]: Done 220 tasks      | elapsed:   11.6s\n",
            "[Parallel(n_jobs=12)]: Done 221 tasks      | elapsed:   11.8s\n",
            "[Parallel(n_jobs=12)]: Done 222 tasks      | elapsed:   11.8s\n",
            "[Parallel(n_jobs=12)]: Done 223 tasks      | elapsed:   11.9s\n",
            "[Parallel(n_jobs=12)]: Done 224 tasks      | elapsed:   12.0s\n",
            "[Parallel(n_jobs=12)]: Done 225 tasks      | elapsed:   12.0s\n",
            "[Parallel(n_jobs=12)]: Done 226 tasks      | elapsed:   12.0s\n",
            "[Parallel(n_jobs=12)]: Done 227 tasks      | elapsed:   12.1s\n",
            "[Parallel(n_jobs=12)]: Done 228 tasks      | elapsed:   12.1s\n",
            "[Parallel(n_jobs=12)]: Done 229 tasks      | elapsed:   12.1s\n",
            "[Parallel(n_jobs=12)]: Done 230 tasks      | elapsed:   12.1s\n",
            "[Parallel(n_jobs=12)]: Done 231 tasks      | elapsed:   12.2s\n",
            "[Parallel(n_jobs=12)]: Done 232 tasks      | elapsed:   12.2s\n",
            "[Parallel(n_jobs=12)]: Done 233 tasks      | elapsed:   12.3s\n",
            "[Parallel(n_jobs=12)]: Done 234 tasks      | elapsed:   12.4s\n",
            "[Parallel(n_jobs=12)]: Done 235 tasks      | elapsed:   12.4s\n",
            "[Parallel(n_jobs=12)]: Done 236 tasks      | elapsed:   12.7s\n",
            "[Parallel(n_jobs=12)]: Done 237 tasks      | elapsed:   12.7s\n",
            "[Parallel(n_jobs=12)]: Done 238 tasks      | elapsed:   12.8s\n",
            "[Parallel(n_jobs=12)]: Done 239 tasks      | elapsed:   12.8s\n",
            "[Parallel(n_jobs=12)]: Done 240 tasks      | elapsed:   12.8s\n",
            "[Parallel(n_jobs=12)]: Done 241 tasks      | elapsed:   12.8s\n",
            "[Parallel(n_jobs=12)]: Done 242 tasks      | elapsed:   12.9s\n",
            "[Parallel(n_jobs=12)]: Done 243 tasks      | elapsed:   12.9s\n",
            "[Parallel(n_jobs=12)]: Done 244 tasks      | elapsed:   12.9s\n",
            "[Parallel(n_jobs=12)]: Done 245 tasks      | elapsed:   13.0s\n",
            "[Parallel(n_jobs=12)]: Done 246 tasks      | elapsed:   13.0s\n",
            "[Parallel(n_jobs=12)]: Done 247 tasks      | elapsed:   13.1s\n",
            "[Parallel(n_jobs=12)]: Done 248 tasks      | elapsed:   13.2s\n",
            "[Parallel(n_jobs=12)]: Done 249 tasks      | elapsed:   13.3s\n",
            "[Parallel(n_jobs=12)]: Done 250 tasks      | elapsed:   13.3s\n",
            "[Parallel(n_jobs=12)]: Done 251 tasks      | elapsed:   13.4s\n",
            "[Parallel(n_jobs=12)]: Done 252 tasks      | elapsed:   13.4s\n",
            "[Parallel(n_jobs=12)]: Done 253 tasks      | elapsed:   13.4s\n",
            "[Parallel(n_jobs=12)]: Done 254 tasks      | elapsed:   13.5s\n",
            "[Parallel(n_jobs=12)]: Done 255 tasks      | elapsed:   13.5s\n",
            "[Parallel(n_jobs=12)]: Done 256 tasks      | elapsed:   13.6s\n",
            "[Parallel(n_jobs=12)]: Done 257 tasks      | elapsed:   13.6s\n",
            "[Parallel(n_jobs=12)]: Done 258 tasks      | elapsed:   13.6s\n",
            "[Parallel(n_jobs=12)]: Done 259 tasks      | elapsed:   13.7s\n",
            "[Parallel(n_jobs=12)]: Done 260 tasks      | elapsed:   13.8s\n",
            "[Parallel(n_jobs=12)]: Done 261 tasks      | elapsed:   13.9s\n",
            "[Parallel(n_jobs=12)]: Done 262 tasks      | elapsed:   13.9s\n",
            "[Parallel(n_jobs=12)]: Done 263 tasks      | elapsed:   13.9s\n",
            "[Parallel(n_jobs=12)]: Done 264 tasks      | elapsed:   14.0s\n",
            "[Parallel(n_jobs=12)]: Done 265 tasks      | elapsed:   14.0s\n",
            "[Parallel(n_jobs=12)]: Done 266 tasks      | elapsed:   14.3s\n",
            "[Parallel(n_jobs=12)]: Done 267 tasks      | elapsed:   14.3s\n",
            "[Parallel(n_jobs=12)]: Done 268 tasks      | elapsed:   14.3s\n",
            "[Parallel(n_jobs=12)]: Done 269 tasks      | elapsed:   14.3s\n",
            "[Parallel(n_jobs=12)]: Done 270 tasks      | elapsed:   14.4s\n",
            "[Parallel(n_jobs=12)]: Done 271 tasks      | elapsed:   14.4s\n",
            "[Parallel(n_jobs=12)]: Done 272 tasks      | elapsed:   14.4s\n",
            "[Parallel(n_jobs=12)]: Done 273 tasks      | elapsed:   14.5s\n",
            "[Parallel(n_jobs=12)]: Done 274 tasks      | elapsed:   14.5s\n",
            "[Parallel(n_jobs=12)]: Done 275 tasks      | elapsed:   14.5s\n",
            "[Parallel(n_jobs=12)]: Done 276 tasks      | elapsed:   14.5s\n",
            "[Parallel(n_jobs=12)]: Done 277 tasks      | elapsed:   14.6s\n",
            "[Parallel(n_jobs=12)]: Done 300 out of 300 | elapsed:   15.7s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[53  6  0]\n",
            " [ 0 41  0]\n",
            " [ 3  7 74]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.95      0.90      0.92        59\n",
            "     neutral       0.76      1.00      0.86        41\n",
            "    positive       1.00      0.88      0.94        84\n",
            "\n",
            "    accuracy                           0.91       184\n",
            "   macro avg       0.90      0.93      0.91       184\n",
            "weighted avg       0.93      0.91      0.92       184\n",
            "\n",
            "Training set score for SVM: 1.000000\n",
            "Testing  set score for SVM: 0.913043\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvgjBndpOYQ7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9511ca66-5fde-4b76-aaab-04deee6ce70e"
      },
      "source": [
        "svm_scores"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9293478260869565, 0.8913043478260869, 0.9130434782608695]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_RSdOMMOXvo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "96090816-e037-4970-ff29-29c27bdaf392"
      },
      "source": [
        "bernouli_scores=[]\n",
        "docs = [df100,df200,df300]\n",
        "for i in docs:\n",
        "  bernouli_scores.append(bernouli(i))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[44  0 15]\n",
            " [ 2 36  3]\n",
            " [21  2 61]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.66      0.75      0.70        59\n",
            "     neutral       0.95      0.88      0.91        41\n",
            "    positive       0.77      0.73      0.75        84\n",
            "\n",
            "    accuracy                           0.77       184\n",
            "   macro avg       0.79      0.78      0.79       184\n",
            "weighted avg       0.77      0.77      0.77       184\n",
            "\n",
            "Training set score for BNB: 0.864802\n",
            "Testing  set score for BNB: 0.750000\n",
            "[[42  0 17]\n",
            " [ 3 34  4]\n",
            " [19  5 60]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.66      0.71      0.68        59\n",
            "     neutral       0.87      0.83      0.85        41\n",
            "    positive       0.74      0.71      0.73        84\n",
            "\n",
            "    accuracy                           0.74       184\n",
            "   macro avg       0.76      0.75      0.75       184\n",
            "weighted avg       0.74      0.74      0.74       184\n",
            "\n",
            "Training set score for BNB: 0.885781\n",
            "Testing  set score for BNB: 0.739130\n",
            "[[43  0 16]\n",
            " [ 5 34  2]\n",
            " [14  7 63]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.69      0.73      0.71        59\n",
            "     neutral       0.83      0.83      0.83        41\n",
            "    positive       0.78      0.75      0.76        84\n",
            "\n",
            "    accuracy                           0.76       184\n",
            "   macro avg       0.77      0.77      0.77       184\n",
            "weighted avg       0.76      0.76      0.76       184\n",
            "\n",
            "Training set score for BNB: 0.885781\n",
            "Testing  set score for BNB: 0.717391\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xxx-Wnupek9t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "125e2e97-5c4e-4b3f-ee9d-cc368b42a799"
      },
      "source": [
        "bernouli_scores"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7663043478260869, 0.7391304347826086, 0.7608695652173914]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM0d7h4lelLo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_2_100 = pd.read_csv('/content/drive/My Drive/Topic detection/Df_count_100.csv', index_col=0)\n",
        "df_2_200 = pd.read_csv('/content/drive/My Drive/Topic detection/Df_count_200.csv', index_col=0)\n",
        "df_2_300 = pd.read_csv('/content/drive/My Drive/Topic detection/Df_count_300.csv', index_col=0)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOtiITPBfbd2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "5e697e8a-301d-48e6-983a-ce4ac9857330"
      },
      "source": [
        "multinomial_scores=[]\n",
        "docs = [df_2_100,df_2_200,df_2_300]\n",
        "for i in docs:\n",
        "  multinomial_scores.append(multinomial(i))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-6fd9849e02cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdf_2_100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_2_200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_2_300\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mmultinomial_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-51-a6e4dec53768>\u001b[0m in \u001b[0;36mmultinomial\u001b[0;34m(TrainData)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_counters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_effective_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_feature_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_count\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    754\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0;34m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m         \u001b[0mcheck_non_negative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MultinomialNB (input X)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_non_negative\u001b[0;34m(X, whom)\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mX_min\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Negative values in data passed to %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mwhom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Negative values in data passed to MultinomialNB (input X)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5tYlNP6fbsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UU6N_A8mWXB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPI-OVc8mWmj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6T3R4onVmXtv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRuN-SENfcGg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugsl70O9fccq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL83iX8Vap8A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "outputId": "47922b9f-65ab-4f63-9559-c568d4e946a8"
      },
      "source": [
        "import pandas as pd\n",
        "TrainData = pd.read_csv('/content/drive/My Drive/Topic detection/TfIdfData.csv', index_col = 0 )\n",
        "TrainData.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Processed Text</th>\n",
              "      <th>TfIdfVectors</th>\n",
              "      <th>feat1</th>\n",
              "      <th>feat2</th>\n",
              "      <th>feat3</th>\n",
              "      <th>feat4</th>\n",
              "      <th>feat5</th>\n",
              "      <th>feat6</th>\n",
              "      <th>feat7</th>\n",
              "      <th>feat8</th>\n",
              "      <th>feat9</th>\n",
              "      <th>feat10</th>\n",
              "      <th>feat11</th>\n",
              "      <th>feat12</th>\n",
              "      <th>feat13</th>\n",
              "      <th>feat14</th>\n",
              "      <th>feat15</th>\n",
              "      <th>feat16</th>\n",
              "      <th>feat17</th>\n",
              "      <th>feat18</th>\n",
              "      <th>feat19</th>\n",
              "      <th>feat20</th>\n",
              "      <th>feat21</th>\n",
              "      <th>feat22</th>\n",
              "      <th>feat23</th>\n",
              "      <th>feat24</th>\n",
              "      <th>feat25</th>\n",
              "      <th>feat26</th>\n",
              "      <th>feat27</th>\n",
              "      <th>feat28</th>\n",
              "      <th>feat29</th>\n",
              "      <th>feat30</th>\n",
              "      <th>feat31</th>\n",
              "      <th>feat32</th>\n",
              "      <th>feat33</th>\n",
              "      <th>feat34</th>\n",
              "      <th>feat35</th>\n",
              "      <th>feat36</th>\n",
              "      <th>...</th>\n",
              "      <th>feat161</th>\n",
              "      <th>feat162</th>\n",
              "      <th>feat163</th>\n",
              "      <th>feat164</th>\n",
              "      <th>feat165</th>\n",
              "      <th>feat166</th>\n",
              "      <th>feat167</th>\n",
              "      <th>feat168</th>\n",
              "      <th>feat169</th>\n",
              "      <th>feat170</th>\n",
              "      <th>feat171</th>\n",
              "      <th>feat172</th>\n",
              "      <th>feat173</th>\n",
              "      <th>feat174</th>\n",
              "      <th>feat175</th>\n",
              "      <th>feat176</th>\n",
              "      <th>feat177</th>\n",
              "      <th>feat178</th>\n",
              "      <th>feat179</th>\n",
              "      <th>feat180</th>\n",
              "      <th>feat181</th>\n",
              "      <th>feat182</th>\n",
              "      <th>feat183</th>\n",
              "      <th>feat184</th>\n",
              "      <th>feat185</th>\n",
              "      <th>feat186</th>\n",
              "      <th>feat187</th>\n",
              "      <th>feat188</th>\n",
              "      <th>feat189</th>\n",
              "      <th>feat190</th>\n",
              "      <th>feat191</th>\n",
              "      <th>feat192</th>\n",
              "      <th>feat193</th>\n",
              "      <th>feat194</th>\n",
              "      <th>feat195</th>\n",
              "      <th>feat196</th>\n",
              "      <th>feat197</th>\n",
              "      <th>feat198</th>\n",
              "      <th>feat199</th>\n",
              "      <th>feat200</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ho acquistato questa confezione di mascherine ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>ho acquist confezion mascherin 19 99 quind 40 ...</td>\n",
              "      <td>[0.27247792065239457, 0.21972266346699976, 0.0...</td>\n",
              "      <td>0.272478</td>\n",
              "      <td>0.219723</td>\n",
              "      <td>0.024187</td>\n",
              "      <td>-0.035276</td>\n",
              "      <td>-0.060019</td>\n",
              "      <td>0.032466</td>\n",
              "      <td>-0.140034</td>\n",
              "      <td>-0.021274</td>\n",
              "      <td>0.010797</td>\n",
              "      <td>-0.139642</td>\n",
              "      <td>-0.248782</td>\n",
              "      <td>-0.112859</td>\n",
              "      <td>0.077791</td>\n",
              "      <td>-0.032370</td>\n",
              "      <td>-0.078478</td>\n",
              "      <td>0.049554</td>\n",
              "      <td>0.066917</td>\n",
              "      <td>-0.007913</td>\n",
              "      <td>-0.012080</td>\n",
              "      <td>-0.078611</td>\n",
              "      <td>0.038777</td>\n",
              "      <td>0.035575</td>\n",
              "      <td>-0.046226</td>\n",
              "      <td>0.047796</td>\n",
              "      <td>0.095787</td>\n",
              "      <td>-0.013445</td>\n",
              "      <td>0.033574</td>\n",
              "      <td>-0.046113</td>\n",
              "      <td>0.052642</td>\n",
              "      <td>0.079219</td>\n",
              "      <td>0.009382</td>\n",
              "      <td>0.105429</td>\n",
              "      <td>0.146709</td>\n",
              "      <td>0.016257</td>\n",
              "      <td>0.265021</td>\n",
              "      <td>0.183178</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000712</td>\n",
              "      <td>0.003130</td>\n",
              "      <td>0.007188</td>\n",
              "      <td>-0.002206</td>\n",
              "      <td>0.016861</td>\n",
              "      <td>0.005693</td>\n",
              "      <td>0.007154</td>\n",
              "      <td>-0.008933</td>\n",
              "      <td>-0.001005</td>\n",
              "      <td>-0.001717</td>\n",
              "      <td>-0.006622</td>\n",
              "      <td>0.010369</td>\n",
              "      <td>-0.006517</td>\n",
              "      <td>0.000171</td>\n",
              "      <td>-0.007744</td>\n",
              "      <td>-0.008937</td>\n",
              "      <td>-0.002413</td>\n",
              "      <td>-0.011081</td>\n",
              "      <td>-0.007513</td>\n",
              "      <td>0.016864</td>\n",
              "      <td>-0.013261</td>\n",
              "      <td>0.015795</td>\n",
              "      <td>-0.013149</td>\n",
              "      <td>-0.005551</td>\n",
              "      <td>0.005734</td>\n",
              "      <td>0.001783</td>\n",
              "      <td>0.001591</td>\n",
              "      <td>0.003175</td>\n",
              "      <td>-0.005366</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>0.007140</td>\n",
              "      <td>0.002043</td>\n",
              "      <td>-0.014306</td>\n",
              "      <td>-0.009748</td>\n",
              "      <td>0.001553</td>\n",
              "      <td>0.003029</td>\n",
              "      <td>0.013427</td>\n",
              "      <td>-0.001351</td>\n",
              "      <td>0.001680</td>\n",
              "      <td>0.010876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Attenzione, ha un ferretto nasale in plastica ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>attenzion ferrett nasal plastic permett far ad...</td>\n",
              "      <td>[0.16908623342662926, 0.09757413226524703, -0....</td>\n",
              "      <td>0.169086</td>\n",
              "      <td>0.097574</td>\n",
              "      <td>-0.005238</td>\n",
              "      <td>-0.042576</td>\n",
              "      <td>-0.009253</td>\n",
              "      <td>0.007023</td>\n",
              "      <td>-0.082983</td>\n",
              "      <td>-0.028276</td>\n",
              "      <td>0.077973</td>\n",
              "      <td>-0.068384</td>\n",
              "      <td>-0.041844</td>\n",
              "      <td>-0.048824</td>\n",
              "      <td>0.046407</td>\n",
              "      <td>-0.028404</td>\n",
              "      <td>-0.075385</td>\n",
              "      <td>0.050105</td>\n",
              "      <td>0.039076</td>\n",
              "      <td>-0.017067</td>\n",
              "      <td>0.119496</td>\n",
              "      <td>-0.014493</td>\n",
              "      <td>0.042645</td>\n",
              "      <td>0.027865</td>\n",
              "      <td>-0.005659</td>\n",
              "      <td>0.073627</td>\n",
              "      <td>0.059247</td>\n",
              "      <td>-0.073071</td>\n",
              "      <td>0.085659</td>\n",
              "      <td>-0.066784</td>\n",
              "      <td>0.108375</td>\n",
              "      <td>0.043017</td>\n",
              "      <td>-0.071770</td>\n",
              "      <td>0.073374</td>\n",
              "      <td>0.198330</td>\n",
              "      <td>-0.035712</td>\n",
              "      <td>0.394452</td>\n",
              "      <td>0.091456</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008430</td>\n",
              "      <td>-0.002051</td>\n",
              "      <td>0.005653</td>\n",
              "      <td>-0.001060</td>\n",
              "      <td>-0.001239</td>\n",
              "      <td>-0.003488</td>\n",
              "      <td>-0.000415</td>\n",
              "      <td>-0.009582</td>\n",
              "      <td>0.009058</td>\n",
              "      <td>-0.001457</td>\n",
              "      <td>-0.003282</td>\n",
              "      <td>-0.006317</td>\n",
              "      <td>0.003986</td>\n",
              "      <td>-0.007342</td>\n",
              "      <td>-0.003682</td>\n",
              "      <td>-0.001634</td>\n",
              "      <td>0.004405</td>\n",
              "      <td>-0.001732</td>\n",
              "      <td>0.009430</td>\n",
              "      <td>0.000913</td>\n",
              "      <td>0.002386</td>\n",
              "      <td>-0.002332</td>\n",
              "      <td>-0.004043</td>\n",
              "      <td>0.001671</td>\n",
              "      <td>0.004705</td>\n",
              "      <td>0.012583</td>\n",
              "      <td>-0.000720</td>\n",
              "      <td>0.003781</td>\n",
              "      <td>-0.000824</td>\n",
              "      <td>-0.007811</td>\n",
              "      <td>0.002804</td>\n",
              "      <td>0.002463</td>\n",
              "      <td>-0.001740</td>\n",
              "      <td>0.002401</td>\n",
              "      <td>-0.001963</td>\n",
              "      <td>0.001424</td>\n",
              "      <td>-0.007116</td>\n",
              "      <td>0.000450</td>\n",
              "      <td>0.004899</td>\n",
              "      <td>0.002939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>La confezione di cartone era già aperta, appen...</td>\n",
              "      <td>negative</td>\n",
              "      <td>la confezion carton già apert appen pres lat t...</td>\n",
              "      <td>[0.21797217894206228, 0.12299623105572668, 0.0...</td>\n",
              "      <td>0.217972</td>\n",
              "      <td>0.122996</td>\n",
              "      <td>0.065318</td>\n",
              "      <td>-0.045467</td>\n",
              "      <td>0.058404</td>\n",
              "      <td>0.044320</td>\n",
              "      <td>0.009989</td>\n",
              "      <td>0.067978</td>\n",
              "      <td>0.051968</td>\n",
              "      <td>-0.041222</td>\n",
              "      <td>-0.274352</td>\n",
              "      <td>-0.081080</td>\n",
              "      <td>0.066843</td>\n",
              "      <td>-0.117769</td>\n",
              "      <td>-0.090430</td>\n",
              "      <td>0.109259</td>\n",
              "      <td>0.094669</td>\n",
              "      <td>-0.007535</td>\n",
              "      <td>-0.113081</td>\n",
              "      <td>-0.007895</td>\n",
              "      <td>0.055765</td>\n",
              "      <td>-0.036258</td>\n",
              "      <td>-0.049051</td>\n",
              "      <td>-0.080781</td>\n",
              "      <td>0.004164</td>\n",
              "      <td>0.025648</td>\n",
              "      <td>-0.068258</td>\n",
              "      <td>0.020109</td>\n",
              "      <td>-0.114043</td>\n",
              "      <td>-0.034672</td>\n",
              "      <td>-0.062693</td>\n",
              "      <td>-0.048389</td>\n",
              "      <td>-0.086449</td>\n",
              "      <td>0.175677</td>\n",
              "      <td>-0.002588</td>\n",
              "      <td>-0.203799</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001298</td>\n",
              "      <td>0.008515</td>\n",
              "      <td>-0.013129</td>\n",
              "      <td>-0.005722</td>\n",
              "      <td>-0.000380</td>\n",
              "      <td>0.002795</td>\n",
              "      <td>0.006812</td>\n",
              "      <td>0.010063</td>\n",
              "      <td>-0.004645</td>\n",
              "      <td>0.002088</td>\n",
              "      <td>0.006688</td>\n",
              "      <td>0.011200</td>\n",
              "      <td>0.006949</td>\n",
              "      <td>0.002952</td>\n",
              "      <td>0.002058</td>\n",
              "      <td>-0.003507</td>\n",
              "      <td>0.005913</td>\n",
              "      <td>0.004957</td>\n",
              "      <td>0.003159</td>\n",
              "      <td>0.003091</td>\n",
              "      <td>-0.003575</td>\n",
              "      <td>-0.002152</td>\n",
              "      <td>-0.002908</td>\n",
              "      <td>0.003800</td>\n",
              "      <td>-0.002425</td>\n",
              "      <td>0.000170</td>\n",
              "      <td>-0.003258</td>\n",
              "      <td>0.003702</td>\n",
              "      <td>0.006239</td>\n",
              "      <td>-0.000163</td>\n",
              "      <td>0.004509</td>\n",
              "      <td>0.000061</td>\n",
              "      <td>0.003800</td>\n",
              "      <td>-0.000824</td>\n",
              "      <td>0.002099</td>\n",
              "      <td>-0.000275</td>\n",
              "      <td>-0.001592</td>\n",
              "      <td>0.004395</td>\n",
              "      <td>0.002083</td>\n",
              "      <td>0.001672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mascherine vendute come \"Maschera Chirurgica 3...</td>\n",
              "      <td>negative</td>\n",
              "      <td>mascherin vend mascher chirurg 3p tip iir conf...</td>\n",
              "      <td>[0.07175741115385922, 0.03131215810517044, 0.0...</td>\n",
              "      <td>0.071757</td>\n",
              "      <td>0.031312</td>\n",
              "      <td>0.035936</td>\n",
              "      <td>-0.057036</td>\n",
              "      <td>0.000778</td>\n",
              "      <td>-0.014077</td>\n",
              "      <td>-0.084098</td>\n",
              "      <td>0.079488</td>\n",
              "      <td>0.059257</td>\n",
              "      <td>-0.149626</td>\n",
              "      <td>-0.212587</td>\n",
              "      <td>-0.042393</td>\n",
              "      <td>0.069109</td>\n",
              "      <td>-0.001030</td>\n",
              "      <td>-0.024891</td>\n",
              "      <td>0.020581</td>\n",
              "      <td>0.087634</td>\n",
              "      <td>0.046171</td>\n",
              "      <td>-0.027870</td>\n",
              "      <td>-0.050561</td>\n",
              "      <td>-0.033546</td>\n",
              "      <td>0.017294</td>\n",
              "      <td>0.057090</td>\n",
              "      <td>0.016539</td>\n",
              "      <td>0.036593</td>\n",
              "      <td>0.041356</td>\n",
              "      <td>-0.170997</td>\n",
              "      <td>0.033856</td>\n",
              "      <td>-0.117031</td>\n",
              "      <td>-0.043175</td>\n",
              "      <td>0.032733</td>\n",
              "      <td>-0.043034</td>\n",
              "      <td>-0.032720</td>\n",
              "      <td>-0.122345</td>\n",
              "      <td>-0.123200</td>\n",
              "      <td>-0.045622</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.003952</td>\n",
              "      <td>-0.002479</td>\n",
              "      <td>0.001994</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.000913</td>\n",
              "      <td>0.001603</td>\n",
              "      <td>0.003920</td>\n",
              "      <td>0.002515</td>\n",
              "      <td>-0.005151</td>\n",
              "      <td>-0.003730</td>\n",
              "      <td>-0.000670</td>\n",
              "      <td>0.001214</td>\n",
              "      <td>-0.000396</td>\n",
              "      <td>-0.001674</td>\n",
              "      <td>0.005860</td>\n",
              "      <td>0.002220</td>\n",
              "      <td>0.001087</td>\n",
              "      <td>0.002812</td>\n",
              "      <td>-0.013707</td>\n",
              "      <td>0.005236</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>-0.007154</td>\n",
              "      <td>-0.001894</td>\n",
              "      <td>-0.000474</td>\n",
              "      <td>0.004815</td>\n",
              "      <td>-0.005157</td>\n",
              "      <td>-0.000861</td>\n",
              "      <td>0.002101</td>\n",
              "      <td>0.003857</td>\n",
              "      <td>0.004209</td>\n",
              "      <td>0.002201</td>\n",
              "      <td>-0.000673</td>\n",
              "      <td>-0.002494</td>\n",
              "      <td>0.000732</td>\n",
              "      <td>0.003137</td>\n",
              "      <td>-0.006297</td>\n",
              "      <td>-0.001338</td>\n",
              "      <td>0.000829</td>\n",
              "      <td>0.000068</td>\n",
              "      <td>0.002367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ARRIVATO APERTO PESSIMO PRODOTTO</td>\n",
              "      <td>negative</td>\n",
              "      <td>arriv apert pessim prodott</td>\n",
              "      <td>[0.024622949971823467, 0.07720488916191945, 0....</td>\n",
              "      <td>0.024623</td>\n",
              "      <td>0.077205</td>\n",
              "      <td>0.104754</td>\n",
              "      <td>-0.133077</td>\n",
              "      <td>0.261053</td>\n",
              "      <td>-0.116749</td>\n",
              "      <td>0.042607</td>\n",
              "      <td>-0.011968</td>\n",
              "      <td>-0.134939</td>\n",
              "      <td>0.107018</td>\n",
              "      <td>-0.065399</td>\n",
              "      <td>0.115100</td>\n",
              "      <td>0.007286</td>\n",
              "      <td>-0.036770</td>\n",
              "      <td>-0.028190</td>\n",
              "      <td>0.009106</td>\n",
              "      <td>0.038686</td>\n",
              "      <td>0.032256</td>\n",
              "      <td>0.056017</td>\n",
              "      <td>-0.048003</td>\n",
              "      <td>-0.017674</td>\n",
              "      <td>0.033227</td>\n",
              "      <td>-0.025836</td>\n",
              "      <td>-0.009794</td>\n",
              "      <td>0.107878</td>\n",
              "      <td>-0.045588</td>\n",
              "      <td>-0.018997</td>\n",
              "      <td>-0.053013</td>\n",
              "      <td>-0.125225</td>\n",
              "      <td>-0.050173</td>\n",
              "      <td>0.085992</td>\n",
              "      <td>-0.243862</td>\n",
              "      <td>0.090571</td>\n",
              "      <td>0.330075</td>\n",
              "      <td>0.078079</td>\n",
              "      <td>-0.182693</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001026</td>\n",
              "      <td>-0.008607</td>\n",
              "      <td>-0.004902</td>\n",
              "      <td>0.005900</td>\n",
              "      <td>0.008167</td>\n",
              "      <td>-0.013703</td>\n",
              "      <td>-0.000115</td>\n",
              "      <td>0.002053</td>\n",
              "      <td>0.012658</td>\n",
              "      <td>0.004097</td>\n",
              "      <td>0.018366</td>\n",
              "      <td>-0.002278</td>\n",
              "      <td>-0.009842</td>\n",
              "      <td>0.003966</td>\n",
              "      <td>-0.007308</td>\n",
              "      <td>0.006488</td>\n",
              "      <td>-0.021583</td>\n",
              "      <td>0.003343</td>\n",
              "      <td>0.003939</td>\n",
              "      <td>-0.007270</td>\n",
              "      <td>0.003429</td>\n",
              "      <td>-0.004072</td>\n",
              "      <td>0.006470</td>\n",
              "      <td>0.007423</td>\n",
              "      <td>-0.008437</td>\n",
              "      <td>0.004770</td>\n",
              "      <td>0.007399</td>\n",
              "      <td>-0.006165</td>\n",
              "      <td>-0.004514</td>\n",
              "      <td>0.005003</td>\n",
              "      <td>-0.002977</td>\n",
              "      <td>-0.004988</td>\n",
              "      <td>0.001843</td>\n",
              "      <td>-0.003085</td>\n",
              "      <td>-0.005825</td>\n",
              "      <td>0.000523</td>\n",
              "      <td>0.005671</td>\n",
              "      <td>-0.007125</td>\n",
              "      <td>-0.004923</td>\n",
              "      <td>0.000338</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 204 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  ...   feat200\n",
              "0  Ho acquistato questa confezione di mascherine ...  ...  0.010876\n",
              "1  Attenzione, ha un ferretto nasale in plastica ...  ...  0.002939\n",
              "2  La confezione di cartone era già aperta, appen...  ...  0.001672\n",
              "3  Mascherine vendute come \"Maschera Chirurgica 3...  ...  0.002367\n",
              "4                   ARRIVATO APERTO PESSIMO PRODOTTO  ...  0.000338\n",
              "\n",
              "[5 rows x 204 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eS8ycycUap-W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "9ac65317-a864-4194-d527-2841eea7eccb"
      },
      "source": [
        "import numpy as np\n",
        "import pylab as pl\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK9hSmR3Ty3l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "bf7ff5cb-9c58-48a8-97e4-fc6777fe3ea0"
      },
      "source": [
        "# Seperating Predictors and Outcome values from train and test sets\n",
        "X_train = TrainData.drop(['Text', 'Sentiment', 'Processed Text', 'TfIdfVectors'], axis = 1)\n",
        "Y_train_label = TrainData['Sentiment']\n",
        "#X_test = TrainData.drop(['Text', 'Sentiment', 'Processed Text', 'TfIdfVectors'], axis = 1)\n",
        "###Y_test_label = TrainData['Sentiment']\n",
        "\n",
        "# Dimension of Train and Test set \n",
        "print(\"Dimension of Train set\",X_train.shape)\n",
        "#print(\"Dimension of Test set\",X_test.shape,\"\\n\")\n",
        "\n",
        "# Transforming non numerical labels into numerical labels\n",
        "from sklearn import preprocessing\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "\n",
        "# encoding train labels \n",
        "encoder.fit(Y_train_label)\n",
        "Y_train = encoder.transform(Y_train_label)\n",
        "\n",
        "# encoding test labels \n",
        "#encoder.fit(Y_test_label)\n",
        "#Y_test = encoder.transform(Y_test_label)\n",
        "\n",
        "#Total Number of Continous and Categorical features in the training set\n",
        "num_cols = X_train._get_numeric_data().columns\n",
        "print(\"Number of numeric features:\",num_cols.size)\n",
        "#list(set(X_train.columns) - set(num_cols))\n",
        "\n",
        "\n",
        "names_of_predictors = list(X_train.columns.values)\n",
        "\n",
        "# Scaling the Train and Test feature set \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "#X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "\n",
        "params_grid = [{'kernel': ['rbf', 'poly', 'linear', 'sigmoid'], 'gamma': [5e-3, 3e-4, 1e-5],\n",
        "                     'C': [10, 20, 50, 100, 200]} ]\n",
        "\n",
        "\n",
        "svm_model = GridSearchCV(SVC(), params_grid, cv=5,  n_jobs = 12, verbose = 12)\n",
        "svm_model.fit(X_train_scaled2, y_train2)\n",
        "\n",
        "\n",
        "final_model = svm_model.best_estimator_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dimension of Train set (613, 200)\n",
            "Number of numeric features: 200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdNrAfon1qsI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "outputId": "31b52eb6-7234-4244-9667-c054f91245ce"
      },
      "source": [
        "X_train_scaled[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.2422465 ,  1.06273577,  0.14596816, -0.20044762, -0.58806611,\n",
              "        0.3546995 , -1.31027444, -0.17867182,  0.09544826, -1.34105118,\n",
              "       -2.42736216, -1.07455485,  0.74679558, -0.24535081, -0.79736548,\n",
              "        0.52641408,  0.68902197, -0.05423255, -0.15217317, -0.82494248,\n",
              "        0.4384681 ,  0.39283499, -0.61098823,  0.56139277,  1.14019803,\n",
              "       -0.14157163,  0.37484142, -0.47070309,  0.6647269 ,  0.93577383,\n",
              "        0.09128176,  1.27978683,  1.91193469,  0.19150933,  3.44042173,\n",
              "        2.44449447,  0.42726319, -1.31939927, -0.92619131,  0.75864173,\n",
              "        1.01092126, -1.23392566, -0.32188437, -0.84495255,  0.67143935,\n",
              "        0.83310585,  0.45586204,  0.19260102,  0.18671166, -2.32332379,\n",
              "        1.70157259, -0.67679777,  0.41053165, -0.60302596,  0.82494123,\n",
              "       -3.56854759, -0.97368057, -0.66613718, -0.11145581,  0.80572792,\n",
              "        0.52326716, -0.08439002,  0.77407631,  1.55084183, -0.86804117,\n",
              "       -1.45160506,  1.48085139, -1.68969227,  0.69916784,  1.1204207 ,\n",
              "        0.90568507,  1.6977748 , -1.77898686,  1.80911834, -1.29424482,\n",
              "       -0.55929742,  0.86594798, -4.16422432,  0.09935421,  3.84753826,\n",
              "       -1.33320539, -3.98465022, -1.61159787, -1.21380839, -1.27911386,\n",
              "       -2.39137972,  3.77953351,  1.00188407,  1.22585363, -0.91307963,\n",
              "        0.73415849, -0.31311734,  0.37851008,  0.27853287, -1.25121542,\n",
              "       -0.37870431,  0.5549395 ,  0.03914685,  1.08423267,  1.94782689,\n",
              "        0.916662  , -0.93563699, -1.14068419,  0.16366056,  0.21202758,\n",
              "       -0.56980859, -0.58211244,  0.40690802, -0.48556031, -0.8017781 ,\n",
              "       -0.61034297,  0.72318933, -0.06971291, -0.0436668 ,  0.55193178,\n",
              "        0.60999925,  0.27094443, -0.87259703, -0.62022542,  0.17984216,\n",
              "       -0.46473564,  0.18337358,  0.29406348, -0.29435289,  0.82734455,\n",
              "       -0.36340612, -0.17109505,  0.81598852, -0.16623634,  0.20513264,\n",
              "       -0.28758673, -0.56005222,  0.20482058,  0.09653021, -0.19500628,\n",
              "       -0.42745046, -0.71194025,  0.02903853, -0.0246201 , -0.03030571,\n",
              "        0.38477552, -0.08152972, -0.46839377,  0.01800751, -0.39694555,\n",
              "       -0.23678959, -0.56051145,  0.1484039 ,  0.14832062,  0.06231621,\n",
              "        0.43833734, -0.11451413,  0.26073062,  0.31158666, -0.07522935,\n",
              "        0.18805668, -0.00723906, -0.23824998,  0.05556134,  0.23471854,\n",
              "        0.03242661,  0.08211289,  0.19656926, -0.05030759,  0.44521811,\n",
              "        0.1504926 ,  0.19685255, -0.22922553, -0.02303435, -0.07956155,\n",
              "       -0.16968402,  0.28065968, -0.180656  , -0.01582766, -0.20167282,\n",
              "       -0.24937348, -0.07766416, -0.31350933, -0.20319282,  0.49125736,\n",
              "       -0.38256393,  0.43088833, -0.37331477, -0.16542996,  0.15774523,\n",
              "        0.02971203,  0.03786938,  0.08107341, -0.16821373, -0.0364391 ,\n",
              "        0.21289466,  0.0546743 , -0.43484308, -0.29246546,  0.03262863,\n",
              "        0.08547474,  0.39073153, -0.04999404,  0.05233192,  0.3181141 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QHYhD6VZXfB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "outputId": "2f40de61-7c68-4467-fd32-10720f14fc76"
      },
      "source": [
        "Y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 2, 0,\n",
              "       0, 0, 0, 0, 2, 0, 2, 2, 0, 2, 0, 2, 2, 0, 2, 0, 2, 2, 0, 2, 0, 2,\n",
              "       2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2,\n",
              "       2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2,\n",
              "       0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0,\n",
              "       0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 2, 2, 2,\n",
              "       0, 2, 0, 0, 2, 0, 0, 2, 0, 2, 2, 0, 2, 0, 2, 0, 0, 2, 0, 2, 2, 0,\n",
              "       2, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 0,\n",
              "       0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 2,\n",
              "       2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2,\n",
              "       2, 2, 0, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 0,\n",
              "       2, 0, 0, 2, 2, 0, 2, 2, 2, 0, 2, 0, 0, 2, 2, 0, 2, 2, 2, 0, 2, 0,\n",
              "       0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0,\n",
              "       2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 2,\n",
              "       2, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2,\n",
              "       2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2,\n",
              "       0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 2, 2, 0, 2, 2, 2, 0, 0, 0, 0, 2,\n",
              "       2, 0, 2, 2, 2, 0, 0, 0, 0, 2, 2, 0, 2, 2, 2, 0, 0, 0, 0, 2, 2, 0,\n",
              "       2, 2, 2, 0, 0, 0, 0, 2, 2, 0, 2, 2, 2, 0, 0, 0, 0, 2, 2, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8offFZOcHfn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_validate\n",
        "\n",
        "final_model = SVC()\n",
        "final_model.fit(X_train_scaled, Y_train)\n",
        "scores = cross_val_score(final_model ,X_train_scaled, Y_train,\n",
        "                       scoring='accuracy', cv = 6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLxl9Qkec9HD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3df4bf2f-1444-4bff-fe36-c8dbe8b9b96b"
      },
      "source": [
        "scores.mean()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.69346087949743"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oV_UTX8a4qp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Libraries to Build Ensemble Model : Random Forest Classifier \n",
        "# Create the parameter grid based on the results of random search \n",
        "params_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
        "                     'C': [ 1000]},\n",
        "                    {'kernel': ['linear'], 'C': [ 1000]}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gk-924sa55o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "outputId": "426e95ec-ae5d-4e06-c263-96581b7869f9"
      },
      "source": [
        "svm_model = GridSearchCV(SVC(), params_grid, cv=5)\n",
        "svm_model.fit(X_train_scaled, Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
              "                           class_weight=None, coef0=0.0,\n",
              "                           decision_function_shape='ovr', degree=3,\n",
              "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                           probability=False, random_state=None, shrinking=True,\n",
              "                           tol=0.001, verbose=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'C': [1000], 'gamma': [0.001, 0.0001],\n",
              "                          'kernel': ['rbf']},\n",
              "                         {'C': [1000], 'kernel': ['linear']}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LQL2nOEbIrP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "428a81b5-c897-4969-b1f1-edbcfaf7ea59"
      },
      "source": [
        "final_model = svm_model.best_estimator_\n",
        "Y_pred = final_model.predict(X_test_scaled)\n",
        "Y_pred_label = list(encoder.inverse_transform(Y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-b9d21ed827c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfinal_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mY_pred_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_test_scaled' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Im_UuQqcbV8-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "eab8177a-f5ef-4118-e7de-0c558e0188fb"
      },
      "source": [
        "print(confusion_matrix(Y_test_label,Y_pred_label))\n",
        "print(\"\\n\")\n",
        "print(classification_report(Y_test_label,Y_pred_label))\n",
        "\n",
        "print(\"Training set score for SVM: %f\" % final_model.score(X_train_scaled , Y_train))\n",
        "print(\"Testing  set score for SVM: %f\" % final_model.score(X_test_scaled  , Y_test ))\n",
        "\n",
        "svm_model.score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-fd93210496ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_pred_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_pred_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training set score for SVM: %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Y_test_label' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dViJ4440TzKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFxIXHDeTzNn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train2, X_test2, y_train2, y_test2 = train_test_split( TrainData.drop(['Text', 'Sentiment', 'Processed Text', 'TfIdfVectors'], axis = 1),\n",
        "TrainData['Sentiment'], test_size=0.3, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5H3mkLHTzPh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "\n",
        "# encoding train labels \n",
        "encoder.fit(y_train2)\n",
        "Y_train2 = encoder.transform(y_train2)\n",
        "\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "\n",
        "# encoding y_test2 labels \n",
        "encoder.fit(y_test2)\n",
        "Y_test2 = encoder.transform(y_test2)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled2 = scaler.fit_transform(X_train2)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_test_scaled2 = scaler.fit_transform(X_test2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c71Hr4TdAlb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "b8217f2a-b146-41a6-cac6-8bc784072afd"
      },
      "source": [
        "Y_test2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 2, 2, 1, 0, 0, 0, 2, 0, 1, 0, 2, 0, 0, 0, 1, 0, 1, 1, 2, 2,\n",
              "       2, 0, 1, 2, 1, 0, 1, 0, 1, 2, 0, 0, 2, 0, 0, 2, 1, 2, 2, 2, 2, 0,\n",
              "       0, 1, 2, 2, 0, 1, 2, 1, 2, 1, 0, 0, 2, 1, 0, 2, 0, 2, 2, 2, 2, 1,\n",
              "       2, 2, 1, 2, 1, 2, 2, 2, 0, 2, 1, 2, 2, 2, 1, 2, 2, 1, 1, 0, 0, 0,\n",
              "       1, 2, 1, 1, 0, 2, 0, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 0, 2, 2, 1,\n",
              "       0, 2, 2, 2, 1, 0, 2, 0, 2, 2, 2, 1, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0,\n",
              "       2, 1, 0, 2, 0, 1, 1, 0, 1, 0, 0, 2, 1, 2, 1, 2, 2, 2, 2, 0, 2, 0,\n",
              "       2, 2, 2, 1, 0, 2, 1, 2, 2, 1, 0, 2, 2, 2, 0, 0, 1, 0, 2, 0, 0, 2,\n",
              "       1, 0, 0, 2, 0, 1, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qR7HyyNcXPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params_grid = [{'kernel': ['rbf', 'poly', 'linear', 'sigmoid'], 'gamma': [5e-3, 3e-4, 1e-5],\n",
        "                     'C': [10, 20, 50, 100, 200]} ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-tEzWEacRJt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7f9d2469-3d48-4a1b-eeea-7e699a3f2ea2"
      },
      "source": [
        "svm_model = GridSearchCV(SVC(), params_grid, cv=5,  n_jobs = 12, verbose = 12)\n",
        "svm_model.fit(X_train_scaled2, y_train2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=12)]: Done   1 tasks      | elapsed:    5.1s\n",
            "[Parallel(n_jobs=12)]: Done   2 tasks      | elapsed:    5.1s\n",
            "[Parallel(n_jobs=12)]: Done   3 tasks      | elapsed:    5.2s\n",
            "[Parallel(n_jobs=12)]: Done   4 tasks      | elapsed:    5.4s\n",
            "[Parallel(n_jobs=12)]: Done   5 tasks      | elapsed:    5.5s\n",
            "[Parallel(n_jobs=12)]: Done   6 tasks      | elapsed:    5.6s\n",
            "[Parallel(n_jobs=12)]: Done   7 tasks      | elapsed:    5.7s\n",
            "[Parallel(n_jobs=12)]: Done   8 tasks      | elapsed:    5.7s\n",
            "[Parallel(n_jobs=12)]: Done   9 tasks      | elapsed:    5.9s\n",
            "[Parallel(n_jobs=12)]: Done  10 tasks      | elapsed:    5.9s\n",
            "[Parallel(n_jobs=12)]: Done  11 tasks      | elapsed:    6.0s\n",
            "[Parallel(n_jobs=12)]: Done  12 tasks      | elapsed:    6.1s\n",
            "[Parallel(n_jobs=12)]: Done  13 tasks      | elapsed:    6.1s\n",
            "[Parallel(n_jobs=12)]: Done  14 tasks      | elapsed:    6.3s\n",
            "[Parallel(n_jobs=12)]: Done  15 tasks      | elapsed:    6.4s\n",
            "[Parallel(n_jobs=12)]: Done  16 tasks      | elapsed:    6.4s\n",
            "[Parallel(n_jobs=12)]: Done  17 tasks      | elapsed:    6.5s\n",
            "[Parallel(n_jobs=12)]: Done  18 tasks      | elapsed:    6.6s\n",
            "[Parallel(n_jobs=12)]: Done  19 tasks      | elapsed:    6.7s\n",
            "[Parallel(n_jobs=12)]: Done  20 tasks      | elapsed:    6.8s\n",
            "[Parallel(n_jobs=12)]: Done  21 tasks      | elapsed:    6.9s\n",
            "[Parallel(n_jobs=12)]: Done  22 tasks      | elapsed:    7.0s\n",
            "[Parallel(n_jobs=12)]: Done  23 tasks      | elapsed:    7.0s\n",
            "[Parallel(n_jobs=12)]: Done  24 tasks      | elapsed:    7.1s\n",
            "[Parallel(n_jobs=12)]: Done  25 tasks      | elapsed:    7.2s\n",
            "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    7.3s\n",
            "[Parallel(n_jobs=12)]: Done  27 tasks      | elapsed:    7.3s\n",
            "[Parallel(n_jobs=12)]: Done  28 tasks      | elapsed:    7.4s\n",
            "[Parallel(n_jobs=12)]: Done  29 tasks      | elapsed:    7.5s\n",
            "[Parallel(n_jobs=12)]: Done  30 tasks      | elapsed:    7.7s\n",
            "[Parallel(n_jobs=12)]: Done  31 tasks      | elapsed:    7.7s\n",
            "[Parallel(n_jobs=12)]: Done  32 tasks      | elapsed:    7.8s\n",
            "[Parallel(n_jobs=12)]: Done  33 tasks      | elapsed:    7.9s\n",
            "[Parallel(n_jobs=12)]: Done  34 tasks      | elapsed:    8.1s\n",
            "[Parallel(n_jobs=12)]: Done  35 tasks      | elapsed:    8.2s\n",
            "[Parallel(n_jobs=12)]: Done  36 tasks      | elapsed:    8.2s\n",
            "[Parallel(n_jobs=12)]: Done  37 tasks      | elapsed:    8.3s\n",
            "[Parallel(n_jobs=12)]: Done  38 tasks      | elapsed:    8.5s\n",
            "[Parallel(n_jobs=12)]: Done  39 tasks      | elapsed:    8.6s\n",
            "[Parallel(n_jobs=12)]: Done  40 tasks      | elapsed:    8.7s\n",
            "[Parallel(n_jobs=12)]: Done  41 tasks      | elapsed:    8.7s\n",
            "[Parallel(n_jobs=12)]: Done  42 tasks      | elapsed:    8.8s\n",
            "[Parallel(n_jobs=12)]: Done  43 tasks      | elapsed:    8.9s\n",
            "[Parallel(n_jobs=12)]: Done  44 tasks      | elapsed:    9.0s\n",
            "[Parallel(n_jobs=12)]: Done  45 tasks      | elapsed:    9.1s\n",
            "[Parallel(n_jobs=12)]: Done  46 tasks      | elapsed:    9.1s\n",
            "[Parallel(n_jobs=12)]: Done  47 tasks      | elapsed:    9.2s\n",
            "[Parallel(n_jobs=12)]: Done  48 tasks      | elapsed:    9.3s\n",
            "[Parallel(n_jobs=12)]: Done  49 tasks      | elapsed:    9.5s\n",
            "[Parallel(n_jobs=12)]: Done  50 tasks      | elapsed:    9.7s\n",
            "[Parallel(n_jobs=12)]: Done  51 tasks      | elapsed:    9.7s\n",
            "[Parallel(n_jobs=12)]: Done  52 tasks      | elapsed:    9.7s\n",
            "[Parallel(n_jobs=12)]: Done  53 tasks      | elapsed:    9.8s\n",
            "[Parallel(n_jobs=12)]: Done  54 tasks      | elapsed:    9.9s\n",
            "[Parallel(n_jobs=12)]: Done  55 tasks      | elapsed:   10.0s\n",
            "[Parallel(n_jobs=12)]: Done  56 tasks      | elapsed:   10.1s\n",
            "[Parallel(n_jobs=12)]: Done  57 tasks      | elapsed:   10.1s\n",
            "[Parallel(n_jobs=12)]: Done  58 tasks      | elapsed:   10.2s\n",
            "[Parallel(n_jobs=12)]: Done  59 tasks      | elapsed:   10.3s\n",
            "[Parallel(n_jobs=12)]: Done  60 tasks      | elapsed:   10.4s\n",
            "[Parallel(n_jobs=12)]: Done  61 tasks      | elapsed:   10.5s\n",
            "[Parallel(n_jobs=12)]: Done  62 tasks      | elapsed:   10.5s\n",
            "[Parallel(n_jobs=12)]: Done  63 tasks      | elapsed:   10.6s\n",
            "[Parallel(n_jobs=12)]: Done  64 tasks      | elapsed:   10.7s\n",
            "[Parallel(n_jobs=12)]: Done  65 tasks      | elapsed:   10.8s\n",
            "[Parallel(n_jobs=12)]: Done  66 tasks      | elapsed:   10.8s\n",
            "[Parallel(n_jobs=12)]: Done  67 tasks      | elapsed:   10.9s\n",
            "[Parallel(n_jobs=12)]: Done  68 tasks      | elapsed:   11.0s\n",
            "[Parallel(n_jobs=12)]: Done  69 tasks      | elapsed:   11.0s\n",
            "[Parallel(n_jobs=12)]: Done  70 tasks      | elapsed:   11.1s\n",
            "[Parallel(n_jobs=12)]: Done  71 tasks      | elapsed:   11.2s\n",
            "[Parallel(n_jobs=12)]: Done  72 tasks      | elapsed:   11.2s\n",
            "[Parallel(n_jobs=12)]: Done  73 tasks      | elapsed:   11.3s\n",
            "[Parallel(n_jobs=12)]: Done  74 tasks      | elapsed:   11.3s\n",
            "[Parallel(n_jobs=12)]: Done  75 tasks      | elapsed:   11.3s\n",
            "[Parallel(n_jobs=12)]: Done  76 tasks      | elapsed:   11.4s\n",
            "[Parallel(n_jobs=12)]: Done  77 tasks      | elapsed:   11.4s\n",
            "[Parallel(n_jobs=12)]: Done  78 tasks      | elapsed:   11.4s\n",
            "[Parallel(n_jobs=12)]: Done  79 tasks      | elapsed:   11.4s\n",
            "[Parallel(n_jobs=12)]: Done  80 tasks      | elapsed:   11.5s\n",
            "[Parallel(n_jobs=12)]: Done  81 tasks      | elapsed:   11.5s\n",
            "[Parallel(n_jobs=12)]: Done  82 tasks      | elapsed:   11.5s\n",
            "[Parallel(n_jobs=12)]: Done  83 tasks      | elapsed:   11.6s\n",
            "[Parallel(n_jobs=12)]: Done  84 tasks      | elapsed:   11.6s\n",
            "[Parallel(n_jobs=12)]: Done  85 tasks      | elapsed:   11.7s\n",
            "[Parallel(n_jobs=12)]: Done  86 tasks      | elapsed:   11.9s\n",
            "[Parallel(n_jobs=12)]: Done  87 tasks      | elapsed:   12.0s\n",
            "[Parallel(n_jobs=12)]: Done  88 tasks      | elapsed:   12.1s\n",
            "[Parallel(n_jobs=12)]: Done  89 tasks      | elapsed:   12.1s\n",
            "[Parallel(n_jobs=12)]: Done  90 tasks      | elapsed:   12.1s\n",
            "[Parallel(n_jobs=12)]: Done  91 tasks      | elapsed:   12.1s\n",
            "[Parallel(n_jobs=12)]: Done  92 tasks      | elapsed:   12.1s\n",
            "[Parallel(n_jobs=12)]: Done  93 tasks      | elapsed:   12.2s\n",
            "[Parallel(n_jobs=12)]: Done  94 tasks      | elapsed:   12.2s\n",
            "[Parallel(n_jobs=12)]: Done  95 tasks      | elapsed:   12.2s\n",
            "[Parallel(n_jobs=12)]: Done  96 tasks      | elapsed:   12.3s\n",
            "[Parallel(n_jobs=12)]: Done  97 tasks      | elapsed:   12.3s\n",
            "[Parallel(n_jobs=12)]: Done  98 tasks      | elapsed:   12.4s\n",
            "[Parallel(n_jobs=12)]: Done  99 tasks      | elapsed:   12.4s\n",
            "[Parallel(n_jobs=12)]: Done 100 tasks      | elapsed:   12.4s\n",
            "[Parallel(n_jobs=12)]: Done 101 tasks      | elapsed:   12.5s\n",
            "[Parallel(n_jobs=12)]: Done 102 tasks      | elapsed:   12.6s\n",
            "[Parallel(n_jobs=12)]: Done 103 tasks      | elapsed:   12.7s\n",
            "[Parallel(n_jobs=12)]: Done 104 tasks      | elapsed:   12.7s\n",
            "[Parallel(n_jobs=12)]: Done 105 tasks      | elapsed:   12.7s\n",
            "[Parallel(n_jobs=12)]: Done 106 tasks      | elapsed:   12.8s\n",
            "[Parallel(n_jobs=12)]: Done 107 tasks      | elapsed:   12.8s\n",
            "[Parallel(n_jobs=12)]: Done 108 tasks      | elapsed:   12.8s\n",
            "[Parallel(n_jobs=12)]: Done 109 tasks      | elapsed:   12.9s\n",
            "[Parallel(n_jobs=12)]: Done 110 tasks      | elapsed:   12.9s\n",
            "[Parallel(n_jobs=12)]: Done 111 tasks      | elapsed:   12.9s\n",
            "[Parallel(n_jobs=12)]: Done 112 tasks      | elapsed:   12.9s\n",
            "[Parallel(n_jobs=12)]: Done 113 tasks      | elapsed:   12.9s\n",
            "[Parallel(n_jobs=12)]: Done 114 tasks      | elapsed:   13.0s\n",
            "[Parallel(n_jobs=12)]: Done 115 tasks      | elapsed:   13.0s\n",
            "[Parallel(n_jobs=12)]: Done 116 tasks      | elapsed:   13.2s\n",
            "[Parallel(n_jobs=12)]: Done 117 tasks      | elapsed:   13.3s\n",
            "[Parallel(n_jobs=12)]: Done 118 tasks      | elapsed:   13.3s\n",
            "[Parallel(n_jobs=12)]: Done 119 tasks      | elapsed:   13.3s\n",
            "[Parallel(n_jobs=12)]: Done 120 tasks      | elapsed:   13.3s\n",
            "[Parallel(n_jobs=12)]: Done 121 tasks      | elapsed:   13.3s\n",
            "[Parallel(n_jobs=12)]: Done 122 tasks      | elapsed:   13.4s\n",
            "[Parallel(n_jobs=12)]: Done 123 tasks      | elapsed:   13.4s\n",
            "[Parallel(n_jobs=12)]: Done 124 tasks      | elapsed:   13.4s\n",
            "[Parallel(n_jobs=12)]: Done 125 tasks      | elapsed:   13.4s\n",
            "[Parallel(n_jobs=12)]: Done 126 tasks      | elapsed:   13.5s\n",
            "[Parallel(n_jobs=12)]: Done 127 tasks      | elapsed:   13.5s\n",
            "[Parallel(n_jobs=12)]: Done 128 tasks      | elapsed:   13.5s\n",
            "[Parallel(n_jobs=12)]: Done 129 tasks      | elapsed:   13.5s\n",
            "[Parallel(n_jobs=12)]: Done 130 tasks      | elapsed:   13.6s\n",
            "[Parallel(n_jobs=12)]: Done 131 tasks      | elapsed:   13.6s\n",
            "[Parallel(n_jobs=12)]: Done 132 tasks      | elapsed:   13.6s\n",
            "[Parallel(n_jobs=12)]: Done 133 tasks      | elapsed:   13.6s\n",
            "[Parallel(n_jobs=12)]: Done 134 tasks      | elapsed:   13.7s\n",
            "[Parallel(n_jobs=12)]: Done 135 tasks      | elapsed:   13.7s\n",
            "[Parallel(n_jobs=12)]: Done 136 tasks      | elapsed:   13.8s\n",
            "[Parallel(n_jobs=12)]: Done 137 tasks      | elapsed:   13.8s\n",
            "[Parallel(n_jobs=12)]: Done 138 tasks      | elapsed:   13.8s\n",
            "[Parallel(n_jobs=12)]: Done 139 tasks      | elapsed:   13.8s\n",
            "[Parallel(n_jobs=12)]: Done 140 tasks      | elapsed:   13.8s\n",
            "[Parallel(n_jobs=12)]: Done 141 tasks      | elapsed:   13.8s\n",
            "[Parallel(n_jobs=12)]: Done 142 tasks      | elapsed:   14.0s\n",
            "[Parallel(n_jobs=12)]: Done 143 tasks      | elapsed:   14.0s\n",
            "[Parallel(n_jobs=12)]: Done 144 tasks      | elapsed:   14.1s\n",
            "[Parallel(n_jobs=12)]: Done 145 tasks      | elapsed:   14.2s\n",
            "[Parallel(n_jobs=12)]: Done 146 tasks      | elapsed:   14.3s\n",
            "[Parallel(n_jobs=12)]: Done 147 tasks      | elapsed:   14.3s\n",
            "[Parallel(n_jobs=12)]: Done 148 tasks      | elapsed:   14.3s\n",
            "[Parallel(n_jobs=12)]: Done 149 tasks      | elapsed:   14.3s\n",
            "[Parallel(n_jobs=12)]: Done 150 tasks      | elapsed:   14.3s\n",
            "[Parallel(n_jobs=12)]: Done 151 tasks      | elapsed:   14.4s\n",
            "[Parallel(n_jobs=12)]: Done 152 tasks      | elapsed:   14.4s\n",
            "[Parallel(n_jobs=12)]: Done 153 tasks      | elapsed:   14.4s\n",
            "[Parallel(n_jobs=12)]: Done 154 tasks      | elapsed:   14.4s\n",
            "[Parallel(n_jobs=12)]: Done 155 tasks      | elapsed:   14.4s\n",
            "[Parallel(n_jobs=12)]: Done 156 tasks      | elapsed:   14.5s\n",
            "[Parallel(n_jobs=12)]: Done 157 tasks      | elapsed:   14.6s\n",
            "[Parallel(n_jobs=12)]: Done 158 tasks      | elapsed:   14.6s\n",
            "[Parallel(n_jobs=12)]: Done 159 tasks      | elapsed:   14.6s\n",
            "[Parallel(n_jobs=12)]: Done 160 tasks      | elapsed:   14.7s\n",
            "[Parallel(n_jobs=12)]: Done 161 tasks      | elapsed:   14.8s\n",
            "[Parallel(n_jobs=12)]: Done 162 tasks      | elapsed:   14.9s\n",
            "[Parallel(n_jobs=12)]: Done 163 tasks      | elapsed:   14.9s\n",
            "[Parallel(n_jobs=12)]: Done 164 tasks      | elapsed:   15.0s\n",
            "[Parallel(n_jobs=12)]: Done 165 tasks      | elapsed:   15.0s\n",
            "[Parallel(n_jobs=12)]: Done 166 tasks      | elapsed:   15.0s\n",
            "[Parallel(n_jobs=12)]: Done 167 tasks      | elapsed:   15.0s\n",
            "[Parallel(n_jobs=12)]: Done 168 tasks      | elapsed:   15.1s\n",
            "[Parallel(n_jobs=12)]: Done 169 tasks      | elapsed:   15.1s\n",
            "[Parallel(n_jobs=12)]: Done 170 tasks      | elapsed:   15.1s\n",
            "[Parallel(n_jobs=12)]: Done 171 tasks      | elapsed:   15.1s\n",
            "[Parallel(n_jobs=12)]: Done 172 tasks      | elapsed:   15.1s\n",
            "[Parallel(n_jobs=12)]: Done 173 tasks      | elapsed:   15.2s\n",
            "[Parallel(n_jobs=12)]: Done 174 tasks      | elapsed:   15.2s\n",
            "[Parallel(n_jobs=12)]: Done 175 tasks      | elapsed:   15.3s\n",
            "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:   15.4s\n",
            "[Parallel(n_jobs=12)]: Done 177 tasks      | elapsed:   15.4s\n",
            "[Parallel(n_jobs=12)]: Done 178 tasks      | elapsed:   15.4s\n",
            "[Parallel(n_jobs=12)]: Done 179 tasks      | elapsed:   15.5s\n",
            "[Parallel(n_jobs=12)]: Done 180 tasks      | elapsed:   15.5s\n",
            "[Parallel(n_jobs=12)]: Done 181 tasks      | elapsed:   15.6s\n",
            "[Parallel(n_jobs=12)]: Done 182 tasks      | elapsed:   15.6s\n",
            "[Parallel(n_jobs=12)]: Done 183 tasks      | elapsed:   15.6s\n",
            "[Parallel(n_jobs=12)]: Done 184 tasks      | elapsed:   15.6s\n",
            "[Parallel(n_jobs=12)]: Done 185 tasks      | elapsed:   15.7s\n",
            "[Parallel(n_jobs=12)]: Done 186 tasks      | elapsed:   15.7s\n",
            "[Parallel(n_jobs=12)]: Done 187 tasks      | elapsed:   15.8s\n",
            "[Parallel(n_jobs=12)]: Done 188 tasks      | elapsed:   15.8s\n",
            "[Parallel(n_jobs=12)]: Done 189 tasks      | elapsed:   15.8s\n",
            "[Parallel(n_jobs=12)]: Done 190 tasks      | elapsed:   15.9s\n",
            "[Parallel(n_jobs=12)]: Done 191 tasks      | elapsed:   15.9s\n",
            "[Parallel(n_jobs=12)]: Done 192 tasks      | elapsed:   15.9s\n",
            "[Parallel(n_jobs=12)]: Done 193 tasks      | elapsed:   15.9s\n",
            "[Parallel(n_jobs=12)]: Done 194 tasks      | elapsed:   15.9s\n",
            "[Parallel(n_jobs=12)]: Done 195 tasks      | elapsed:   15.9s\n",
            "[Parallel(n_jobs=12)]: Done 196 tasks      | elapsed:   16.0s\n",
            "[Parallel(n_jobs=12)]: Done 197 tasks      | elapsed:   16.0s\n",
            "[Parallel(n_jobs=12)]: Done 198 tasks      | elapsed:   16.0s\n",
            "[Parallel(n_jobs=12)]: Done 199 tasks      | elapsed:   16.0s\n",
            "[Parallel(n_jobs=12)]: Done 200 tasks      | elapsed:   16.1s\n",
            "[Parallel(n_jobs=12)]: Done 201 tasks      | elapsed:   16.2s\n",
            "[Parallel(n_jobs=12)]: Done 202 tasks      | elapsed:   16.2s\n",
            "[Parallel(n_jobs=12)]: Done 203 tasks      | elapsed:   16.2s\n",
            "[Parallel(n_jobs=12)]: Done 204 tasks      | elapsed:   16.2s\n",
            "[Parallel(n_jobs=12)]: Done 205 tasks      | elapsed:   16.4s\n",
            "[Parallel(n_jobs=12)]: Done 206 tasks      | elapsed:   16.4s\n",
            "[Parallel(n_jobs=12)]: Done 207 tasks      | elapsed:   16.5s\n",
            "[Parallel(n_jobs=12)]: Done 208 tasks      | elapsed:   16.5s\n",
            "[Parallel(n_jobs=12)]: Done 209 tasks      | elapsed:   16.5s\n",
            "[Parallel(n_jobs=12)]: Done 210 tasks      | elapsed:   16.5s\n",
            "[Parallel(n_jobs=12)]: Done 211 tasks      | elapsed:   16.5s\n",
            "[Parallel(n_jobs=12)]: Done 212 tasks      | elapsed:   16.6s\n",
            "[Parallel(n_jobs=12)]: Done 213 tasks      | elapsed:   16.6s\n",
            "[Parallel(n_jobs=12)]: Done 214 tasks      | elapsed:   16.6s\n",
            "[Parallel(n_jobs=12)]: Done 215 tasks      | elapsed:   16.7s\n",
            "[Parallel(n_jobs=12)]: Done 216 tasks      | elapsed:   16.7s\n",
            "[Parallel(n_jobs=12)]: Done 217 tasks      | elapsed:   16.8s\n",
            "[Parallel(n_jobs=12)]: Done 218 tasks      | elapsed:   16.8s\n",
            "[Parallel(n_jobs=12)]: Done 219 tasks      | elapsed:   16.8s\n",
            "[Parallel(n_jobs=12)]: Done 220 tasks      | elapsed:   16.8s\n",
            "[Parallel(n_jobs=12)]: Done 221 tasks      | elapsed:   16.9s\n",
            "[Parallel(n_jobs=12)]: Done 222 tasks      | elapsed:   17.1s\n",
            "[Parallel(n_jobs=12)]: Done 223 tasks      | elapsed:   17.1s\n",
            "[Parallel(n_jobs=12)]: Done 224 tasks      | elapsed:   17.2s\n",
            "[Parallel(n_jobs=12)]: Done 225 tasks      | elapsed:   17.2s\n",
            "[Parallel(n_jobs=12)]: Done 226 tasks      | elapsed:   17.2s\n",
            "[Parallel(n_jobs=12)]: Done 227 tasks      | elapsed:   17.3s\n",
            "[Parallel(n_jobs=12)]: Done 228 tasks      | elapsed:   17.3s\n",
            "[Parallel(n_jobs=12)]: Done 229 tasks      | elapsed:   17.3s\n",
            "[Parallel(n_jobs=12)]: Done 230 tasks      | elapsed:   17.3s\n",
            "[Parallel(n_jobs=12)]: Done 231 tasks      | elapsed:   17.3s\n",
            "[Parallel(n_jobs=12)]: Done 232 tasks      | elapsed:   17.3s\n",
            "[Parallel(n_jobs=12)]: Done 233 tasks      | elapsed:   17.3s\n",
            "[Parallel(n_jobs=12)]: Done 234 tasks      | elapsed:   17.4s\n",
            "[Parallel(n_jobs=12)]: Done 235 tasks      | elapsed:   17.5s\n",
            "[Parallel(n_jobs=12)]: Done 236 tasks      | elapsed:   17.7s\n",
            "[Parallel(n_jobs=12)]: Done 237 tasks      | elapsed:   17.7s\n",
            "[Parallel(n_jobs=12)]: Done 238 tasks      | elapsed:   17.7s\n",
            "[Parallel(n_jobs=12)]: Done 239 tasks      | elapsed:   17.7s\n",
            "[Parallel(n_jobs=12)]: Done 240 tasks      | elapsed:   17.7s\n",
            "[Parallel(n_jobs=12)]: Done 241 tasks      | elapsed:   17.7s\n",
            "[Parallel(n_jobs=12)]: Done 242 tasks      | elapsed:   17.8s\n",
            "[Parallel(n_jobs=12)]: Done 243 tasks      | elapsed:   17.8s\n",
            "[Parallel(n_jobs=12)]: Done 244 tasks      | elapsed:   17.8s\n",
            "[Parallel(n_jobs=12)]: Done 245 tasks      | elapsed:   17.8s\n",
            "[Parallel(n_jobs=12)]: Done 246 tasks      | elapsed:   17.9s\n",
            "[Parallel(n_jobs=12)]: Done 247 tasks      | elapsed:   17.9s\n",
            "[Parallel(n_jobs=12)]: Done 248 tasks      | elapsed:   17.9s\n",
            "[Parallel(n_jobs=12)]: Done 249 tasks      | elapsed:   18.0s\n",
            "[Parallel(n_jobs=12)]: Done 250 tasks      | elapsed:   18.0s\n",
            "[Parallel(n_jobs=12)]: Done 251 tasks      | elapsed:   18.0s\n",
            "[Parallel(n_jobs=12)]: Done 252 tasks      | elapsed:   18.1s\n",
            "[Parallel(n_jobs=12)]: Done 253 tasks      | elapsed:   18.1s\n",
            "[Parallel(n_jobs=12)]: Done 254 tasks      | elapsed:   18.1s\n",
            "[Parallel(n_jobs=12)]: Done 255 tasks      | elapsed:   18.1s\n",
            "[Parallel(n_jobs=12)]: Done 256 tasks      | elapsed:   18.1s\n",
            "[Parallel(n_jobs=12)]: Done 257 tasks      | elapsed:   18.2s\n",
            "[Parallel(n_jobs=12)]: Done 258 tasks      | elapsed:   18.2s\n",
            "[Parallel(n_jobs=12)]: Done 259 tasks      | elapsed:   18.2s\n",
            "[Parallel(n_jobs=12)]: Done 260 tasks      | elapsed:   18.3s\n",
            "[Parallel(n_jobs=12)]: Done 261 tasks      | elapsed:   18.4s\n",
            "[Parallel(n_jobs=12)]: Done 262 tasks      | elapsed:   18.4s\n",
            "[Parallel(n_jobs=12)]: Done 263 tasks      | elapsed:   18.4s\n",
            "[Parallel(n_jobs=12)]: Done 264 tasks      | elapsed:   18.5s\n",
            "[Parallel(n_jobs=12)]: Done 265 tasks      | elapsed:   18.5s\n",
            "[Parallel(n_jobs=12)]: Done 266 tasks      | elapsed:   18.6s\n",
            "[Parallel(n_jobs=12)]: Done 267 tasks      | elapsed:   18.7s\n",
            "[Parallel(n_jobs=12)]: Done 268 tasks      | elapsed:   18.7s\n",
            "[Parallel(n_jobs=12)]: Done 269 tasks      | elapsed:   18.8s\n",
            "[Parallel(n_jobs=12)]: Done 270 tasks      | elapsed:   18.8s\n",
            "[Parallel(n_jobs=12)]: Done 271 tasks      | elapsed:   18.8s\n",
            "[Parallel(n_jobs=12)]: Done 272 tasks      | elapsed:   18.8s\n",
            "[Parallel(n_jobs=12)]: Done 273 tasks      | elapsed:   18.8s\n",
            "[Parallel(n_jobs=12)]: Done 274 tasks      | elapsed:   18.8s\n",
            "[Parallel(n_jobs=12)]: Done 275 tasks      | elapsed:   18.9s\n",
            "[Parallel(n_jobs=12)]: Done 276 tasks      | elapsed:   19.0s\n",
            "[Parallel(n_jobs=12)]: Done 277 tasks      | elapsed:   19.0s\n",
            "[Parallel(n_jobs=12)]: Done 300 out of 300 | elapsed:   19.7s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
              "                           class_weight=None, coef0=0.0,\n",
              "                           decision_function_shape='ovr', degree=3,\n",
              "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                           probability=False, random_state=None, shrinking=True,\n",
              "                           tol=0.001, verbose=False),\n",
              "             iid='deprecated', n_jobs=12,\n",
              "             param_grid=[{'C': [10, 20, 50, 100, 200],\n",
              "                          'gamma': [0.005, 0.0003, 1e-05],\n",
              "                          'kernel': ['rbf', 'poly', 'linear', 'sigmoid']}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe8t_KmHggCq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4745d7b1-1539-4c62-92f6-ef56b206995d"
      },
      "source": [
        "svm_model.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 10, 'gamma': 0.0003, 'kernel': 'sigmoid'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJZBQDNbchvb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "54f4bcff-8032-414e-edfc-b95771c89e5b"
      },
      "source": [
        "final_model = svm_model.best_estimator_\n",
        "final_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma=0.0003, kernel='sigmoid',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ldr0TUCcruA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "outputId": "42224842-7e3b-4294-b564-2aafcb664f71"
      },
      "source": [
        "Y_pred = final_model.predict(X_test_scaled2)\n",
        "#Y_pred_label = list(encoder.inverse_transform(Y_pred))\n",
        "#Y_pred is cathegorical\n",
        "\n",
        "print(confusion_matrix(y_test2,Y_pred))\n",
        "print(\"\\n\")\n",
        "print(classification_report(y_test2,Y_pred))\n",
        "\n",
        "print(\"Training set score for SVM: %f\" % final_model.score(X_train_scaled2 , y_train2))\n",
        "print(\"Testing  set score for SVM: %f\" % final_model.score(X_test_scaled2  , y_test2 ))\n",
        "\n",
        "svm_model.score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[55  0  4]\n",
            " [ 0 41  0]\n",
            " [10  0 74]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.85      0.93      0.89        59\n",
            "     neutral       1.00      1.00      1.00        41\n",
            "    positive       0.95      0.88      0.91        84\n",
            "\n",
            "    accuracy                           0.92       184\n",
            "   macro avg       0.93      0.94      0.93       184\n",
            "weighted avg       0.93      0.92      0.92       184\n",
            "\n",
            "Training set score for SVM: 1.000000\n",
            "Testing  set score for SVM: 0.923913\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method BaseSearchCV.score of GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
              "                           class_weight=None, coef0=0.0,\n",
              "                           decision_function_shape='ovr', degree=3,\n",
              "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                           probability=False, random_state=None, shrinking=True,\n",
              "                           tol=0.001, verbose=False),\n",
              "             iid='deprecated', n_jobs=12,\n",
              "             param_grid=[{'C': [10, 20, 50, 100, 200],\n",
              "                          'gamma': [0.005, 0.0003, 1e-05],\n",
              "                          'kernel': ['rbf', 'poly', 'linear', 'sigmoid']}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=12)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p70Yf0PVgfTr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#how to save a model\n",
        "import joblib\n",
        "joblib.dump( final_model, '/content/drive/My Drive/Topic detection/firstSVM.pkl')\n",
        "\n",
        "my_model_loaded = joblib.load('/content/drive/My Drive/Topic detection/firstSVM.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxXfbQ2Uc2ck",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "3b8d6f70-5e06-4f14-c07d-c9e7c5268ab3"
      },
      "source": [
        "my_model_loaded"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma=0.0003, kernel='sigmoid',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01fu4Exvi3un",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2LFoatwmexg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "25f2c13a-f5c8-42b4-fbe7-0c67b87e135d"
      },
      "source": [
        "# Gaussian assumption\n",
        "\n",
        "gnb = GaussianNB()\n",
        "Y_pred = gnb.fit(X_train2, y_train2).predict(X_test2)\n",
        "\n",
        "print(confusion_matrix(y_test2,Y_pred))\n",
        "print(\"\\n\")\n",
        "print(classification_report(y_test2,Y_pred))\n",
        "\n",
        "print(\"Training set score for SVM: %f\" % gnb.score(X_train_scaled2 , y_train2))\n",
        "print(\"Testing  set score for SVM: %f\" % gnb.score(X_test_scaled2  , y_test2 ))\n",
        "\n",
        "gnb.score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[45  0 14]\n",
            " [ 0 41  0]\n",
            " [45  4 35]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.50      0.76      0.60        59\n",
            "     neutral       0.91      1.00      0.95        41\n",
            "    positive       0.71      0.42      0.53        84\n",
            "\n",
            "    accuracy                           0.66       184\n",
            "   macro avg       0.71      0.73      0.69       184\n",
            "weighted avg       0.69      0.66      0.65       184\n",
            "\n",
            "Training set score for SVM: 0.696970\n",
            "Testing  set score for SVM: 0.586957\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method ClassifierMixin.score of GaussianNB(priors=None, var_smoothing=1e-09)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyB5zK7Jms_r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "31a85be9-fd83-4e14-cee6-604e28b5e93e"
      },
      "source": [
        "# bernoulli\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "gnb =   BernoulliNB()\n",
        "Y_pred = gnb.fit(X_train2, y_train2).predict(X_test2)\n",
        "\n",
        "print(confusion_matrix(y_test2,Y_pred))\n",
        "print(\"\\n\")\n",
        "print(classification_report(y_test2,Y_pred))\n",
        "\n",
        "print(\"Training set score for BNB: %f\" % gnb.score(X_train_scaled2 , y_train2))\n",
        "print(\"Testing  set score for BNB: %f\" % gnb.score(X_test_scaled2  , y_test2 ))\n",
        "\n",
        "gnb.score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[43  0 16]\n",
            " [ 0 38  3]\n",
            " [13  3 68]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.77      0.73      0.75        59\n",
            "     neutral       0.93      0.93      0.93        41\n",
            "    positive       0.78      0.81      0.80        84\n",
            "\n",
            "    accuracy                           0.81       184\n",
            "   macro avg       0.83      0.82      0.82       184\n",
            "weighted avg       0.81      0.81      0.81       184\n",
            "\n",
            "Training set score for BNB: 0.864802\n",
            "Testing  set score for BNB: 0.755435\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method ClassifierMixin.score of BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vzPcKYVoxmb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d6e56f9c-a885-49d2-8eec-c306e414d5ca"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "#print accuracy_score(pred, labels_test)\n",
        "accuracy_score(Y_pred ,y_test2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8097826086956522"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4YKJmawpdXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Do multinomial"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCIna2gB4SJb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}